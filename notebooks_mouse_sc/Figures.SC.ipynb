{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import anndata\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import gzip as gz\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jw3514/Work/ASD_Circuits_CellType/src/')\n",
    "from ASD_Circuits import *\n",
    "#from CellType_PSY import *\n",
    "os.chdir(\"/home/jw3514/Work/ASD_Circuits_CellType/notebooks_mouse_sc/\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "#  Figure 5 (Cell type results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixSubiculum(DF):\n",
    "    X = DF.loc[\"Subiculum_dorsal_part\"]\n",
    "    Y = DF.loc[\"Subiculum_ventral_part\"]\n",
    "    Z = [(X[0]+Y[0])/2, \"Hippocampus\", 214]\n",
    "    DF.loc[\"Subiculum\"] = Z\n",
    "    DF = DF.drop([\"Subiculum_dorsal_part\", \"Subiculum_ventral_part\"])\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_STR_Bias = pd.read_csv(\"../../ASD_Circuits/dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.csv\", index_col=0)\n",
    "ASD_STR_Bias = FixSubiculum(ASD_STR_Bias)\n",
    "ASD_CircuitsSet = pd.read_csv(\n",
    "    \"/home/jw3514/Work/ASD_Circuits/notebooks/ASD.SA.Circuits.Size46.csv\",\n",
    "    index_col=\"idx\")\n",
    "ASD_Circuits = ASD_CircuitsSet.loc[3, \"STRs\"].split(\";\")\n",
    "ASD_Circuits.append(\"Subiculum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 5A STR Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_STR_Bias = pd.read_csv(\"../../ASD_Circuits/dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.csv\", index_col=0)\n",
    "ASD_STR_Bias = FixSubiculum(ASD_STR_Bias)\n",
    "#SC_Agg_Bias = pd.read_csv(\"dat/JonDat/MERFISH_Bias_NeuroOnly_JC.csv\", index_col=0)\n",
    "SC_Agg_Bias = pd.read_csv(\"dat/Bias/STR/ASD.MERFISH_Allen.NM.ISHMatch.Z2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SC_Agg_Bias = SC_Agg_Bias.rename(columns={\"RANK\":\"Rank\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_STR_Bias['REGION'] = ASD_STR_Bias['REGION'].replace('Amygdalar', 'Amygdala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_CircuitsSet = pd.read_csv(\n",
    "    \"/home/jw3514/Work/ASD_Circuits/notebooks/ASD.SA.Circuits.Size46.csv\",\n",
    "    index_col=\"idx\")\n",
    "ASD_Circuits = ASD_CircuitsSet.loc[3, \"STRs\"].split(\";\")\n",
    "ASD_Circuits.append(\"Subiculum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in ASD_STR_Bias.iterrows():\n",
    "    ASD_STR_Bias.loc[i, \"SC_Bias\"] = SC_Agg_Bias.loc[i, \"EFFECT\"]\n",
    "    ASD_STR_Bias.loc[i, \"SC_Rank\"] = int(SC_Agg_Bias.loc[i, \"Rank\"])\n",
    "    if i in ASD_Circuits:\n",
    "        ASD_STR_Bias.loc[i, \"isCir\"] = 1\n",
    "    else:\n",
    "        ASD_STR_Bias.loc[i, \"isCir\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def TestBiasCompare(Bias1, Bias2, name1=\"1\", name2=\"2\"):\n",
    "    REGIONS = list(set(Bias1[\"REGION\"].values))\n",
    "\n",
    "    REGIONS_seq = ['Isocortex','Olfactory_areas', 'Cortical_subplate', \n",
    "                   'Hippocampus','Amygdala','Striatum', \n",
    "                   \"Thalamus\", \"Hypothalamus\", \"Midbrain\", \n",
    "                   \"Medulla\", \"Pallidum\", \"Pons\", \n",
    "                   \"Cerebellum\"]\n",
    "    REG_COR_Dic = dict(zip(REGIONS_seq, [\"#268ad5\", \"#D5DBDB\", \"#7ac3fa\", \n",
    "                                     \"#2c9d39\", \"#742eb5\", \"#ed8921\", \n",
    "                                     \"#e82315\", \"#E6B0AA\", \"#f6b26b\",  \n",
    "                                     \"#20124d\", \"#2ECC71\", \"#D2B4DE\", \n",
    "                                     \"#ffd966\", ]))\n",
    "    plt.figure(dpi=300, figsize=(6, 4))\n",
    "\n",
    "    # Use Seaborn for style and color palette\n",
    "    sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "    palette = sns.color_palette(\"deep\")\n",
    "\n",
    "    JoinDF = Bias1.join(Bias2, how=\"inner\", lsuffix=\"_{}\".format(name1), rsuffix=\"_{}\".format(name2))\n",
    "    R,P = pearsonr(JoinDF[\"EFFECT_{}\".format(name1)].values, JoinDF[\"EFFECT_{}\".format(name2)].values)\n",
    "    RR,PP = spearmanr(JoinDF[\"EFFECT_{}\".format(name1)].values, JoinDF[\"EFFECT_{}\".format(name2)].values)\n",
    "    # Scatter plot with improved aesthetics\n",
    "    for reg in REGIONS_seq:\n",
    "        RegDF = JoinDF[JoinDF[\"REGION_{}\".format(name1)]==reg]\n",
    "        X = RegDF[\"EFFECT_{}\".format(name1)].values\n",
    "        Y = RegDF[\"EFFECT_{}\".format(name2)].values\n",
    "        plt.scatter(X, Y, facecolor=REG_COR_Dic[reg], alpha=0.7, s=20, label=reg.replace(\"_\", \" \"))\n",
    "    minX, maxY = min(JoinDF[\"EFFECT_{}\".format(name1)].values), max(JoinDF[\"EFFECT_{}\".format(name2)].values)\n",
    "    \n",
    "    Top50_X = JoinDF.sort_values(\"EFFECT_{}\".format(name1), ascending=False).head(50).index.values\n",
    "    top50_Y = JoinDF.sort_values(\"EFFECT_{}\".format(name2), ascending=False).head(50).index.values \n",
    "    STR_Com = len(set(Top50_X).intersection(set(top50_Y)))\n",
    "    #plt.text(x=minX, y=maxY*0.7, s=\"r=%.2f P<%.1e\\nrho=%.2f P<%.1e\\nSTR_Comm=%d\"%(R, P, RR, PP, STR_Com), \n",
    "    #         fontsize=6, weight='bold')\n",
    "    #plt.text(x=minX, y=maxY*0.7, s=\"r=%.2f\\nP<%.1e\\nrho=%.2f P<%.1e\"%(R, np.max([P, 1e-10]), RR, \n",
    "    #                                                                 np.max([PP, 1e-10])), \n",
    "    #         fontsize=6, weight='bold')\n",
    "    plt.text(x=minX-0.2, y=maxY*0.7, s=\"r=%.2f\\nP<%.1e\"%(R, np.max([P, 1e-10])), \n",
    "             fontsize=12, weight='bold')\n",
    "    # Adding labels, title, and legend\n",
    "    plt.xlabel(name1, fontsize=14, weight='bold')\n",
    "    plt.ylabel(name2, fontsize=14, weight='bold')\n",
    "    #plt.title(\"Scatter Plot of EFFECT vs. SC_Bias\", fontsize=16, weight='bold')\n",
    "    #plt.legend(fontsize=6)\n",
    "    plt.legend(fontsize=8, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.plot([-1.1, 0.8], [-1.1, 0.8], color=\"grey\", alpha=0.3)\n",
    "    plt.xlim(-1.1, 0.8)\n",
    "    plt.ylim(-1.1, 0.8)\n",
    "    # Adding grid lines\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Adjusting ticks\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias1 = ASD_STR_Bias\n",
    "Bias2 = SC_Agg_Bias\n",
    "#BiasCorrelation(Bias1, Bias2, \"Z2\", \"Zmatch\")\n",
    "TestBiasCompare(Bias1, Bias2,  \"ISH Bias\", \"MERFISH Bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS_seq = ['Isocortex','Olfactory_areas', 'Cortical_subplate', \n",
    "               'Hippocampus','Amygdala','Striatum', \n",
    "               \"Thalamus\", \"Hypothalamus\", \"Midbrain\", \n",
    "               \"Medulla\", \"Pallidum\", \"Pons\", \n",
    "               \"Cerebellum\"]\n",
    "REG_COR_Dic = dict(zip(REGIONS_seq, [\"#268ad5\", \"#D5DBDB\", \"#7ac3fa\", \n",
    "                                 \"#2c9d39\", \"#742eb5\", \"#ed8921\", \n",
    "                                 \"#e82315\", \"#E6B0AA\", \"#f6b26b\",  \n",
    "                                 \"#20124d\", \"#2ECC71\", \"#D2B4DE\", \n",
    "                                 \"#ffd966\", ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISH_REG_Bias = []\n",
    "MF_REG_Bias = []\n",
    "for Reg in REGIONS_seq:\n",
    "    ISH_Reg = ASD_STR_Bias[ASD_STR_Bias[\"REGION\"]==Reg][\"EFFECT\"]\n",
    "    MF_Reg = SC_Agg_Bias[SC_Agg_Bias[\"REGION\"]==Reg][\"EFFECT\"]\n",
    "    #print(Reg, ISH_Reg.max() - ISH_Reg.min(), MF_Reg.max() - MF_Reg.min())\n",
    "    #ISH_REG_Bias.append(ISH_Reg.mean())\n",
    "    #MF_REG_Bias.append(MF_Reg.mean())\n",
    "    ISH_REG_Bias.append(np.nanmean(ISH_Reg))\n",
    "    MF_REG_Bias.append(np.nanmean(MF_Reg))\n",
    "    print(Reg, np.nanmean(ISH_Reg), np.nanmean(MF_Reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "R1, P1 = pearsonr(ISH_REG_Bias, MF_REG_Bias)\n",
    "R2, P2 = spearmanr(ISH_REG_Bias, MF_REG_Bias)\n",
    "print(R1, P1, R2, P2)\n",
    "plt.figure(dpi=200, figsize=(6,6))\n",
    "for Reg in REGIONS_seq:\n",
    "    ISH_Reg = ASD_STR_Bias[ASD_STR_Bias[\"REGION\"]==Reg][\"EFFECT\"]\n",
    "    MF_Reg = SC_Agg_Bias[SC_Agg_Bias[\"REGION\"]==Reg][\"EFFECT\"]\n",
    "    X = ISH_Reg.mean()\n",
    "    Y = MF_Reg.mean()\n",
    "    plt.scatter(ISH_Reg.mean(), MF_Reg.mean(), color=REG_COR_Dic[Reg])\n",
    "    plt.text(X, Y, s=Reg, fontsize=15)\n",
    "plt.plot([-0.6, 0.5], [-0.6, 0.5], color=\"grey\", alpha=0.3)\n",
    "plt.text(-0.4, 0.2, s=\"R = %.2f\\nrho = %.2f\"%(R1, R2), fontsize=15)\n",
    "plt.xlabel(\"ISH\")\n",
    "plt.xlim(-0.6, 0.5)\n",
    "plt.ylim(-0.6, 0.5)\n",
    "plt.ylabel(\"MERFISH per Vol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 5B Sub Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASD_Cluster_Bias_for_DN = pd.read_csv(\"dat/Bias/ASD.ClusterV3.top60.UMI.Z2.pvalues.csv\", index_col=0)\n",
    "#ASD_Cluster_Bias_noDN = pd.read_csv(\"dat/Bias/ASD.ClusterV3.top60.UMI.Z2.noDN.pvalues.csv\", index_col=0)\n",
    "ASD_BiasDN_z1clip3_addP = pd.read_csv(\"dat/Bias/ASD.ClusterV3.top60.UMI.Z2.z1clip3.addP.csv\", index_col=0)\n",
    "#ASD_Bias.to_csv(\"dat/Bias/ASD.ClusterV3.top60.UMI.Z2.pvalues.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### V1 QQ Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetExpQ(pvalues):\n",
    "    sorted_pvalues = np.sort(pvalues)\n",
    "    expected = np.linspace(0, 1, len(sorted_pvalues), endpoint=False)[1:]\n",
    "    expected_quantiles = -np.log10(expected)\n",
    "    observed_quantiles = -np.log10(sorted_pvalues[1:])\n",
    "    return expected_quantiles, observed_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def QQPlot_MouseSC(DF_w_Pvalues, Classes, max_val=4.1):\n",
    "    P_Q005_DF = DF_w_Pvalues[DF_w_Pvalues[\"qvalues\"]<0.05]#\n",
    "    if P_Q005_DF.shape[0] > 0:\n",
    "        P_Q005 = P_Q005_DF[\"Pvalue\"][-1]\n",
    "    else:\n",
    "        P_Q005 = -1\n",
    "    P_Q01_DF = DF_w_Pvalues[DF_w_Pvalues[\"qvalues\"]<0.1]#[\"Pvalue\"][-1]\n",
    "    if P_Q01_DF.shape[0] > 0:\n",
    "        P_Q01 = P_Q01_DF[\"Pvalue\"][-1]\n",
    "    else:\n",
    "        P_Q01 = -1\n",
    "\n",
    "    plt.figure(dpi=300, figsize=(8, 8))\n",
    "    sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "    # Plot the quantiles\n",
    "    for Class in Classes:\n",
    "        tmp = DF_w_Pvalues[DF_w_Pvalues[\"class_id_label\"]==Class]\n",
    "        Class_Pvals = tmp[\"Pvalue\"].values\n",
    "        Qexp, Qobs = GetExpQ(Class_Pvals)\n",
    "        plt.scatter(Qexp, Qobs , alpha=0.7, s=50, label=Class)\n",
    "\n",
    "    Other = DF_w_Pvalues[~DF_w_Pvalues[\"class_id_label\"].isin(Classes)]\n",
    "    Other_Pvals = Other[\"Pvalue\"].values\n",
    "    Qexp, Qobs = GetExpQ(Other_Pvals)\n",
    "    plt.scatter(Qexp, Qobs , alpha=0.7, color=\"grey\", s=50, label=\"Other\")\n",
    "\n",
    "    if P_Q005 != -1:\n",
    "        plt.axhline(y=-np.log10(P_Q005), color='grey', linestyle='--', linewidth=2,)\n",
    "        plt.text(x=3.25, y=-np.log10(P_Q005) + 0.05, s=\"FDR 0.05\")\n",
    "    if P_Q01 != -1:\n",
    "        plt.axhline(y=-np.log10(P_Q01), color='grey', linestyle='--', linewidth=2,)\n",
    "        plt.text(x=3.25, y=-np.log10(P_Q01) + 0.05, s=\"FDR 0.1\")\n",
    "\n",
    "    # Add a reference line\n",
    "    plt.plot([0, max_val], [0, max_val], 'r--', linewidth=2)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Expected -log10(p-value)', fontsize=25, weight='bold')\n",
    "    plt.ylabel('Observed -log10(p-value)', fontsize=25, weight='bold')\n",
    "    #plt.title(title, fontsize=16, weight='bold')\n",
    "\n",
    "    # Customize the ticks\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    # Add grid\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "    plt.legend(fontsize=15, loc=\"lower right\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classes = [\"01 IT-ET Glut\",  \"02 NP-CT-L6b Glut\", \n",
    "           \"09 CNU-LGE GABA\", \"18 TH Glut\", \"11 CNU-HYa GABA\", \"13 CNU-HYa Glut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "QQPlot_MouseSC(ASD_BiasDN_z1clip3_addP, Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## V2 Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "CellTypesDF = pd.read_csv(\"dat/CellTypeHierarchy.csv\")\n",
    "Class2Cluster = {}\n",
    "Subclass2Cluster = {}\n",
    "for i, row in CellTypesDF.iterrows():\n",
    "    _cluster, _class, _subclass, _supertype = row\n",
    "    if _class not in Class2Cluster:\n",
    "        Class2Cluster[_class] = []\n",
    "    if _subclass not in Subclass2Cluster:\n",
    "        Subclass2Cluster[_subclass] = []\n",
    "    Class2Cluster[_class].append(_cluster)\n",
    "    Subclass2Cluster[_subclass].append(_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ClassBiasBoxPlot(DF):\n",
    "    Class = sorted(Class2Cluster.keys())\n",
    "    sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "    # Calculate medians and sort data by medians\n",
    "    ASD_dat_CB = []\n",
    "    medians = []\n",
    "    for _CT in Class:\n",
    "        subdf = DF[DF[\"class_id_label\"]==_CT]\n",
    "        data = [x for x in subdf[\"EFFECT\"].values if x==x]\n",
    "        ASD_dat_CB.append(data)\n",
    "        medians.append(np.median(data))\n",
    "\n",
    "    # Sort based on medians\n",
    "    sorted_indices = np.argsort(medians)\n",
    "    sorted_ASD_dat_CB = [ASD_dat_CB[i] for i in sorted_indices]\n",
    "    sorted_Class = [Class[i] for i in sorted_indices]\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(dpi=480, figsize=(8, 8))\n",
    "    boxplot = ax.boxplot(sorted_ASD_dat_CB, labels=sorted_Class, vert=False, patch_artist=True)\n",
    "    colors = sns.color_palette(\"muted\", len(sorted_Class))\n",
    "    for patch, color in zip(boxplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xlabel('ASD Bias', fontsize=14)\n",
    "    plt.ylabel('Classes', fontsize=14)\n",
    "    plt.title('ASD Bias Across Different Classes', fontsize=16, weight='bold')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassBiasBoxPlot(ASD_BiasDN_z1clip3_addP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# C - Subclass level for selected classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data generation (using the provided example structure)\n",
    "Subclass = sorted(Subclass2Cluster.keys())\n",
    "CTX_Glut = Subclass[0:34] # CTX Glut\n",
    "dat = []\n",
    "for _CT in CTX_Glut:\n",
    "    clusters_ = Subclass2Cluster[_CT]\n",
    "    clusters_ = [x for x in clusters_ if x in ASD_BiasDN_z1clip3_addP.index.values]\n",
    "    dat.append([x for x in ASD_BiasDN_z1clip3_addP.loc[clusters_, \"EFFECT\"].values if x==x])\n",
    "\n",
    "# Calculate medians and sort data based on medians\n",
    "medians = [np.median(d) for d in dat]\n",
    "sorted_indices = np.argsort(medians)[::-1]\n",
    "sorted_dat = [dat[i] for i in sorted_indices]\n",
    "sorted_CTX_Glut = [CTX_Glut[i] for i in sorted_indices]\n",
    "\n",
    "# Set up the plotting style and context\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(dpi=480, figsize=(8, 9))  # Adjust the figure size as needed\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(data=sorted_dat, orient='h', ax=ax, palette='deep')\n",
    "\n",
    "# Set the labels\n",
    "ax.set_xlabel(\"ASD Bias\", fontsize=16, weight='bold')\n",
    "ax.set_yticklabels(sorted_CNU_HYa_Glut, fontsize=12)\n",
    "\n",
    "# Improve grid and layout\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Customize the ticks\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Add title if necessary\n",
    "# plt.title(\"ASD Bias Across Different Subclasses\", fontsize=18, weight='bold')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['006 L4/5 IT CTX Glut', '007 L2/3 IT CTX Glut']\n",
    "sorted_CTX_Glut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test for enrichment at top of ranked list\n",
    "# Testing if 2 specific neuron types appear at the top of sorted_CTX_Glut\n",
    "\n",
    "from scipy.stats import hypergeom\n",
    "from scipy.stats import rankdata\n",
    "import numpy as np\n",
    "\n",
    "# Your test types\n",
    "test = ['006 L4/5 IT CTX Glut', '007 L2/3 IT CTX Glut']\n",
    "\n",
    "# Check if sorted_CTX_Glut exists and get its length\n",
    "if 'sorted_CTX_Glut' in locals():\n",
    "    N = len(sorted_CTX_Glut)  # Total number of CTX_Glut types\n",
    "    M = len(test)  # Number of test types (2)\n",
    "    \n",
    "    # Find positions of test types in sorted list (1-indexed for ranks)\n",
    "    test_positions = []\n",
    "    for t in test:\n",
    "        if t in sorted_CTX_Glut:\n",
    "            pos = sorted_CTX_Glut.index(t) + 1  # 1-indexed rank\n",
    "            test_positions.append(pos)\n",
    "    \n",
    "    print(f\"Total CTX_Glut types: {N}\")\n",
    "    print(f\"Test types: {test}\")\n",
    "    print(f\"Positions in ranked list: {test_positions}\")\n",
    "    print(f\"Mean rank: {np.mean(test_positions):.2f}\")\n",
    "    \n",
    "    # ===== OPTION 1: HYPERGEOMETRIC TEST =====\n",
    "    # Tests: \"Are the test types overrepresented in top K positions?\"\n",
    "    # Best when: You have a specific cutoff K (e.g., top 5, top 10)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HYPERGEOMETRIC TEST\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test multiple K values (top K positions)\n",
    "    for K in [2, 3, 5, 10]:\n",
    "        # Count how many test types are in top K\n",
    "        observed = sum(1 for pos in test_positions if pos <= K)\n",
    "        \n",
    "        # Hypergeometric test: P(X >= observed)\n",
    "        # Parameters: N (population), M (successes in population), K (sample size)\n",
    "        p_value = hypergeom.sf(observed - 1, N, M, K)  # sf = survival function (1 - cdf)\n",
    "        \n",
    "        print(f\"\\nTop {K} positions:\")\n",
    "        print(f\"  Observed test types in top {K}: {observed}/{M}\")\n",
    "        print(f\"  Expected by chance: {M * K / N:.2f}\")\n",
    "        print(f\"  P-value (one-tailed): {p_value:.4e}\")\n",
    "        if p_value < 0.05:\n",
    "            print(f\"  *** Significant enrichment! ***\")\n",
    "    \n",
    "    # ===== OPTION 2: PERMUTATION TEST =====\n",
    "    # Tests: \"Do the test types have unusually high ranks?\"\n",
    "    # Best when: You want to test rank-based statistics without fixed cutoff\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PERMUTATION TEST\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_permutations = 10000\n",
    "    observed_mean_rank = np.mean(test_positions)\n",
    "    \n",
    "    # Generate null distribution by permuting ranks\n",
    "    null_mean_ranks = []\n",
    "    for _ in range(n_permutations):\n",
    "        # Randomly select 2 positions from 1 to N\n",
    "        random_positions = np.random.choice(range(1, N+1), size=M, replace=False)\n",
    "        null_mean_ranks.append(np.mean(random_positions))\n",
    "    \n",
    "    null_mean_ranks = np.array(null_mean_ranks)\n",
    "    \n",
    "    # Calculate p-value: proportion of permutations with mean rank <= observed\n",
    "    p_value_perm = np.mean(null_mean_ranks <= observed_mean_rank)\n",
    "    \n",
    "    print(f\"\\nObserved mean rank: {observed_mean_rank:.2f}\")\n",
    "    print(f\"Expected mean rank (null): {np.mean(null_mean_ranks):.2f}\")\n",
    "    print(f\"P-value (one-tailed): {p_value_perm:.4e}\")\n",
    "    if p_value_perm < 0.05:\n",
    "        print(f\"  *** Significant enrichment! ***\")\n",
    "    \n",
    "    # ===== SUM OF RANKS TEST =====\n",
    "    # Tests: \"Is the sum of ranks lower than expected?\" (lower sum = better ranks)\n",
    "    # This is equivalent to mean rank but sometimes more intuitive\n",
    "    \n",
    "    observed_sum_rank = np.sum(test_positions)\n",
    "    \n",
    "    # Generate null distribution for sum of ranks\n",
    "    null_sum_ranks = []\n",
    "    for _ in range(n_permutations):\n",
    "        random_positions = np.random.choice(range(1, N+1), size=M, replace=False)\n",
    "        null_sum_ranks.append(np.sum(random_positions))\n",
    "    \n",
    "    null_sum_ranks = np.array(null_sum_ranks)\n",
    "    \n",
    "    # Calculate p-value: proportion of permutations with sum rank <= observed\n",
    "    # Lower sum = better (both types higher up), so we test P(sum <= observed)\n",
    "    p_value_sum = np.mean(null_sum_ranks <= observed_sum_rank)\n",
    "    \n",
    "    print(f\"\\n\" + \"-\"*60)\n",
    "    print(f\"SUM OF RANKS TEST\")\n",
    "    print(f\"-\"*60)\n",
    "    print(f\"Observed sum of ranks: {observed_sum_rank}\")\n",
    "    print(f\"Expected sum of ranks (null): {np.mean(null_sum_ranks):.2f}\")\n",
    "    print(f\"P-value (one-tailed, testing if sum <= observed): {p_value_sum:.4e}\")\n",
    "    if p_value_sum < 0.05:\n",
    "        print(f\"  *** Significant enrichment! ***\")\n",
    "    print(f\"\\nNote: Lower sum = better ranks. Testing if sum_rank <= observed_sum_rank\")\n",
    "    print(f\"      This is equivalent to testing mean rank, but sum can be more intuitive.\")\n",
    "    \n",
    "    # Also test: Are both types in top K? (more stringent)\n",
    "    print(f\"\\nTesting if BOTH types are in top positions:\")\n",
    "    for K in [2, 3, 5]:\n",
    "        both_in_top = all(pos <= K for pos in test_positions)\n",
    "        # Permutation test: probability that 2 random types both fall in top K\n",
    "        null_both_in_top = []\n",
    "        for _ in range(n_permutations):\n",
    "            random_positions = np.random.choice(range(1, N+1), size=M, replace=False)\n",
    "            null_both_in_top.append(all(pos <= K for pos in random_positions))\n",
    "        p_both = np.mean(null_both_in_top)\n",
    "        \n",
    "        print(f\"  Top {K}: Both in top? {both_in_top}, P-value: {p_both:.4e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RECOMMENDATION:\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\"\"\n",
    "    Use HYPERGEOMETRIC TEST if:\n",
    "    - You have a specific biological cutoff (e.g., \"top 5 most biased types\")\n",
    "    - You want exact p-values\n",
    "    - You're testing enrichment in a specific region of the ranking\n",
    "    \n",
    "    Use PERMUTATION TEST if:\n",
    "    - You want to test overall rank enrichment without fixed cutoff\n",
    "    - You want more flexibility in test statistics\n",
    "    - You're comfortable with approximate p-values\n",
    "    \n",
    "    For your case (testing if 2 types are at the \"top\"), I recommend:\n",
    "    1. Hypergeometric test with K=5 or K=10 (most interpretable)\n",
    "    2. Permutation test for mean rank (more flexible, no cutoff needed)\n",
    "    \"\"\")\n",
    "    \n",
    "else:\n",
    "    print(\"Error: sorted_CTX_Glut not found. Please run the cell that creates it first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.02 * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data generation (using the provided example structure)\n",
    "Subclass = sorted(Subclass2Cluster.keys())\n",
    "CTX_GABA = Subclass[45:58] + Subclass[66:72]  # CTX GABA\n",
    "dat = []\n",
    "for _CT in CTX_GABA:\n",
    "    dat.append([x for x in ASD_BiasDN_z1clip3_addP.loc[Subclass2Cluster[_CT], \"EFFECT\"].values if x==x])\n",
    "\n",
    "# Calculate medians and sort data based on medians\n",
    "medians = [np.median(d) for d in dat]\n",
    "sorted_indices = np.argsort(medians)[::-1]\n",
    "sorted_dat = [dat[i] for i in sorted_indices]\n",
    "sorted_CTX_GABA = [CTX_GABA[i] for i in sorted_indices]\n",
    "\n",
    "# Set up the plotting style and context\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(dpi=480, figsize=(8, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(data=sorted_dat, orient='h', ax=ax, palette='deep')\n",
    "\n",
    "# Set the labels\n",
    "ax.set_xlabel(\"ASD Bias\", fontsize=16, weight='bold')\n",
    "ax.set_yticklabels(sorted_CTX_GABA, fontsize=12)\n",
    "\n",
    "# Improve grid and layout\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Customize the ticks\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Add title if necessary\n",
    "# plt.title(\"ASD Bias Across Different Subclasses\", fontsize=18, weight='bold')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTX_GABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test for enrichment at top of ranked list - CTX_GABA\n",
    "# Testing if 2 specific neuron types appear at the top of sorted_CTX_GABA\n",
    "\n",
    "from scipy.stats import hypergeom\n",
    "from scipy.stats import rankdata\n",
    "import numpy as np\n",
    "\n",
    "# Your test types for CTX_GABA\n",
    "test_GABA = ['046 Vip Gaba', '053 Sst Gaba']\n",
    "\n",
    "# Check if sorted_CTX_GABA exists and get its length\n",
    "if 'sorted_CTX_GABA' in locals() or 'sorted_CTX_GABA' in globals():\n",
    "    N = len(sorted_CTX_GABA)  # Total number of CTX_GABA types\n",
    "    M = len(test_GABA)  # Number of test types (2)\n",
    "    \n",
    "    # Find positions of test types in sorted list (1-indexed for ranks)\n",
    "    test_positions = []\n",
    "    for t in test_GABA:\n",
    "        if t in sorted_CTX_GABA:\n",
    "            pos = sorted_CTX_GABA.index(t) + 1  # 1-indexed rank\n",
    "            test_positions.append(pos)\n",
    "        else:\n",
    "            print(f\"Warning: {t} not found in sorted_CTX_GABA\")\n",
    "    \n",
    "    if len(test_positions) == M:\n",
    "        print(f\"Total CTX_GABA types: {N}\")\n",
    "        print(f\"Test types: {test_GABA}\")\n",
    "        print(f\"Positions in ranked list: {test_positions}\")\n",
    "        print(f\"Mean rank: {np.mean(test_positions):.2f}\")\n",
    "        \n",
    "        # ===== OPTION 1: HYPERGEOMETRIC TEST =====\n",
    "        # Tests: \"Are the test types overrepresented in top K positions?\"\n",
    "        # Best when: You have a specific cutoff K (e.g., top 5, top 10)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"HYPERGEOMETRIC TEST - CTX_GABA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Test multiple K values (top K positions)\n",
    "        for K in [2, 3, 5, 10]:\n",
    "            # Count how many test types are in top K\n",
    "            observed = sum(1 for pos in test_positions if pos <= K)\n",
    "            \n",
    "            # Hypergeometric test: P(X >= observed)\n",
    "            # Parameters: N (population), M (successes in population), K (sample size)\n",
    "            p_value = hypergeom.sf(observed - 1, N, M, K)  # sf = survival function (1 - cdf)\n",
    "            \n",
    "            print(f\"\\nTop {K} positions:\")\n",
    "            print(f\"  Observed test types in top {K}: {observed}/{M}\")\n",
    "            print(f\"  Expected by chance: {M * K / N:.2f}\")\n",
    "            print(f\"  P-value (one-tailed): {p_value:.4e}\")\n",
    "            if p_value < 0.05:\n",
    "                print(f\"  *** Significant enrichment! ***\")\n",
    "        \n",
    "        # ===== OPTION 2: PERMUTATION TEST =====\n",
    "        # Tests: \"Do the test types have unusually high ranks?\"\n",
    "        # Best when: You want to test rank-based statistics without fixed cutoff\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PERMUTATION TEST - CTX_GABA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        n_permutations = 10000\n",
    "        observed_mean_rank = np.mean(test_positions)\n",
    "        \n",
    "        # Generate null distribution by permuting ranks\n",
    "        null_mean_ranks = []\n",
    "        for _ in range(n_permutations):\n",
    "            # Randomly select 2 positions from 1 to N\n",
    "            random_positions = np.random.choice(range(1, N+1), size=M, replace=False)\n",
    "            null_mean_ranks.append(np.mean(random_positions))\n",
    "        \n",
    "        null_mean_ranks = np.array(null_mean_ranks)\n",
    "        \n",
    "        # Calculate p-value: proportion of permutations with mean rank <= observed\n",
    "        p_value_perm = np.mean(null_mean_ranks <= observed_mean_rank)\n",
    "        \n",
    "        print(f\"\\nObserved mean rank: {observed_mean_rank:.2f}\")\n",
    "        print(f\"Expected mean rank (null): {np.mean(null_mean_ranks):.2f}\")\n",
    "        print(f\"P-value (one-tailed): {p_value_perm:.4e}\")\n",
    "        if p_value_perm < 0.05:\n",
    "            print(f\"  *** Significant enrichment! ***\")\n",
    "        \n",
    "        # ===== SUM OF RANKS TEST =====\n",
    "        # Tests: \"Is the sum of ranks lower than expected?\" (lower sum = better ranks)\n",
    "        # This is equivalent to mean rank but sometimes more intuitive\n",
    "        \n",
    "        observed_sum_rank = np.sum(test_positions)\n",
    "        \n",
    "        # Generate null distribution for sum of ranks\n",
    "        null_sum_ranks = []\n",
    "        for _ in range(n_permutations):\n",
    "            random_positions = np.random.choice(range(1, N+1), size=M, replace=False)\n",
    "            null_sum_ranks.append(np.sum(random_positions))\n",
    "        \n",
    "        null_sum_ranks = np.array(null_sum_ranks)\n",
    "        \n",
    "        # Calculate p-value: proportion of permutations with sum rank <= observed\n",
    "        # Lower sum = better (both types higher up), so we test P(sum <= observed)\n",
    "        p_value_sum = np.mean(null_sum_ranks <= observed_sum_rank)\n",
    "        \n",
    "        print(f\"\\n\" + \"-\"*60)\n",
    "        print(f\"SUM OF RANKS TEST - CTX_GABA\")\n",
    "        print(f\"-\"*60)\n",
    "        print(f\"Observed sum of ranks: {observed_sum_rank}\")\n",
    "        print(f\"Expected sum of ranks (null): {np.mean(null_sum_ranks):.2f}\")\n",
    "        print(f\"P-value (one-tailed, testing if sum <= observed): {p_value_sum:.4e}\")\n",
    "        if p_value_sum < 0.05:\n",
    "            print(f\"  *** Significant enrichment! ***\")\n",
    "        print(f\"\\nNote: Lower sum = better ranks. Testing if sum_rank <= observed_sum_rank\")\n",
    "        print(f\"      This is equivalent to testing mean rank, but sum can be more intuitive.\")\n",
    "        \n",
    "        # Also test: Are both types in top K? (more stringent)\n",
    "        print(f\"\\nTesting if BOTH types are in top positions:\")\n",
    "        for K in [2, 3, 5]:\n",
    "            both_in_top = all(pos <= K for pos in test_positions)\n",
    "            # Permutation test: probability that 2 random types both fall in top K\n",
    "            null_both_in_top = []\n",
    "            for _ in range(n_permutations):\n",
    "                random_positions = np.random.choice(range(1, N+1), size=M, replace=False)\n",
    "                null_both_in_top.append(all(pos <= K for pos in random_positions))\n",
    "            p_both = np.mean(null_both_in_top)\n",
    "            \n",
    "            print(f\"  Top {K}: Both in top? {both_in_top}, P-value: {p_both:.4e}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RECOMMENDATION:\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\"\"\n",
    "        Use HYPERGEOMETRIC TEST if:\n",
    "        - You have a specific biological cutoff (e.g., \"top 5 most biased types\")\n",
    "        - You want exact p-values\n",
    "        - You're testing enrichment in a specific region of the ranking\n",
    "        \n",
    "        Use PERMUTATION TEST if:\n",
    "        - You want to test overall rank enrichment without fixed cutoff\n",
    "        - You want more flexibility in test statistics\n",
    "        - You're comfortable with approximate p-values\n",
    "        \n",
    "        For your case (testing if 2 types are at the \"top\"), I recommend:\n",
    "        1. Hypergeometric test with K=5 or K=10 (most interpretable)\n",
    "        2. Permutation test for mean rank (more flexible, no cutoff needed)\n",
    "        \"\"\")\n",
    "    else:\n",
    "        print(f\"Error: Only found {len(test_positions)}/{M} test types in sorted_CTX_GABA\")\n",
    "        print(f\"Found positions: {test_positions}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Error: sorted_CTX_GABA not found. Please run the cell that creates it first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.1820e-01 * 2.2000e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data generation (using the provided example structure)\n",
    "Subclass = sorted(Subclass2Cluster.keys())\n",
    "CNU_HYa_Glut = Subclass[58:65]+Subclass[36:45]\n",
    "dat = []\n",
    "for _CT in CNU_HYa_Glut:\n",
    "    dat.append([x for x in ASD_BiasDN_z1clip3_addP.loc[Subclass2Cluster[_CT], \"EFFECT\"].values if x==x])\n",
    "\n",
    "# Calculate medians and sort data based on medians\n",
    "medians = [np.median(d) for d in dat]\n",
    "sorted_indices = np.argsort(medians)[::-1]\n",
    "sorted_dat = [dat[i] for i in sorted_indices]\n",
    "sorted_CNU_HYa_Glut = [CNU_HYa_Glut[i] for i in sorted_indices]\n",
    "\n",
    "# Set up the plotting style and context\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(dpi=480, figsize=(7, 4))  # Adjust the figure size as needed\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(data=sorted_dat, orient='h', ax=ax, palette='deep')\n",
    "\n",
    "# Set the labels\n",
    "ax.set_xlabel(\"ASD Bias\", fontsize=16, weight='bold')\n",
    "ax.set_yticklabels(sorted_CNU_HYa_Glut, fontsize=12)\n",
    "\n",
    "# Improve grid and layout\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Customize the ticks\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data generation (using the provided example structure)\n",
    "Subclass = sorted(Subclass2Cluster.keys())\n",
    "CNU_HYa_Glut = Subclass[73:91] + Subclass[110:122]\n",
    "dat = []\n",
    "for _CT in CNU_HYa_Glut:\n",
    "    dat.append([x for x in ASD_BiasDN_z1clip3_addP.loc[Subclass2Cluster[_CT], \"EFFECT\"].values if x==x])\n",
    "\n",
    "# Calculate medians and sort data based on medians\n",
    "medians = [np.median(d) for d in dat]\n",
    "sorted_indices = np.argsort(medians)[::-1]\n",
    "sorted_dat = [dat[i] for i in sorted_indices]\n",
    "sorted_CNU_HYa_Glut = [CNU_HYa_Glut[i] for i in sorted_indices]\n",
    "\n",
    "# Set up the plotting style and context\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(dpi=480, figsize=(8, 8))  # Adjust the figure size as needed\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(data=sorted_dat, orient='h', ax=ax, palette='deep')\n",
    "\n",
    "# Set the labels\n",
    "ax.set_xlabel(\"ASD Bias\", fontsize=16, weight='bold')\n",
    "ax.set_yticklabels(sorted_CNU_HYa_Glut, fontsize=12)\n",
    "\n",
    "# Improve grid and layout\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Customize the ticks\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data generation (using the provided example structure)\n",
    "Subclass = sorted(Subclass2Cluster.keys())\n",
    "CNU_HYa_Glut = Subclass[73:91]\n",
    "dat = []\n",
    "for _CT in CNU_HYa_Glut:\n",
    "    dat.append([x for x in ASD_BiasDN_z1clip3_addP.loc[Subclass2Cluster[_CT], \"EFFECT\"].values if x==x])\n",
    "\n",
    "# Calculate medians and sort data based on medians\n",
    "medians = [np.median(d) for d in dat]\n",
    "sorted_indices = np.argsort(medians)[::-1]\n",
    "sorted_dat = [dat[i] for i in sorted_indices]\n",
    "sorted_CNU_HYa_Glut = [CNU_HYa_Glut[i] for i in sorted_indices]\n",
    "\n",
    "# Set up the plotting style and context\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(dpi=480, figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(data=sorted_dat, orient='h', ax=ax, palette='deep')\n",
    "\n",
    "# Set the labels\n",
    "ax.set_xlabel(\"ASD Bias\", fontsize=16, weight='bold')\n",
    "ax.set_yticklabels(sorted_CNU_HYa_Glut, fontsize=12)\n",
    "\n",
    "# Improve grid and layout\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Customize the ticks\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data generation (using the provided example structure)\n",
    "Subclass = sorted(Subclass2Cluster.keys())\n",
    "CNU_HYa_Glut = Subclass[146:154] +  Subclass[58:65] + Subclass[36:39]\n",
    "dat = []\n",
    "for _CT in CNU_HYa_Glut:\n",
    "    dat.append([x for x in ASD_BiasDN_z1clip3_addP.loc[Subclass2Cluster[_CT], \"EFFECT\"].values if x==x])\n",
    "\n",
    "# Calculate medians and sort data based on medians\n",
    "medians = [np.median(d) for d in dat]\n",
    "sorted_indices = np.argsort(medians)[::-1]\n",
    "sorted_dat = [dat[i] for i in sorted_indices]\n",
    "sorted_CNU_HYa_Glut = [CNU_HYa_Glut[i] for i in sorted_indices]\n",
    "\n",
    "# Set up the plotting style and context\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(dpi=480, figsize=(8, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(data=sorted_dat, orient='h', ax=ax, palette='deep')\n",
    "\n",
    "# Set the labels\n",
    "ax.set_xlabel(\"ASD Bias\", fontsize=16, weight='bold')\n",
    "ax.set_yticklabels(sorted_CNU_HYa_Glut, fontsize=12)\n",
    "\n",
    "# Improve grid and layout\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Customize the ticks\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "# F (STR vs CT Mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "MERFISH = pd.read_csv(\"dat/MERFISH/MERFISH.cells.ASD.Bias.Anno.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Circuits_cleannames = [\" \".join(x.split(\"_\")) for x in ASD_Circuits]\n",
    "#ASD_Circuits_cleannames.append(\"Subiculum\")\n",
    "ASD_Circuits_cleannames.remove(\"Subiculum ventral part\")\n",
    "ASD_Circuits_cleannames.remove(\"Subiculum dorsal part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MERFISH_Circuit = MERFISH[MERFISH[\"ISH_STR\"].isin(ASD_Circuits_cleannames)]\n",
    "MERFISH_Circuit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = MERFISH_Circuit[\"class\"].value_counts()\n",
    "class_counts = class_counts[class_counts>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(dpi=300, figsize=(6, 6))\n",
    "class_counts.plot(kind='bar', color='grey')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Cell Class', fontsize=14, weight='bold')\n",
    "plt.ylabel('Number of Cells in ASD Circuit', fontsize=14, weight='bold')\n",
    "#plt.title('Bar Plot from Pandas Series', fontsize=14)\n",
    "plt.yscale('log')  # Set y-axis to log scale\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Cir_Clusters = set(MERFISH_Circuit[\"cluster\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Cluster_Bias_for_DN = pd.read_csv(\"dat/Bias/ASD.ClusterV3.top60.UMI.Z2.z1clip3.addP.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cir_ASD_Cluster_Bias_for_DN_sub = ASD_Cluster_Bias_for_DN[ASD_Cluster_Bias_for_DN.index.isin(ASD_Cir_Clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate ASD Bias\n",
    "for i, row in MERFISH_Circuit.iterrows():\n",
    "    cluster = row[\"cluster\"]\n",
    "    if cluster not in ASD_Cluster_Bias_for_DN.index.values:\n",
    "        MERFISH_Circuit.loc[i, \"ASD.Bias\"] = 0\n",
    "    else:\n",
    "        MERFISH_Circuit.loc[i, \"ASD.Bias\"] = ASD_Cluster_Bias_for_DN.loc[cluster, \"EFFECT\"]\n",
    "    #MERFISH_Circuit.loc[i, \"SCZ.Bias.adj\"] = SCZ_Cluster_Bias_for_DN.loc[cluster, \"Bias_Adj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = MERFISH_Circuit[\"cluster\"].value_counts()\n",
    "cluster_counts = cluster_counts[cluster_counts>50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts_df = pd.DataFrame(cluster_counts)\n",
    "cluster_counts_df.columns = ['Count']\n",
    "cluster_counts_df.index.name = 'Cluster'\n",
    "cluster_counts_df.to_csv(\"dat/ASD.Cluster.Count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_counts = MERFISH_Circuit[\"subclass\"].value_counts()\n",
    "subclass_counts = subclass_counts[subclass_counts>500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_str_subclass_bias_dat = []\n",
    "for STR_ in ASD_Circuits_cleannames:\n",
    "    tmp = MERFISH_Circuit[MERFISH_Circuit[\"ISH_STR\"]==STR_]\n",
    "    _str_subclass_bias_dat = []\n",
    "    for subclass,n in subclass_counts.items():\n",
    "        tmptmp = tmp[tmp[\"subclass\"]==subclass]\n",
    "        if tmptmp.shape[0] == 0:\n",
    "            _str_subclass_bias_dat.append(0)\n",
    "        else:\n",
    "            _str_subclass_bias_dat.append(np.nanmean(tmptmp[\"ASD.Bias\"].values))\n",
    "            #_str_subclass_bias_dat.append(np.nanmean(tmptmp[\"SCZ.Bias.1000\"].values))\n",
    "    asd_str_subclass_bias_dat.append(_str_subclass_bias_dat)\n",
    "asd_str_subclass_bias_dat = np.array(asd_str_subclass_bias_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Subclass_STR_Bias_DF = pd.DataFrame(data=asd_str_subclass_bias_dat, index=ASD_Circuits_cleannames, \n",
    "                                    columns=subclass_counts.index.values)\n",
    "Subclass_STR_Bias_DF = Subclass_STR_Bias_DF.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_dat_v1 = []\n",
    "subclass_dat_v2 = []\n",
    "for STR_ in ASD_Circuits_cleannames:\n",
    "    tmp = MERFISH_Circuit[MERFISH_Circuit[\"ISH_STR\"]==STR_]\n",
    "    print(STR_, tmp.shape)\n",
    "    str_subclass_frac_dat_1 = []\n",
    "    str_subclass_frac_dat_2 = []\n",
    "    for subclass_,n in subclass_counts.items():\n",
    "        tmptmp = tmp[tmp[\"subclass\"]==subclass_]\n",
    "        n_cell = tmptmp.shape[0]\n",
    "        frac_cell_1 = n_cell/n\n",
    "        frac_cell_2 = n_cell/tmp.shape[0]\n",
    "        str_subclass_frac_dat_1.append(frac_cell_1)\n",
    "        str_subclass_frac_dat_2.append(frac_cell_2)\n",
    "    subclass_dat_v1.append(str_subclass_frac_dat_1)\n",
    "    subclass_dat_v2.append(str_subclass_frac_dat_2)\n",
    "subclass_dat_v1 = np.array(subclass_dat_v1)\n",
    "subclass_dat_v2 = np.array(subclass_dat_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "##### Get Region composition of sublcass cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_STR_Bias.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "MERFISH_Circuit.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "##### Get STR composition of sublcass cell types and plot biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "SubclassCellComp = pd.DataFrame(data=subclass_dat_v2, index=ASD_Circuits_cleannames, columns=subclass_counts.index.values)\n",
    "SubclassCellComp = SubclassCellComp.transpose()\n",
    "SubclassCellComp = SubclassCellComp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cir_ISH_Bias = ASD_STR_Bias[ASD_STR_Bias.index.isin(ASD_Circuits)]\n",
    "Cir_ISH_Bias_sorted = Cir_ISH_Bias.sort_values(by=['REGION', 'EFFECT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_Sort_Names = []\n",
    "RegionSorts = [\"Isocortex\", \"Olfactory_areas\", \"Cortical_subplate\", \"Hippocampus\", \"Striatum\", \n",
    "           \"Amygdala\", \"Pallidum\", \"Thalamus\", \"Midbrain\"]\n",
    "STR_Reg = {}\n",
    "for REG in RegionSorts:\n",
    "    tmp = Cir_ISH_Bias[Cir_ISH_Bias[\"REGION\"]==REG]\n",
    "    ShortNames = [\" \".join(x.split(\"_\")) for x in tmp.index.values]\n",
    "    for XX in ShortNames:\n",
    "        STR_Reg[XX] = REG\n",
    "    STR_Sort_Names.extend(ShortNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegionSorts = [\"Isocortex\", \"Olfactory_areas\", \"Cortical_subplate\", \"Hippocampus\", \"Striatum\", \n",
    "           \"Amygdala\", \"Pallidum\", \"Thalamus\", \"Midbrain\"]\n",
    "Colors = [\"#0098D4\", \"#783F04\", \"#9FC5E8\", \"#6AA84F\", \"#E69138\", \"#674EA7\", \n",
    "         \"#674EA7\", \"#F44336\", \"#783F04\"]\n",
    "region_colors = dict(zip(RegionSorts, Colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df = Subclass_STR_Bias_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "SubclassCellComp.to_csv(\"dat/ASD.Cir.SubClassCellComp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Subclass_STR_Bias_DF.to_csv(\"dat/ASD.Cir.SubClassBias.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "SubclassCellComp = pd.read_csv(\"dat/ASD.Cir.SubClassCellComp.csv\", index_col=0)\n",
    "Subclass_STR_Bias_DF = pd.read_csv(\"dat/ASD.Cir.SubClassBias.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_STR_Bias[\"REGION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = SubclassCellComp.index\n",
    "y_labels = STR_Sort_Names \n",
    "y_labels = y_labels[::-1]\n",
    "\n",
    "# # Prepare data for scatter plot\n",
    "# x = []\n",
    "# y = []\n",
    "# sizes = []\n",
    "# colors = []\n",
    "\n",
    "# norm = plt.Normalize(-0.6, 0.6)\n",
    "\n",
    "# sm = plt.cm.ScalarMappable(cmap=\"coolwarm\", norm=norm)\n",
    "# sm.set_array([])\n",
    "\n",
    "# for i, structure  in enumerate(x_labels):\n",
    "#     for j, cell_type in enumerate(y_labels):\n",
    "#         x.append(i)\n",
    "#         y.append(j)\n",
    "#         #sizes.append(SubclassCellComp.loc[structure, cell_type] * 3500)  # Scale up the sizes for better visualization\n",
    "#         sizes.append(size_transform(SubclassCellComp.loc[structure, cell_type]))\n",
    "#         bias_value = bias_df.loc[structure, cell_type]\n",
    "#         colors.append(sm.to_rgba(bias_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "code_folding": [
     0,
     5,
     11
    ]
   },
   "outputs": [],
   "source": [
    "regions = ['Isocortex','Olfactory_areas', 'Cortical_subplate', \n",
    "               'Hippocampus','Amygdala','Striatum', \n",
    "               \"Thalamus\", \"Hypothalamus\", \"Midbrain\", \n",
    "               \"Medulla\", \"Pallidum\", \"Pons\", \n",
    "               \"Cerebellum\"]\n",
    "region_colors = dict(zip(regions, [\"#268ad5\", \"#D5DBDB\", \"#7ac3fa\", \n",
    "                                 \"#2c9d39\", \"#742eb5\", \"#ed8921\", \n",
    "                                 \"#e82315\", \"#E6B0AA\", \"#f6b26b\",  \n",
    "                                 \"#20124d\", \"#2ECC71\", \"#D2B4DE\", \n",
    "                                 \"#ffd966\", ]))\n",
    "y_region_seq = [ASD_STR_Bias.loc[\"_\".join(x.split()), \"REGION\"] for x in y_labels]\n",
    "def shorten_name(x):\n",
    "    if x ==\"Lateral septal nucleus rostral rostroventral part\":\n",
    "        return \"Lateral septal nucleus\"\n",
    "    else:\n",
    "        return x\n",
    "def size_transform(comp):\n",
    "    if comp ==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 100 + comp * 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_transform(comp):\n",
    "    if comp ==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 100 + comp * 2500\n",
    "comp = [0.001, 0.01, 0.1, 0.5]\n",
    "size_of_comps = [size_transform(x) for x in comp]\n",
    "\n",
    "fig,  ax = plt.subplots(dpi=480, figsize=(40, 28))\n",
    "\n",
    "# Plot scatter points for each `comp` value with corresponding sizes\n",
    "for i, (c, size) in enumerate(zip(comp, size_of_comps)):\n",
    "    ax.scatter([], [], s=size, label=f'comp = {c}')\n",
    "\n",
    "# Create the legend\n",
    "ax.legend(loc='center', bbox_to_anchor=(0.5, 0.5), fontsize=12, frameon=False)\n",
    "\n",
    "# Remove axes for a cleaner look\n",
    "ax.axis('off')\n",
    "\n",
    "# Adjust layout and show the legend\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = SubclassCellComp.index\n",
    "y_labels = STR_Sort_Names \n",
    "y_labels = y_labels[::-1]\n",
    "\n",
    "# Prepare data for scatter plot\n",
    "x = []\n",
    "y = []\n",
    "sizes = []\n",
    "colors = []\n",
    "\n",
    "norm = plt.Normalize(-0.6, 0.6)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=\"coolwarm\", norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "for i, structure  in enumerate(x_labels):\n",
    "    for j, cell_type in enumerate(y_labels):\n",
    "        x.append(i)\n",
    "        y.append(j)\n",
    "        #sizes.append(SubclassCellComp.loc[structure, cell_type] * 3500)  # Scale up the sizes for better visualization\n",
    "        sizes.append(size_transform(SubclassCellComp.loc[structure, cell_type]))\n",
    "        bias_value = bias_df.loc[structure, cell_type]\n",
    "        colors.append(sm.to_rgba(bias_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['Isocortex','Olfactory_areas', 'Cortical_subplate', \n",
    "               'Hippocampus','Amygdala','Striatum', \n",
    "               \"Thalamus\", \"Hypothalamus\", \"Midbrain\", \n",
    "               \"Medulla\", \"Pallidum\", \"Pons\", \n",
    "               \"Cerebellum\"]\n",
    "region_colors = dict(zip(regions, [\"#268ad5\", \"#D5DBDB\", \"#7ac3fa\", \n",
    "                                 \"#2c9d39\", \"#742eb5\", \"#ed8921\", \n",
    "                                 \"#e82315\", \"#E6B0AA\", \"#f6b26b\",  \n",
    "                                 \"#20124d\", \"#2ECC71\", \"#D2B4DE\", \n",
    "                                 \"#ffd966\", ]))\n",
    "y_region_seq = [ASD_STR_Bias.loc[\"_\".join(x.split()), \"REGION\"] for x in y_labels]\n",
    "def shorten_name(x):\n",
    "    if x ==\"Lateral septal nucleus rostral rostroventral part\":\n",
    "        return \"Lateral septal nucleus\"\n",
    "    else:\n",
    "        return x\n",
    "def size_transform(comp):\n",
    "    if comp ==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 100 + comp * 2500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,  ax = plt.subplots(dpi=480, figsize=(50, 28))\n",
    "\n",
    "# Scatter plot\n",
    "scatter = ax.scatter(x, y, s=sizes, alpha=0.8, c=colors)\n",
    "\n",
    "# Prepare y-labels with extra space\n",
    "\n",
    "y_labels2 = [\"{}     \".format(shorten_name(x)) for x in y_labels]\n",
    "ax.set_xticks(np.arange(len(x_labels)))\n",
    "ax.set_xticklabels(x_labels, rotation=90, fontsize=30)\n",
    "ax.set_yticks(np.arange(len(y_labels)))\n",
    "ax.set_yticklabels(y_labels2, fontsize=42)\n",
    "\n",
    "# Adjust the layout to give more space for y-tick labels\n",
    "plt.subplots_adjust(left=0.15, right=0.9, top=0.95, bottom=0.15)  # Increase 'left' to give more space for y-tick labels\n",
    "\n",
    "# Add the region color column as a new axis\n",
    "ax_region = fig.add_axes([0.135, 0.15, 0.01, 0.79])  # Adjust the position of the region bar\n",
    "\n",
    "ax_region.set_yticks(np.arange(len(y_labels)))\n",
    "ax_region.set_yticklabels([])  # No labels, just colors\n",
    "ax_region.set_xticklabels([])\n",
    "ax_region.tick_params(left=False, right=False)  # No ticks\n",
    "\n",
    "# Color each y-tick according to its region\n",
    "for i, region in enumerate(y_region_seq):\n",
    "    if region == \"Amygdalar\":\n",
    "        region = \"Amygdala\"\n",
    "    ax_region.add_patch(plt.Rectangle((0, i - 0.5), 1, 1, color=region_colors[region]))\n",
    "\n",
    "# Add marker size legend for cell composition (marker and font 50% larger)\n",
    "ax.scatter([], [], s=0, label='Cell composition', color=\"grey\")\n",
    "for i, (c, size) in enumerate(zip(comp, size_of_comps)):\n",
    "    ax.scatter([], [], s=size * 1.5, label=f' : {c}', color=\"grey\")\n",
    "\n",
    "# Create the legend\n",
    "ax.legend(loc='center', bbox_to_anchor=(1.1, -0.1), fontsize=52, frameon=False)\n",
    "\n",
    "# Adjust the grid and spines\n",
    "ax.grid(True, linestyle='--', alpha=0.1)\n",
    "ax.set_xlim(-0.5, len(x_labels))\n",
    "ax.set_ylim(-0.5, len(y_labels))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"../results/figs/ASD_top60_SubClass_CellCompBias_with_regions.pdf\", bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "region_colors2 = {'Isocortex': '#268ad5',\n",
    " 'Olfactory areas': '#D5DBDB',\n",
    " 'Cortical subplate': '#7ac3fa',\n",
    " 'Hippocampus': '#2c9d39',\n",
    " 'Amygdala': '#742eb5',\n",
    " 'Striatum': '#ed8921',\n",
    " 'Thalamus': '#e82315',\n",
    " 'Midbrain': '#f6b26b',\n",
    " 'Pallidum': '#2ECC71',}\n",
    "\n",
    "# Create a figure for the legend\n",
    "fig, ax = plt.subplots(dpi=360, figsize=(10, 6))\n",
    "\n",
    "# Create patches for each region\n",
    "patches = [mpatches.Patch(color=color, label=region) for region, color in region_colors2.items()]\n",
    "\n",
    "# Add the legend to the plot and make it take up the whole figure\n",
    "ax.legend(handles=patches, loc='center', ncol=2, fontsize=50, frameon=False,\n",
    "          bbox_to_anchor=(0.5, 0.5), bbox_transform=plt.gcf().transFigure)\n",
    "\n",
    "# Remove axes for a cleaner look\n",
    "ax.axis('off')\n",
    "\n",
    "# Adjust layout to remove any padding\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "\n",
    "# Show the legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=200, figsize=(35, 20))\n",
    "\n",
    "scatter = ax.scatter(x, y, s=sizes, alpha=0.8, c=colors)\n",
    "\n",
    "y_labels2 = [\"{}    \".format(x) for x in y_labels]\n",
    "ax.set_xticks(np.arange(len(x_labels)))\n",
    "ax.set_xticklabels(x_labels, rotation=90, fontsize=25)\n",
    "ax.set_yticks(np.arange(len(y_labels)))\n",
    "ax.set_yticklabels(y_labels2, fontsize=30)\n",
    "\n",
    "for tick in plt.gca().get_yticklabels():\n",
    "    tick.set_verticalalignment('center')\n",
    "    tick.set_multialignment('center')\n",
    "\n",
    "ax.grid(True, linestyle='--', alpha=0.1)\n",
    "ax.set_xlim(-0.5, len(x_labels))\n",
    "ax.set_ylim(-0.5, len(y_labels))\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Add colorbar for bias values\n",
    "cbar = plt.colorbar(sm, orientation=\"vertical\")\n",
    "cbar.set_label('Bias', fontsize=25)\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.15)\n",
    "plt.savefig(\"figs/ASD_top60_SubClass_CellCompBias.v2.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ModifySTRName(STR_Names):\n",
    "    res = []\n",
    "    for Name in STR_Names:\n",
    "        tokens = Name.split()\n",
    "        len_token = len(tokens)\n",
    "        if len(Name) > 10 and len_token > 1:\n",
    "            len_token = len(tokens)\n",
    "            #print(tokens, len_token)\n",
    "            break_point = int(len_token/2)\n",
    "            line1 = tokens[:break_point]\n",
    "            line2 = tokens[break_point:]\n",
    "            NewName = \"{}\\n{}\".format(\" \".join(line1), \" \".join(line2))\n",
    "        else:\n",
    "            NewName = Name\n",
    "        res.append(NewName)\n",
    "    return res\n",
    "y_labels2 = ModifySTRName(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_ct_neur_comps = []\n",
    "dat_ct_neur_bias = []\n",
    "dat_ct_glia_comps = []\n",
    "dat_ct_glia_bias = []\n",
    "for i, str in enumerate(SubclassCellComp.columns.values):\n",
    "    #print(str)\n",
    "    list_ct = SubclassCellComp.index.values\n",
    "    NN = [x for x in list_ct if x.endswith(\"NN\")]\n",
    "    NEU = [x for x in list_ct if not x.endswith(\"NEU\")]\n",
    "    str_ct_neur_comps = SubclassCellComp.loc[NEU, str]\n",
    "    str_ct_neur_bias = bias_df.loc[NEU, str]\n",
    "    str_ct_glia_comps = SubclassCellComp.loc[NN, str]\n",
    "    str_ct_glia_bias = bias_df.loc[NN, str]\n",
    "    \n",
    "    dat_ct_neur_comps.extend(str_ct_neur_comps)\n",
    "    dat_ct_neur_bias.extend(str_ct_neur_bias)\n",
    "    dat_ct_glia_comps.extend(str_ct_glia_comps)\n",
    "    dat_ct_glia_bias.extend(str_ct_glia_bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation coefficients\n",
    "r_neur, p_neur = pearsonr(dat_ct_neur_comps, dat_ct_neur_bias)\n",
    "r_non_neur, p_non_neur = pearsonr(dat_ct_glia_comps, dat_ct_glia_bias)\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 7), dpi=120)  # Increased figure size\n",
    "\n",
    "# Plot neurons\n",
    "plt.scatter(dat_ct_neur_comps, dat_ct_neur_bias, alpha=0.6, edgecolors='w', color='blue', label='Neurons', s=50)  # Increased marker size\n",
    "\n",
    "# Plot glia\n",
    "plt.scatter(dat_ct_glia_comps, dat_ct_glia_bias, alpha=0.6, edgecolors='w', color='red', label='Non-Neurons', s=50)  # Increased marker size\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Cell Composition Bias\", fontsize=18)  # Increased font size\n",
    "plt.ylabel(\"Cell Type Bias\", fontsize=18)  # Increased font size\n",
    "plt.title(\"Cell Composition vs Cell Type Bias\", fontsize=20)  # Increased font size\n",
    "\n",
    "# Add correlation information to the plot\n",
    "plt.text(0.55, 0.25, f\"Neurons: r={r_neur:.3f}, p={p_neur:.1e}\", transform=plt.gca().transAxes, fontsize=14, color='blue')  # Increased font size\n",
    "plt.text(0.55, 0.20, f\"Non-Neurons: r={r_non_neur:.3f}, p={p_non_neur:.1e}\", transform=plt.gca().transAxes, fontsize=14, color='red')  # Increased font size\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=16)  # Increased font size\n",
    "\n",
    "# Add grid and improve layout\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Increase tick label font size\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "SubclassCellComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "# Test Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Sibling\n",
    "ScoreMatDir=\"/home/jw3514/Work/ASD_Circuits/dat/allen-mouse-conn/ScoreingMat_jw_v3/\"\n",
    "IpsiInfoMat=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.csv\", index_col=0)\n",
    "IpsiInfoMatShort_v1=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.Short.3900.csv\", index_col=0)\n",
    "IpsiInfoMatLong_v1=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.Long.3900.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixSubiculum_reverse(DF):\n",
    "    Z = DF.loc[\"Subiculum\"]\n",
    "    DF.loc[\"Subiculum_dorsal_part\", :] = Z\n",
    "    DF.loc[\"Subiculum_ventral_part\", :] = Z\n",
    "    DF = DF.drop([\"Subiculum\"])\n",
    "    DF = DF.sort_values(\"EFFECT\", ascending=False)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Bias_MERFISH_STR_Z2_CM = pd.read_csv(\"dat/Bias/STR/ASD.MERFISH_Allen.CM.ISHMatch.Z2.csv\", index_col=0)\n",
    "ASD_Bias_MERFISH_STR_Z2_VM = pd.read_csv(\"dat/Bias/STR/ASD.MERFISH_Allen.VM.ISHMatch.Z2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Bias_MERFISH_STR_Z2_CM = FixSubiculum_reverse(ASD_Bias_MERFISH_STR_Z2_CM)\n",
    "ASD_Bias_MERFISH_STR_Z2_VM = FixSubiculum_reverse(ASD_Bias_MERFISH_STR_Z2_VM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Bias_MERFISH_STR_Z2_VM.to_csv(\"dat/Bias/STR/ASD.MERFISH_Allen.VM.ISHMatch.Z2.splitSB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = pd.read_csv(\"dat/Bias/STR/ASD.MERFISH_Allen.NM.ISHMatch.Z2.csv\", index_col=0)\n",
    "XX = ASD_Bias_MERFISH_STR_Z2_VM = FixSubiculum_reverse(XX)\n",
    "XX.to_csv(\"dat/Bias/STR/ASD.MERFISH_Allen.NM.ISHMatch.Z2.splitSB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASD_159_bias = pd.read_csv(\"../../ASD_Circuits/dat/Unionize_bias/ASD.159.pLI.z2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASD_159_bias.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_Ranks = ASD_Bias_MERFISH_STR_Z2_CM.index.values\n",
    "#STR_Ranks = ASD_Bias.index.values\n",
    "topNs = list(range(200, 5, -1))\n",
    "SC_Agg_topN_score = []\n",
    "SC_Agg_topN_scoreShort = []\n",
    "SC_Agg_topN_scoreLong = []\n",
    "for topN in topNs:\n",
    "    top_strs = STR_Ranks[:topN]\n",
    "    score = ScoreCircuit_SI_Joint(top_strs, IpsiInfoMat)\n",
    "    scoreShort = ScoreCircuit_SI_Joint(top_strs, IpsiInfoMatShort_v1)\n",
    "    scoreLong = ScoreCircuit_SI_Joint(top_strs, IpsiInfoMatLong_v1)\n",
    "    SC_Agg_topN_score.append(score)\n",
    "    SC_Agg_topN_scoreShort.append(scoreShort)\n",
    "    SC_Agg_topN_scoreLong.append(scoreLong)\n",
    "SC_Agg_topN_score = np.array(SC_Agg_topN_score)\n",
    "SC_Agg_topN_scoreShort = np.array(SC_Agg_topN_scoreShort)\n",
    "SC_Agg_topN_scoreLong = np.array(SC_Agg_topN_scoreLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "topNs = np.arange(200, 5, -1)\n",
    "DIR = \"/home/jw3514/Work/ASD_Circuits/scripts/RankScores\"\n",
    "Cont_Distance = np.load(\"{}/RankScore.Ipsi.Cont.npy\".format(DIR))\n",
    "Cont_DistanceShort = np.load(\"{}/RankScore.Ipsi.Short.3900.Cont.npy\".format(DIR))\n",
    "Cont_DistanceLong = np.load(\"{}/RankScore.Ipsi.Long.3900.Cont.npy\".format(DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, obs, obs1, obs2 in list(zip(topNs, SC_Agg_topN_score, SC_Agg_topN_scoreShort, SC_Agg_topN_scoreLong)):\n",
    "    if n < 60:\n",
    "        Null = Cont_Distance[:, np.where(topNs==n)].flatten()\n",
    "        z, p = GetPermutationP(Null, obs)\n",
    "        \n",
    "        Null = Cont_DistanceShort[:, np.where(topNs==n)].flatten()\n",
    "        z1, p1 = GetPermutationP(Null, obs1)\n",
    "        \n",
    "        Null = Cont_DistanceLong[:, np.where(topNs==n)].flatten()\n",
    "        z2, p2 = GetPermutationP(Null, obs2)\n",
    "        print(\"%d %.3f %.4f %.4f %.4f\"%(n, obs, p, p1, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1, dpi=480, figsize=(7,11))\n",
    "\n",
    "BarLen = 34.1\n",
    "#BarLen = 47.5\n",
    "\n",
    "cont = np.median(Cont_Distance, axis=0)\n",
    "ax1.plot(topNs, SC_Agg_topN_score, color=\"blue\", marker=\"o\", markersize=5, lw=1,\n",
    "                     ls=\"dashed\", label=\"ASD\\nProbands\")\n",
    "\n",
    "lower = np.percentile(Cont_Distance, 50-BarLen, axis=0)\n",
    "upper = np.percentile(Cont_Distance, 50+BarLen, axis=0)\n",
    "ax1.errorbar(topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "            yerr=(cont - lower, upper - cont ), ls=\"dashed\", label=\"Siblings\")\n",
    "ax1.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "ax1.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax1.legend(fontsize=13)\n",
    "\n",
    "cont = np.nanmean(Cont_DistanceLong, axis=0)\n",
    "ax2.plot(topNs, SC_Agg_topN_scoreLong, color=\"blue\", marker=\"o\", markersize=5, lw=1,\n",
    "                     ls=\"dashed\", label=\"ASD\\nProbands\")\n",
    "\n",
    "lower = np.nanpercentile(Cont_DistanceLong, 50-BarLen, axis=0)\n",
    "upper = np.nanpercentile(Cont_DistanceLong, 50+BarLen, axis=0)\n",
    "ax2.errorbar(topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "            yerr=(cont - lower, abs(upper - cont) ), ls=\"dashed\", label=\"Siblings\")\n",
    "ax2.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "ax2.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax2.legend(fontsize=13)\n",
    "\n",
    "cont = np.median(Cont_DistanceShort, axis=0)\n",
    "ax3.plot(topNs, SC_Agg_topN_scoreShort, color=\"blue\", marker=\"o\", markersize=5, lw=1,\n",
    "                     ls=\"dashed\", label=\"ASD\\nProbands\")\n",
    "\n",
    "lower = np.percentile(Cont_DistanceShort, 50-BarLen, axis=0)\n",
    "upper = np.percentile(Cont_DistanceShort, 50+BarLen, axis=0)\n",
    "ax3.errorbar(topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "            yerr=(cont - lower, upper - cont ), ls=\"dashed\", label=\"Siblings\")\n",
    "ax3.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "ax3.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax3.legend(fontsize=13)\n",
    "\n",
    "#fig.text(0.5, -0.03, 'Top Number of Structuress', ha='center')\n",
    "#fig.text(-0.03, 0.5, 'SI Score', va='center', rotation='vertical')\n",
    "ax1.set_xlim(0, 121)\n",
    "ax2.set_xlim(0, 121)\n",
    "ax3.set_xlim(0, 121)\n",
    "plt.tight_layout()\n",
    "#plt.legend(fontsize=15)\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "ax3.grid(True)\n",
    "#plt.savefig(\"../figs/main/Fig2.BCD.pdf\")\n",
    "#plt.savefig(\"../figs/main/Fig2.BCD.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Bias_MERFISH_STR_Z2_NM = XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_Ranks = ASD_Bias_MERFISH_STR_Z2_NM.index.values\n",
    "#STR_Ranks = ASD_Bias.index.values\n",
    "topNs = list(range(200, 5, -1))\n",
    "SC_Agg_topN_score = []\n",
    "SC_Agg_topN_scoreShort = []\n",
    "SC_Agg_topN_scoreLong = []\n",
    "for topN in topNs:\n",
    "    top_strs = STR_Ranks[:topN]\n",
    "    score = ScoreCircuit_SI_Joint(top_strs, IpsiInfoMat)\n",
    "    scoreShort = ScoreCircuit_SI_Joint(top_strs, IpsiInfoMatShort_v1)\n",
    "    scoreLong = ScoreCircuit_SI_Joint(top_strs, IpsiInfoMatLong_v1)\n",
    "    SC_Agg_topN_score.append(score)\n",
    "    SC_Agg_topN_scoreShort.append(scoreShort)\n",
    "    SC_Agg_topN_scoreLong.append(scoreLong)\n",
    "SC_Agg_topN_score = np.array(SC_Agg_topN_score)\n",
    "SC_Agg_topN_scoreShort = np.array(SC_Agg_topN_scoreShort)\n",
    "SC_Agg_topN_scoreLong = np.array(SC_Agg_topN_scoreLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cont_Distance[:, np.where(topNs==50)].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, obs, obs1, obs2 in list(zip(topNs, SC_Agg_topN_score, SC_Agg_topN_scoreShort, SC_Agg_topN_scoreLong)):\n",
    "    if n < 60:\n",
    "        Null = Cont_Distance[:, np.where(topNs==n)].flatten()\n",
    "        z, p = GetPermutationP(Null, obs)\n",
    "        \n",
    "        Null = Cont_DistanceShort[:, np.where(topNs==n)].flatten()\n",
    "        z1, p1 = GetPermutationP(Null, obs1)\n",
    "        \n",
    "        Null = Cont_DistanceLong[:, np.where(topNs==n)].flatten()\n",
    "        z2, p2 = GetPermutationP(Null, obs2)\n",
    "        print(\"%d %.3f %.4f %.4f %.4f\"%(n, obs, p, p1, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1, dpi=480, figsize=(7,11))\n",
    "\n",
    "BarLen = 34.1\n",
    "#BarLen = 47.5\n",
    "\n",
    "cont = np.median(Cont_Distance, axis=0)\n",
    "ax1.plot(topNs, SC_Agg_topN_score, color=\"blue\", marker=\"o\", markersize=5, lw=1,\n",
    "                     ls=\"dashed\", label=\"ASD\\nProbands\")\n",
    "\n",
    "lower = np.percentile(Cont_Distance, 50-BarLen, axis=0)\n",
    "upper = np.percentile(Cont_Distance, 50+BarLen, axis=0)\n",
    "ax1.errorbar(topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "            yerr=(cont - lower, upper - cont ), ls=\"dashed\", label=\"Siblings\")\n",
    "ax1.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "ax1.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax1.legend(fontsize=13)\n",
    "\n",
    "cont = np.nanmean(Cont_DistanceLong, axis=0)\n",
    "ax2.plot(topNs, SC_Agg_topN_scoreLong, color=\"blue\", marker=\"o\", markersize=5, lw=1,\n",
    "                     ls=\"dashed\", label=\"ASD\\nProbands\")\n",
    "\n",
    "lower = np.nanpercentile(Cont_DistanceLong, 50-BarLen, axis=0)\n",
    "upper = np.nanpercentile(Cont_DistanceLong, 50+BarLen, axis=0)\n",
    "ax2.errorbar(topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "            yerr=(cont - lower, abs(upper - cont) ), ls=\"dashed\", label=\"Siblings\")\n",
    "ax2.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "ax2.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax2.legend(fontsize=13)\n",
    "\n",
    "cont = np.median(Cont_DistanceShort, axis=0)\n",
    "ax3.plot(topNs, SC_Agg_topN_scoreShort, color=\"blue\", marker=\"o\", markersize=5, lw=1,\n",
    "                     ls=\"dashed\", label=\"ASD\\nProbands\")\n",
    "\n",
    "lower = np.percentile(Cont_DistanceShort, 50-BarLen, axis=0)\n",
    "upper = np.percentile(Cont_DistanceShort, 50+BarLen, axis=0)\n",
    "ax3.errorbar(topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "            yerr=(cont - lower, upper - cont ), ls=\"dashed\", label=\"Siblings\")\n",
    "ax3.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "ax3.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax3.legend(fontsize=13)\n",
    "\n",
    "#fig.text(0.5, -0.03, 'Top Number of Structuress', ha='center')\n",
    "#fig.text(-0.03, 0.5, 'SI Score', va='center', rotation='vertical')\n",
    "ax1.set_xlim(0, 121)\n",
    "ax2.set_xlim(0, 121)\n",
    "ax3.set_xlim(0, 121)\n",
    "plt.tight_layout()\n",
    "#plt.legend(fontsize=15)\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "ax3.grid(True)\n",
    "#plt.savefig(\"../figs/main/Fig2.BCD.pdf\")\n",
    "#plt.savefig(\"../figs/main/Fig2.BCD.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = pd.read_csv(\"dat/JonDat/MERFISH_Bias_NeuroOnly_JC.csv\", index_col=0)\n",
    "XX = ASD_Bias_MERFISH_STR_Z2_VM = FixSubiculum_reverse(XX)\n",
    "XX.to_csv(\"dat/JonDat/MERFISH_Bias_NeuroOnly_JC.splitSB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gencic)",
   "language": "python",
   "name": "gencic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
