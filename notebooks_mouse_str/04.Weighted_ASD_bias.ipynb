{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ProjDIR = \"/home/jw3514/Work/ASD_Circuits_CellType\"\n",
    "sys.path.insert(1, os.path.join(ProjDIR, \"src\"))\n",
    "from ASD_Circuits import (\n",
    "    LoadGeneINFO, STR2Region, SPARK_Gene_Weights,\n",
    "    MouseSTR_AvgZ_Weighted, ScoreCircuit_SI_Joint,\n",
    "    bootstrap_gene_mutations, BiasCorrelation,\n",
    ")\n",
    "from plot import (\n",
    "    plot_structure_bias_correlation,\n",
    "    compute_circuit_scores_for_profiles,\n",
    "    plot_circuit_connectivity_scores_multi,\n",
    "    plot_circuit_scores_with_bootstrap_ci,\n",
    ")\n",
    "\n",
    "os.chdir(os.path.join(ProjDIR, \"notebooks_mouse_str\"))\n",
    "print(f\"Project root: {ProjDIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Weighted ASD Mutation Bias\n",
    "\n",
    "This notebook computes structure-level mutation bias for ASD genes\n",
    "using mutation-count-based gene weights (SPARK/DeNovoWEST, Zhou et al. 2022).\n",
    "\n",
    "**Sections**:\n",
    "1. Load data and compute gene weights (with/without mutability correction)\n",
    "2. Compare recomputed bias vs reference\n",
    "3. Mutation bootstrap (1000 iterations)\n",
    "4. CCS profiles with bootstrap confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data & Compute Gene Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config and expression matrix\n",
    "with open(\"../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "expr_matrix_path = config[\"analysis_types\"][\"STR_ISH\"][\"expr_matrix\"]\n",
    "STR_BiasMat = pd.read_parquet(f\"../{expr_matrix_path}\")\n",
    "HGNC, ENSID2Entrez, GeneSymbol2Entrez, Entrez2Symbol = LoadGeneINFO()\n",
    "Anno = STR2Region()\n",
    "\n",
    "print(f\"Expression matrix: {STR_BiasMat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SPARK exome-wide significant ASD genes (Zhou et al. 2022)\n",
    "Spark_Meta_2stage = pd.read_excel(\n",
    "    \"../dat/Genetics/41588_2022_1148_MOESM4_ESM.xlsx\",\n",
    "    skiprows=2, sheet_name=\"Table S7\"\n",
    ")\n",
    "Spark_Meta_2stage = Spark_Meta_2stage[Spark_Meta_2stage[\"pDenovoWEST_Meta\"] != \".\"]\n",
    "Spark_Meta_ExomeWide = Spark_Meta_2stage[\n",
    "    Spark_Meta_2stage[\"pDenovoWEST_Meta\"] <= 1.3e-6\n",
    "]\n",
    "print(f\"Exome-wide significant genes: {Spark_Meta_ExomeWide.shape[0]}\")\n",
    "print(f\"  Total LoF: {Spark_Meta_ExomeWide['AutismMerged_LoF'].sum()}\")\n",
    "print(f\"  Total Dmis: {Spark_Meta_ExomeWide['AutismMerged_Dmis_REVEL0.5'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load background mutation rate (BGMR) for mutability correction\n",
    "bgmr_path = config[\"data_files\"][\"Denovo_mut_rate\"]\n",
    "BGMR = pd.read_csv(bgmr_path, sep=None, engine='python', index_col=0)\n",
    "\n",
    "if \"GeneName\" in BGMR.columns:\n",
    "    BGMR[\"entrez_id\"] = BGMR[\"GeneName\"].map(GeneSymbol2Entrez)\n",
    "    BGMR = BGMR[~BGMR[\"entrez_id\"].isna()].copy()\n",
    "    BGMR[\"entrez_id\"] = BGMR[\"entrez_id\"].astype(int)\n",
    "    BGMR = BGMR.set_index(\"entrez_id\")\n",
    "print(f\"BGMR: {BGMR.shape[0]} genes with mutation rates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gene weights — two versions:\n",
    "# 1. With mutability correction (BGMR): subtracts expected mutation counts\n",
    "# 2. Without correction (BGMR=None): uses raw observed counts only\n",
    "\n",
    "_, Agg_gene_bgmr = SPARK_Gene_Weights(\n",
    "    Spark_Meta_ExomeWide, BGMR,\n",
    "    out=\"../dat/Unionize_bias/Spark_Meta_EWS.GeneWeight.bgmr.csv\"\n",
    ")\n",
    "ASD_STR_Bias_bgmr = MouseSTR_AvgZ_Weighted(STR_BiasMat, Agg_gene_bgmr)\n",
    "\n",
    "_, Agg_gene2MutN = SPARK_Gene_Weights(\n",
    "    Spark_Meta_ExomeWide, None,\n",
    "    out=\"../dat/Unionize_bias/Spark_Meta_EWS.GeneWeight.v2.csv\"\n",
    ")\n",
    "ASD_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, Agg_gene2MutN)\n",
    "\n",
    "print(f\"Genes with mutability correction: {len(Agg_gene_bgmr)}\")\n",
    "print(f\"Genes without correction:         {len(Agg_gene2MutN)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare with Reference Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference bias (from FDR-corrected analysis)\n",
    "ASD_Z2_ref = pd.read_csv(\n",
    "    \"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.FDR.csv\", index_col=\"STR\"\n",
    ")\n",
    "\n",
    "# Scatter: recomputed vs reference\n",
    "BiasCorrelation(\n",
    "    ASD_STR_Bias, ASD_Z2_ref,\n",
    "    name1=\"Recomputed ASD Bias\", name2=\"Reference (FDR)\", dpi=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of mutability correction\n",
    "plot_structure_bias_correlation(\n",
    "    ASD_Z2_ref, ASD_STR_Bias_bgmr,\n",
    "    label_a='Mutation Bias\\nZhou et al. 61 ASD genes',\n",
    "    label_b='Mutation Bias (Mutability Corrected)\\nZhou et al. 61 ASD genes',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 3. Mutation Bootstrap\n",
    "\n",
    "Resample mutations at the individual mutation level (preserving total counts)\n",
    "to generate 1000 bootstrap replicates. Two modes:\n",
    "- **Weighted**: probability proportional to observed mutation counts per gene\n",
    "- **Uniform**: equal probability across genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select gene-level columns for bootstrap\n",
    "Spark_Meta_EW_Genes = Spark_Meta_ExomeWide[[\n",
    "    \"GeneID\", \"EntrezID\", \"HGNC\", \"ExACpLI\", \"LOEUF\",\n",
    "    \"AutismMerged_LoF\", \"AutismMerged_Dmis_REVEL0.5\", \"pDenovoWEST_Meta\"\n",
    "]]\n",
    "print(f\"Bootstrapping {len(Spark_Meta_EW_Genes)} genes, 1000 iterations each...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bootstrap replicates\n",
    "N_BOOT = 1000\n",
    "boot_DFs_weights = bootstrap_gene_mutations(Spark_Meta_EW_Genes, N_BOOT, weighted=True)\n",
    "boot_DFs_uniform = bootstrap_gene_mutations(Spark_Meta_EW_Genes, N_BOOT, weighted=False)\n",
    "print(f\"Generated {N_BOOT} weighted + {N_BOOT} uniform bootstrap replicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bias for each bootstrap replicate (with caching)\n",
    "BOOT_CACHE_W = \"../results/Bootstrap_bias/Spark_ExomeWide/Weighted_Resampling\"\n",
    "BOOT_CACHE_U = \"../results/Bootstrap_bias/Spark_ExomeWide/Uniform_Resampling\"\n",
    "\n",
    "# Check if cached results exist\n",
    "cached_w = os.path.exists(os.path.join(BOOT_CACHE_W, \"Spark_ExomeWide.GeneWeight.boot0.csv\"))\n",
    "cached_u = os.path.exists(os.path.join(BOOT_CACHE_U, \"Spark_ExomeWide.GeneWeight.boot0.csv\"))\n",
    "\n",
    "if cached_w:\n",
    "    print(\"Loading cached weighted bootstrap bias...\")\n",
    "    boot_bias_list_weights = []\n",
    "    for i in range(N_BOOT):\n",
    "        df = pd.read_csv(os.path.join(BOOT_CACHE_W, f\"Spark_ExomeWide.GeneWeight.boot{i}.csv\"), index_col=0)\n",
    "        boot_bias_list_weights.append(df)\n",
    "else:\n",
    "    print(\"Computing weighted bootstrap bias (this takes a few minutes)...\")\n",
    "    os.makedirs(BOOT_CACHE_W, exist_ok=True)\n",
    "    boot_bias_list_weights = []\n",
    "    for i, DF in enumerate(boot_DFs_weights):\n",
    "        _, boot_gw = SPARK_Gene_Weights(DF, BGMR, Bmis=False)\n",
    "        boot_bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, boot_gw)\n",
    "        boot_bias_list_weights.append(boot_bias)\n",
    "        boot_bias.to_csv(os.path.join(BOOT_CACHE_W, f\"Spark_ExomeWide.GeneWeight.boot{i}.csv\"))\n",
    "\n",
    "if cached_u:\n",
    "    print(\"Loading cached uniform bootstrap bias...\")\n",
    "    boot_bias_list_uniform = []\n",
    "    for i in range(N_BOOT):\n",
    "        df = pd.read_csv(os.path.join(BOOT_CACHE_U, f\"Spark_ExomeWide.GeneWeight.boot{i}.csv\"), index_col=0)\n",
    "        boot_bias_list_uniform.append(df)\n",
    "else:\n",
    "    print(\"Computing uniform bootstrap bias (this takes a few minutes)...\")\n",
    "    os.makedirs(BOOT_CACHE_U, exist_ok=True)\n",
    "    boot_bias_list_uniform = []\n",
    "    for i, DF in enumerate(boot_DFs_uniform):\n",
    "        _, boot_gw = SPARK_Gene_Weights(DF, BGMR)\n",
    "        boot_bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, boot_gw)\n",
    "        boot_bias_list_uniform.append(boot_bias)\n",
    "        boot_bias.to_csv(os.path.join(BOOT_CACHE_U, f\"Spark_ExomeWide.GeneWeight.boot{i}.csv\"))\n",
    "\n",
    "print(f\"Loaded {len(boot_bias_list_weights)} weighted, {len(boot_bias_list_uniform)} uniform bootstrap biases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 4. CCS Profiles with Bootstrap Confidence Intervals\n",
    "\n",
    "Compute Circuit Connectivity Scores (CCS) for the original ASD bias\n",
    "and all bootstrap replicates, then plot with confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load connectivity scoring matrices and sibling null CCS profiles\n",
    "CONN_DIR = os.path.join(ProjDIR, \"dat/allen-mouse-conn\")\n",
    "SCORE_DIR = os.path.join(CONN_DIR, \"ConnectomeScoringMat\")\n",
    "RANK_DIR = os.path.join(CONN_DIR, \"RankScores\")\n",
    "\n",
    "IpsiInfoMat = pd.read_csv(os.path.join(SCORE_DIR, \"InfoMat.Ipsi.csv\"), index_col=0)\n",
    "IpsiInfoMatShort = pd.read_csv(os.path.join(SCORE_DIR, \"InfoMat.Ipsi.Short.3900.csv\"), index_col=0)\n",
    "IpsiInfoMatLong = pd.read_csv(os.path.join(SCORE_DIR, \"InfoMat.Ipsi.Long.3900.csv\"), index_col=0)\n",
    "\n",
    "Cont_Distance = np.load(os.path.join(RANK_DIR, \"RankScore.Ipsi.Cont.npy\"))\n",
    "Cont_DistanceShort = np.load(os.path.join(RANK_DIR, \"RankScore.Ipsi.Short.3900.Cont.npy\"))\n",
    "Cont_DistanceLong = np.load(os.path.join(RANK_DIR, \"RankScore.Ipsi.Long.3900.Cont.npy\"))\n",
    "\n",
    "info_mats = {\n",
    "    \"Standard\": IpsiInfoMat,\n",
    "    \"Short\": IpsiInfoMatShort,\n",
    "    \"Long\": IpsiInfoMatLong,\n",
    "}\n",
    "cont_distance_dict = {\n",
    "    \"Standard\": Cont_Distance,\n",
    "    \"Short\": Cont_DistanceShort,\n",
    "    \"Long\": Cont_DistanceLong,\n",
    "}\n",
    "print(f\"Sibling null CCS profiles: {Cont_Distance.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCS profile: recomputed vs reference\n",
    "topNs = list(range(200, 5, -1))\n",
    "\n",
    "profiles = {\n",
    "    \"Spark 61 (recomputed)\": ASD_STR_Bias,\n",
    "    \"Spark 61 (reference)\": ASD_Z2_ref,\n",
    "}\n",
    "\n",
    "circuit_scores = compute_circuit_scores_for_profiles(profiles, topNs, info_mats)\n",
    "\n",
    "fig = plot_circuit_connectivity_scores_multi(\n",
    "    topNs, circuit_scores, cont_distance_dict, xlim=(0, 121)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CCS for original ASD bias (mean line for bootstrap CI plots)\n",
    "CCS_CACHE = \"../results/Bootstrap_bias/Spark_ExomeWide/bootstrap_CCS.npz\"\n",
    "\n",
    "if os.path.exists(CCS_CACHE):\n",
    "    print(\"Loading cached bootstrap CCS scores...\")\n",
    "    cached = np.load(CCS_CACHE)\n",
    "    mean_circuit_scores = {k: cached[f\"mean_{k}\"] for k in info_mats}\n",
    "    boot_circuit_scores_weights = {k: cached[f\"boot_{k}\"] for k in info_mats}\n",
    "else:\n",
    "    print(\"Computing CCS for original ASD bias...\")\n",
    "    mean_circuit_scores = {}\n",
    "    str_ranks = ASD_STR_Bias.sort_values(\"EFFECT\", ascending=False).index.values\n",
    "    for conn_type, info_mat in info_mats.items():\n",
    "        scores = [ScoreCircuit_SI_Joint(str_ranks[:topN], info_mat) for topN in topNs]\n",
    "        mean_circuit_scores[conn_type] = np.array(scores)\n",
    "\n",
    "    print(f\"Computing CCS for {N_BOOT} bootstrap samples (3 conn types × 195 topNs)...\")\n",
    "    boot_circuit_scores_weights = {ct: [] for ct in info_mats}\n",
    "    for boot_idx, boot_bias in enumerate(boot_bias_list_weights):\n",
    "        if (boot_idx + 1) % 100 == 0:\n",
    "            print(f\"  Bootstrap {boot_idx + 1}/{N_BOOT}\")\n",
    "        str_ranks = boot_bias.sort_values(\"EFFECT\", ascending=False).index.values\n",
    "        for conn_type, info_mat in info_mats.items():\n",
    "            scores = [ScoreCircuit_SI_Joint(str_ranks[:topN], info_mat) for topN in topNs]\n",
    "            boot_circuit_scores_weights[conn_type].append(scores)\n",
    "\n",
    "    for ct in boot_circuit_scores_weights:\n",
    "        boot_circuit_scores_weights[ct] = np.array(boot_circuit_scores_weights[ct])\n",
    "        print(f\"  {ct}: {boot_circuit_scores_weights[ct].shape}\")\n",
    "\n",
    "    # Cache results\n",
    "    os.makedirs(os.path.dirname(CCS_CACHE), exist_ok=True)\n",
    "    save_dict = {}\n",
    "    for ct in info_mats:\n",
    "        save_dict[f\"mean_{ct}\"] = mean_circuit_scores[ct]\n",
    "        save_dict[f\"boot_{ct}\"] = boot_circuit_scores_weights[ct]\n",
    "    np.savez(CCS_CACHE, **save_dict)\n",
    "    print(f\"Cached to {CCS_CACHE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: CCS with 95% bootstrap CI + sibling IQR\n",
    "fig = plot_circuit_scores_with_bootstrap_ci(\n",
    "    topNs=topNs,\n",
    "    mean_scores=mean_circuit_scores,\n",
    "    boot_scores=boot_circuit_scores_weights,\n",
    "    cont_distance_dict=cont_distance_dict,\n",
    "    ci_type='percentile',\n",
    "    percentile_range=95,\n",
    "    viz_style='shade',\n",
    "    show_asd_ci=True,\n",
    "    show_sib_ci=True,\n",
    "    xlim=(0, 121),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: CCS with sibling IQR only (no bootstrap CI)\n",
    "fig = plot_circuit_scores_with_bootstrap_ci(\n",
    "    topNs=topNs,\n",
    "    mean_scores=mean_circuit_scores,\n",
    "    boot_scores=boot_circuit_scores_weights,\n",
    "    cont_distance_dict=cont_distance_dict,\n",
    "    show_asd_ci=False,\n",
    "    show_sib_ci=True,\n",
    "    xlim=(0, 121),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: CCS with bootstrap CI only (no sibling IQR)\n",
    "fig = plot_circuit_scores_with_bootstrap_ci(\n",
    "    topNs=topNs,\n",
    "    mean_scores=mean_circuit_scores,\n",
    "    boot_scores=boot_circuit_scores_weights,\n",
    "    cont_distance_dict=cont_distance_dict,\n",
    "    show_asd_ci=True,\n",
    "    show_sib_ci=False,\n",
    "    xlim=(0, 121),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Output | Description |\n",
    "|--------|-------------|\n",
    "| `Spark_Meta_EWS.GeneWeight.v2.csv` | Gene weights (no mutability correction) |\n",
    "| `Spark_Meta_EWS.GeneWeight.bgmr.csv` | Gene weights (mutability corrected) |\n",
    "| `Bootstrap_bias/Spark_ExomeWide/Weighted_Resampling/` | 1000 bootstrap bias CSVs |\n",
    "| `Bootstrap_bias/Spark_ExomeWide/Uniform_Resampling/` | 1000 bootstrap bias CSVs |\n",
    "| `Bootstrap_bias/Spark_ExomeWide/bootstrap_CCS.npz` | Cached CCS for bootstrap |"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "gencic",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
