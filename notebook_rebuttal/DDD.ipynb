{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "ProjDIR = \"/home/jw3514/Work/ASD_Circuits_CellType/\" # Change to your project directory\n",
    "sys.path.insert(1, f'{ProjDIR}/src/')\n",
    "from ASD_Circuits import *\n",
    "from plot import *\n",
    "\n",
    "try:\n",
    "    os.chdir(f\"{ProjDIR}/notebook_rebuttal/\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not change directory - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "\n",
    "HGNC, ENSID2Entrez, GeneSymbol2Entrez, Entrez2Symbol = LoadGeneINFO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "with open(\"../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "expr_matrix_path = config[\"analysis_types\"][\"STR_ISH\"][\"expr_matrix\"]\n",
    "STR_BiasMat = pd.read_parquet(f\"../{expr_matrix_path}\")\n",
    "STR_Anno = STR2Region()\n",
    "\n",
    "expr_matrix_path = config[\"analysis_types\"][\"CT_Z2\"][\"expr_matrix\"]\n",
    "CT_BiasMat = pd.read_parquet(f\"../{expr_matrix_path}\")\n",
    "CT_Anno = pd.read_csv(ProjDIR + \"dat/MouseCT_Cluster_Anno.csv\", index_col=\"cluster_id_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Structure level "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. ALL DDD genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD_GW = Fil2Dict(config[\"gene_sets\"][\"DDD_293\"][\"geneweights\"])\n",
    "DDD_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, DDD_GW)\n",
    "DDD_STR_Bias[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in DDD_STR_Bias.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoreMatDir=\"/home/jw3514/Work/ASD_Circuits/dat/allen-mouse-conn/ScoreingMat_jw_v3/\"\n",
    "WeightMat = pd.read_csv(ScoreMatDir + \"WeightMat.Ipsi.csv\", index_col=0)\n",
    "IpsiInfoMat=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.csv\", index_col=0)\n",
    "IpsiInfoMatShort_v1=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.Short.3900.csv\", index_col=0)\n",
    "IpsiInfoMatLong_v1=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.Long.3900.csv\", index_col=0)\n",
    "\n",
    "topNs = np.arange(200, 5, -1)\n",
    "DIR = \"/home/jw3514/Work/ASD_Circuits/scripts/RankScores/\"\n",
    "Cont_Distance = np.load(\"{}/RankScore.Ipsi.Cont.npy\".format(DIR))\n",
    "Cont_DistanceShort = np.load(\"{}/RankScore.Ipsi.Short.3900.Cont.npy\".format(DIR))\n",
    "Cont_DistanceLong = np.load(\"{}/RankScore.Ipsi.Long.3900.Cont.npy\".format(DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = calculate_circuit_scores(DDD_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax1 = plt.subplots(1,1, dpi=480, figsize=(12,6), facecolor='none')\n",
    "\n",
    "fig.patch.set_alpha(0)\n",
    "ax1.patch.set_alpha(0)\n",
    "\n",
    "BarLen = 34.1\n",
    "#BarLen = 47.5\n",
    "\n",
    "topNs = list(range(200, 5, -1))  # Define topNs based on the range used in calculate_circuit_scores\n",
    "                        \n",
    "ax1.plot(topNs, score, color='#1f77b4', marker=\"o\", markersize=5, lw=1,\n",
    "                    ls=\"dashed\", label=\"DD\", alpha = 0.5)\n",
    "\n",
    "cont = np.median(Cont_Distance, axis=0)\n",
    "lower = np.percentile(Cont_Distance, 50-BarLen, axis=0)\n",
    "upper = np.percentile(Cont_Distance, 50+BarLen, axis=0)\n",
    "ax1.errorbar(topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "            yerr=(cont - lower, upper - cont ), ls=\"dashed\", label=\"Siblings\")\n",
    "ax1.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "ax1.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "ax1.set_xlim(0, 121)\n",
    "\n",
    "# Place legend outside of plot\n",
    "ax1.legend(fontsize=13, bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.tight_layout()  # Adjust layout to prevent legend cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_ASD_STR_Bias = pd.read_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.FDR.csv\", index_col=0)\n",
    "Spark_ASD_STR_Bias[\"Region\"] = Spark_ASD_STR_Bias[\"REGION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_ASD_STR_Bias[Spark_ASD_STR_Bias[\"qvalues\"]<0.05].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Section 2: Structure Level Results\n",
    "\n",
    "This section includes:\n",
    "1. DDD exclude ASD correlation with ASD\n",
    "2. Constraint (top25% LOEUF) with ASD  \n",
    "3. Residual structures analysis\n",
    "\n",
    "## 2.1 Helper Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Section 3: Cell Type Results\n",
    "\n",
    "This section includes cell type-level analyses:\n",
    "1. DDD exclude ASD correlation with ASD\n",
    "2. Constraint (top25% LOEUF) with ASD\n",
    "3. Residual cell type analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def fit_structure_bias_linear_model(merged_data, metric='EFFECT', suffixes=('_1', '_2')):\n",
    "\n",
    "    X = merged_data[f'{metric}{suffixes[1]}'].values.reshape(-1, 1)\n",
    "    y = merged_data[f'{metric}{suffixes[0]}'].values\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    results_df = merged_data.copy()\n",
    "    results_df['predicted'] = y_pred\n",
    "    results_df['residual'] = residuals\n",
    "\n",
    "    return results_df\n",
    "\n",
    "#results_df = fit_structure_bias_linear_model(merged_data2, metric='EFFECT', suffixes=('_ASD', '_DD'))\n",
    "\n",
    "def merge_str_bias_datasets(dataset1, dataset2, suffixes=('_1', '_2')):\n",
    "    \"\"\"\n",
    "    Merge two structure bias datasets for comparison.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset1 : DataFrame\n",
    "        First dataset with 'Rank', 'EFFECT', and 'Region' columns\n",
    "    dataset2 : DataFrame\n",
    "        Second dataset with 'Rank' and 'EFFECT' columns\n",
    "    suffixes : tuple of str\n",
    "        Suffixes to append to column names for each dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    merged_data : DataFrame\n",
    "        Merged dataset with comparison metrics for both Rank and EFFECT\n",
    "    \"\"\"\n",
    "    # Select all relevant columns\n",
    "    dataset1_cols = ['Rank', 'EFFECT', 'Region']\n",
    "    dataset2_cols = ['Rank', 'EFFECT']\n",
    "    \n",
    "    # Merge the datasets on structure names for comparison\n",
    "    merged_data = pd.merge(dataset1[dataset1_cols], dataset2[dataset2_cols], \n",
    "                          left_index=True, right_index=True, suffixes=suffixes)\n",
    "\n",
    "    # Calculate differences for both Rank and EFFECT metrics\n",
    "    merged_data[f'DIFF_Rank'] = merged_data[f'Rank{suffixes[0]}'] - merged_data[f'Rank{suffixes[1]}']\n",
    "    merged_data[f'ABS_DIFF_Rank'] = np.abs(merged_data[f'DIFF_Rank'])\n",
    "    \n",
    "    merged_data[f'DIFF_EFFECT'] = merged_data[f'EFFECT{suffixes[0]}'] - merged_data[f'EFFECT{suffixes[1]}']\n",
    "    merged_data[f'ABS_DIFF_EFFECT'] = np.abs(merged_data[f'DIFF_EFFECT'])\n",
    "\n",
    "    # Sort by absolute difference in EFFECT by default\n",
    "    merged_data = merged_data.sort_values('ABS_DIFF_EFFECT', ascending=False)\n",
    "    merged_data = fit_structure_bias_linear_model(merged_data, metric='EFFECT', suffixes=suffixes)\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "\n",
    "# Call the function\n",
    "merged_data = merge_str_bias_datasets(Spark_ASD_STR_Bias, DDD_STR_Bias, suffixes=('_ASD', '_DD'))\n",
    "plot_structure_bias_comparison(merged_data, suffixes=('_ASD', '_DD'),  metric=\"EFFECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_GW = Fil2Dict(ProjDIR+\"dat/Genetics/GeneWeights_DN/Spark_Meta_EWS.GeneWeight.DN.gw\")\n",
    "# ASD_SC_Bias = MouseCT_AvgZ_Weighted(CT_BiasMat, ASD_GW)\n",
    "# ASD_SC_Bias = add_class(ASD_SC_Bias, CT_Anno)\n",
    "# ASD_SC_Bias.to_csv(ProjDIR + \"/results/CT_Z2/ASD_Spark61.csv\")\n",
    "\n",
    "# DDD_SC_Bias = MouseCT_AvgZ_Weighted(CT_BiasMat, DDD_GW)\n",
    "# DDD_SC_Bias = add_class(DDD_SC_Bias, CT_Anno)\n",
    "# DDD_SC_Bias.to_csv(ProjDIR + \"/results/CT_Z2/DDD_295.csv\")\n",
    "ASD_SC_Bias = pd.read_csv(ProjDIR + \"/results/CT_Z2/ASD_All_bias_addP_sibling.csv\", index_col=0)\n",
    "DDD_SC_Bias = pd.read_csv(ProjDIR + \"/results/CT_Z2/DDD_293_bias_addP_sibling.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_scatter_mouseCT(DDD_SC_Bias, ASD_SC_Bias, name1=\"DD Cell Type Bias\", name2=\"ASD Cell Type Bias\", effect_col1=\"EFFECT\", effect_col2=\"EFFECT\", dpi=240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Exclude ASD genes and see whats left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/home/jw3514/Work/ASD_Circuits_CellType/dat/Genetics/Fu_et_al_2022.xlsx\"\n",
    "# fu_DF_Pval = pd.read_excel(file_path, sheet_name=\"Supplementary Table 11\", skiprows=0)\n",
    "# ASD_GENES = fu_DF_Pval[fu_DF_Pval[\"ASD185\"] == 1][\"gene_gencodeV33\"]\n",
    "# ASD_GENES = [GeneSymbol2Entrez[gene] for gene in ASD_GENES]\n",
    "\n",
    "ASD_GENES = list(ASD_GW.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD_GW_filt_ASD = {k: v for k, v in DDD_GW.items() if k not in ASD_GENES}\n",
    "print(len(DDD_GW_filt_ASD))\n",
    "DDD_rmASD_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, DDD_GW_filt_ASD)\n",
    "DDD_rmASD_STR_Bias[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in DDD_rmASD_STR_Bias.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict2Fil(DDD_GW, ProjDIR+\"/dat/Genetics/GeneWeights/DDD.top293.gw\")\n",
    "Dict2Fil(DDD_GW_filt_ASD, ProjDIR+\"/dat/Genetics/GeneWeights/DDD.top245.ExcludeASD.gw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data2 = merge_str_bias_datasets(Spark_ASD_STR_Bias, DDD_rmASD_STR_Bias, suffixes=('_ASD', '_DD_ExcludeASD'))\n",
    "plot_structure_bias_comparison(merged_data2, suffixes=('_ASD', '_DD_ExcludeASD'), metric='EFFECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC = pd.read_csv('../results/GENCIC_MouseSTRBias.csv', index_col=0)\n",
    "Circuit_STRs = GENCIC[GENCIC[\"Circuits.46\"]==1][\"Structure\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.3 Residual Structures Analysis: DDD Exclude ASD vs ASD\n",
    "\n",
    "def plot_top_residual_structures(merged_data, top_n=30, top_threshold=40, \n",
    "                                name1=\"ASD\", name2=\"DD\", figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Plot brain structures with largest residuals from regression analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    merged_data : DataFrame\n",
    "        Merged dataset with residual and region information\n",
    "    top_n : int\n",
    "        Number of top structures to display\n",
    "    top_threshold : int\n",
    "        Filter to structures in top N of at least one dataset\n",
    "    name1, name2 : str\n",
    "        Names of the two datasets being compared\n",
    "    figsize : tuple\n",
    "        Figure size (width, height)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    top_diff : DataFrame\n",
    "        Top structures with largest residuals\n",
    "    \"\"\"\n",
    "    # Filter to only structures that appear in top threshold of at least one dataset\n",
    "    top_structures = merged_data[(merged_data[f\"Rank_{name1}\"] <= top_threshold) | \n",
    "                                (merged_data[f\"Rank_{name2}\"] <= top_threshold)]\n",
    "\n",
    "    print(f\"Total structures in top {top_threshold} of at least one dataset: {len(top_structures)}\")\n",
    "\n",
    "    # Sort by absolute difference for top structures only\n",
    "    top_structures = top_structures.copy()\n",
    "    top_structures[\"ABS_DIFF\"] = abs(merged_data[f\"residual\"])\n",
    "    top_structures = top_structures.sort_values('ABS_DIFF', ascending=True)\n",
    "\n",
    "    # Take the top N structures with largest differences from those in top threshold\n",
    "    top_n = min(top_n, len(top_structures))  # Use min to avoid index errors if fewer structures available\n",
    "    top_diff = top_structures.tail(top_n)  # Get largest differences\n",
    "\n",
    "    print(f\"Showing top {len(top_diff)} structures with largest differences (from top {top_threshold} filter)\")\n",
    "\n",
    "    # Define regions and colors\n",
    "    REGIONS_seq = ['Isocortex','Olfactory_areas', 'Cortical_subplate', \n",
    "                    'Hippocampus','Amygdala','Striatum', \n",
    "                    \"Thalamus\", \"Hypothalamus\", \"Midbrain\", \n",
    "                    \"Medulla\", \"Pallidum\", \"Pons\", \n",
    "                    \"Cerebellum\"]\n",
    "    REG_COR_Dic = dict(zip(REGIONS_seq, [\"#268ad5\", \"#D5DBDB\", \"#7ac3fa\", \n",
    "                                        \"#2c9d39\", \"#742eb5\", \"#ed8921\", \n",
    "                                        \"#e82315\", \"#E6B0AA\", \"#f6b26b\",  \n",
    "                                        \"#20124d\", \"#2ECC71\", \"#D2B4DE\", \n",
    "                                        \"#ffd966\", ]))\n",
    "\n",
    "    # Create publication-quality plot of residuals for top_diff structures\n",
    "    plt.rcParams.update({'font.size': 12, 'font.family': 'Arial'})\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=300)\n",
    "\n",
    "    # Sort top_diff by residuals for better visualization\n",
    "    top_diff_sorted = top_diff.sort_values('ABS_DIFF', ascending=True)\n",
    "\n",
    "    # Create colors based on region\n",
    "    colors = [REG_COR_Dic.get(region, '#808080') for region in top_diff_sorted['Region']]\n",
    "\n",
    "    # Create horizontal bar plot with better styling\n",
    "    bars = ax.barh(range(len(top_diff_sorted)), \n",
    "                   top_diff_sorted[f'residual'], \n",
    "                   color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "    # Customize the plot with publication-quality styling\n",
    "    ax.set_yticks(range(len(top_diff_sorted)))\n",
    "    ax.set_yticklabels([name.replace('_', ' ') for name in top_diff_sorted.index], \n",
    "                       fontsize=12, fontweight='normal')\n",
    "    ax.set_xlabel(f'Residuals ({name1} vs {name2})', fontsize=14, fontweight='bold')\n",
    "    #ax.set_title(f'Top {len(top_diff)} Brain Structures with Largest Residuals', \n",
    "    #             fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "    # Remove top and right spines for cleaner look\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1)\n",
    "    ax.spines['bottom'].set_linewidth(1)\n",
    "\n",
    "    # Add subtle grid\n",
    "    ax.grid(True, axis='x', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Add vertical line at x=0 with better styling\n",
    "    ax.axvline(x=0, color='black', linestyle='-', alpha=0.7, linewidth=1)\n",
    "\n",
    "    # Create legend for regions with better styling\n",
    "    unique_regions = sorted(list(set(top_diff_sorted['Region'])))\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=REG_COR_Dic.get(region, '#808080'), \n",
    "                                    alpha=0.8, edgecolor='black', linewidth=0.5) \n",
    "                       for region in unique_regions if region in REG_COR_Dic]\n",
    "    legend_labels = [region.replace('_', ' ') for region in unique_regions if region in REG_COR_Dic]\n",
    "\n",
    "    if legend_elements:\n",
    "        ax.legend(\n",
    "            legend_elements, legend_labels,\n",
    "            loc='center left',       # You can change this to your preferred location, e.g. 'center left'\n",
    "            bbox_to_anchor=(0.70, 0.1), # Pushes legend outside right of plot at vertical center\n",
    "            fontsize=10, \n",
    "            frameon=True,\n",
    "            fancybox=True,\n",
    "            shadow=True,\n",
    "            framealpha=0.9\n",
    "        )\n",
    "\n",
    "    # Adjust layout and margins\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.3)  # Make room for structure names\n",
    "    plt.show()\n",
    "    \n",
    "    return top_diff\n",
    "\n",
    "# Call the function\n",
    "merged_data_eval = merged_data2[merged_data2.index.isin(Circuit_STRs)]\n",
    "top_diff = plot_top_residual_structures(merged_data_eval, top_n=20, top_threshold=40,\n",
    "                                       name1=\"ASD\", name2=\"DD_ExcludeASD\", figsize=(6, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Cell Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDD_rmASD_SC_Bias = MouseCT_AvgZ_Weighted(CT_BiasMat, DDD_GW_filt_ASD)\n",
    "# DDD_rmASD_SC_Bias = add_class(DDD_rmASD_SC_Bias, CT_Anno)\n",
    "# DDD_rmASD_SC_Bias.to_csv(ProjDIR + \"/results/CT_Z2/DDD_245.rmASD.csv\")\n",
    "\n",
    "DDD_rmASD_SC_Bias = pd.read_csv(ProjDIR + \"/results/CT_Z2/DDD_293_ExcludeASD_bias_addP_sibling.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_scatter_mouseCT(DDD_rmASD_SC_Bias, ASD_SC_Bias, name1=\"DD (ASD Excluded) Cell Type Bias\", name2=\"ASD Cell Type Bias\", effect_col1=\"EFFECT\", effect_col2=\"EFFECT\", dpi=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD_rmASD_SC_Bias.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.4 Residual Cell Type Analysis: DDD Exclude ASD vs ASD\n",
    "\n",
    "def merge_ct_bias_datasets(dataset1, dataset2, suffixes=('_1', '_2')):\n",
    "    \"\"\"\n",
    "    Merge two structure bias datasets for comparison.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset1 : DataFrame\n",
    "        First dataset with 'Rank', 'EFFECT', and 'Region' columns\n",
    "    dataset2 : DataFrame\n",
    "        Second dataset with 'Rank' and 'EFFECT' columns\n",
    "    suffixes : tuple of str\n",
    "        Suffixes to append to column names for each dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    merged_data : DataFrame\n",
    "        Merged dataset with comparison metrics for both Rank and EFFECT\n",
    "    \"\"\"\n",
    "    # Select all relevant columns\n",
    "    dataset1_cols = ['Rank', 'EFFECT', 'class_id_label', 'subclass_id_label', 'CCF_broad.freq', 'CCF_acronym.freq']\n",
    "    dataset2_cols = ['Rank', 'EFFECT']\n",
    "    \n",
    "    # Merge the datasets on structure names for comparison\n",
    "    merged_data = pd.merge(dataset1[dataset1_cols], dataset2[dataset2_cols], \n",
    "                          left_index=True, right_index=True, suffixes=suffixes)\n",
    "\n",
    "    # Calculate differences for both Rank and EFFECT metrics\n",
    "    merged_data[f'DIFF_Rank'] = merged_data[f'Rank{suffixes[0]}'] - merged_data[f'Rank{suffixes[1]}']\n",
    "    merged_data[f'ABS_DIFF_Rank'] = np.abs(merged_data[f'DIFF_Rank'])\n",
    "    \n",
    "    merged_data[f'DIFF_EFFECT'] = merged_data[f'EFFECT{suffixes[0]}'] - merged_data[f'EFFECT{suffixes[1]}']\n",
    "    merged_data[f'ABS_DIFF_EFFECT'] = np.abs(merged_data[f'DIFF_EFFECT'])\n",
    "\n",
    "    # Sort by absolute difference in EFFECT by default\n",
    "    merged_data = merged_data.sort_values('ABS_DIFF_EFFECT', ascending=False)\n",
    "    merged_data = fit_structure_bias_linear_model(merged_data, metric='EFFECT', suffixes=suffixes)\n",
    "    \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique class_id_label values from CT_Anno\n",
    "print(CT_Anno['class_id_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_merged_data = merge_ct_bias_datasets(ASD_SC_Bias, DDD_rmASD_SC_Bias, suffixes=('_ASD', '_DD'))\n",
    "\n",
    "CNU_LGE_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '09 CNU-LGE GABA'].index.tolist() if x in ct_merged_data.index]\n",
    "IT_ET_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '01 IT-ET Glut'].index.tolist() if x in ct_merged_data.index]\n",
    "NP_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '02 NP-CT-L6b Glut'].index.tolist() if x in ct_merged_data.index]\n",
    "CGE_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '06 CTX-CGE GABA'].index.tolist() if x in ct_merged_data.index]\n",
    "MGE_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '07 CTX-MGE GABA'].index.tolist() if x in ct_merged_data.index]\n",
    "\n",
    "\n",
    "D1D2_labels = ['061 STR D1 Gaba', '062 STR D2 Gaba']\n",
    "STR_D1D2 = [idx for idx in CT_Anno[CT_Anno['subclass_id_label'].isin(D1D2_labels)].index if idx in ct_merged_data.index]\n",
    "Other_LGE = [idx for idx in CT_Anno[CT_Anno['class_id_label'] == '09 CNU-LGE GABA'].index if idx in ct_merged_data.index and idx not in STR_D1D2]\n",
    "\n",
    "HIP = ['016 CA1-ProS Glut', '017 CA3 Glut']\n",
    "HIP_Glut = [x for x in CT_Anno[CT_Anno['subclass_id_label'].isin(HIP)].index.tolist() if x in ct_merged_data.index]\n",
    "Other_IT_ET = [x for x in CT_Anno[CT_Anno['class_id_label'] == '01 IT-ET Glut'].index if x in ct_merged_data.index and x not in HIP_Glut]\n",
    "\n",
    "AMY =  ['012 MEA Slc17a7 Glut',\n",
    " '013 COAp Grxcr2 Glut',\n",
    " '014 LA-BLA-BMA-PA Glut',\n",
    " '015 ENTmv-PA-COAp Glut',]\n",
    "AMY_Glut = [x for x in CT_Anno[CT_Anno['subclass_id_label'].isin(AMY)].index.tolist() if x in ct_merged_data.index]\n",
    "Other_IT_ET = [x for x in CT_Anno[CT_Anno['class_id_label'] == '01 IT-ET Glut'].index if x in ct_merged_data.index and x not in AMY_Glut and x not in HIP_Glut]\n",
    "\n",
    "RU_Cluster = [x for x in CT_Anno[CT_Anno['subclass_id_label'] == '152 RE-Xi Nox4 Glut'].index.tolist() if x in ct_merged_data.index]\n",
    "PF_Cluster = [x for x in CT_Anno[CT_Anno['subclass_id_label'] == '154 PF Fzd5 Glut'].index.tolist() if x in ct_merged_data.index]\n",
    "RU_PF = RU_Cluster + PF_Cluster\n",
    "Other_TH_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '18 TH Glut'].index.tolist() if x in ct_merged_data.index and x not in RU_PF]\n",
    "\n",
    "AMY_HYA_Glut = [x for x in CT_Anno[CT_Anno['class_id_label'] == '13 CNU-HYa Glut'].index.tolist() if x in ct_merged_data.index]\n",
    "AMY_HYA_GABA = [x for x in CT_Anno[CT_Anno['class_id_label'] == '11 CNU-HYa GABA'].index.tolist() if x in ct_merged_data.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\n",
    "    \"D1/D2 MSN\": STR_D1D2,\n",
    "    \"CNU_LGE_GABA (Other)\": Other_LGE,\n",
    "    \"PF_RE_TH_Glut\": RU_PF,\n",
    "    \"TH_Glut (Other)\": Other_TH_Cluster,\n",
    "    \"CNU_HYA_Glut\": AMY_HYA_Glut,\n",
    "    \"CNU_HYA_GABA\": AMY_HYA_GABA,\n",
    "    \"CTX_CGE_GABA\": CGE_Cluster,\n",
    "    \"IT_ET_Glut\": IT_ET_Cluster,\n",
    "    \"NP_CT_L6b_Glut\": NP_Cluster,\n",
    "    \"CTX_MGE_GABA\": MGE_Cluster,\n",
    "}\n",
    "\n",
    "plot_palette = [\n",
    "    \"orange\",   # D1/D2 MSN\n",
    "    \"green\",    # CNU_LGE_GABA (Other)\n",
    "    \"purple\",   # PF_RE_TH_Glut\n",
    "    \"red\",      # TH_Glut (Other)\n",
    "    \"blue\",     # CNU_HYA_Glut\n",
    "    \"gold\",     # CNU_HYA_GABA\n",
    "    \"pink\",     # CTX_CGE_GABA\n",
    "    \"teal\",     # IT_ET_Glut\n",
    "    \"sienna\",   # NP_CT_L6b_Glut\n",
    "    \"indigo\"    # CTX_MGE_GABA\n",
    "]\n",
    "\n",
    "pairwise_tests = [\n",
    "    (\"D1/D2 MSN\", \"CNU_LGE_GABA (Other)\"),\n",
    "    (\"PF_RE_TH_Glut\", \"TH_Glut (Other)\"),\n",
    "    #(\"CTX_CGE_GABA\", [\"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "    (\"D1/D2 MSN\", [\"CTX_CGE_GABA\", \"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "    #(\"PF_RE_TH_Glut\", [\"CTX_CGE_GABA\", \"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "    (\"CNU_HYA_Glut\", [\"CTX_CGE_GABA\", \"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "    (\"CNU_HYA_GABA\", [\"CTX_CGE_GABA\", \"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "]\n",
    "# ct_merged_data = merge_ct_bias_datasets(ASD_SC_Bias, DDD_rmASD_SC_Bias, suffixes=('_ASD', '_DD'))\n",
    "# _ = cluster_residual_boxplot(\n",
    "#     ct_merged_data,\n",
    "#     cluster_dict,\n",
    "#     metric=\"residual\",\n",
    "#     palette=plot_palette,\n",
    "#     figsize=(12,8),\n",
    "#     pairwise_tests=pairwise_tests\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def bh_fdr(pvals):\n",
    "    \"\"\"Benjamini–Hochberg FDR correction; returns adjusted p-values.\"\"\"\n",
    "    pvals = np.asarray(pvals, dtype=float)\n",
    "    n = np.sum(np.isfinite(pvals))\n",
    "    out = pvals.copy()\n",
    "    if n == 0:\n",
    "        return out\n",
    "    idx = np.where(np.isfinite(pvals))[0]\n",
    "    p = pvals[idx]\n",
    "    order = np.argsort(p)\n",
    "    ranked = p[order]\n",
    "    adj = ranked * n / (np.arange(1, n + 1))\n",
    "    adj = np.minimum.accumulate(adj[::-1])[::-1]\n",
    "    adj = np.clip(adj, 0, 1)\n",
    "    out_idx = np.empty_like(adj)\n",
    "    out_idx[order] = adj\n",
    "    out[idx] = out_idx\n",
    "    return out\n",
    "\n",
    "def p_to_star(p):\n",
    "    if p < 1e-4: return \"****\"\n",
    "    if p < 1e-3: return \"***\"\n",
    "    if p < 1e-2: return \"**\"\n",
    "    if p < 5e-2: return \"*\"\n",
    "    return \"ns\"\n",
    "\n",
    "def wrap_label(s, max_len=16):\n",
    "    if len(s) <= max_len:\n",
    "        return s\n",
    "    for sep in [\" \", \"_\"]:\n",
    "        if sep in s:\n",
    "            parts = s.split(sep)\n",
    "            line1, line2 = [], []\n",
    "            cur = 0\n",
    "            for part in parts:\n",
    "                add = len(part) + (1 if line1 else 0)\n",
    "                if cur + add <= max_len:\n",
    "                    line1.append(part); cur += add\n",
    "                else:\n",
    "                    line2.append(part)\n",
    "            if line2:\n",
    "                return \" \".join(line1) + \"\\n\" + \" \".join(line2)\n",
    "    return s\n",
    "\n",
    "def cluster_residual_boxplot(\n",
    "    results_df,\n",
    "    cluster_dict,\n",
    "    metric=\"residual\",\n",
    "    palette=None,\n",
    "    figsize=(12, 8),\n",
    "    pairwise_tests=None,\n",
    "    p_adjust=\"fdr_bh\",     # None or \"fdr_bh\"\n",
    "    p_style=\"stars\",       # \"stars\" or \"exact\"\n",
    "    show_ns=False,\n",
    "    wrap_xticks=True,\n",
    "    wrap_len=16,\n",
    "    point_size=2.2,\n",
    "    point_alpha=0.16,\n",
    "    point_color=\"0.2\",\n",
    "    rasterize_points=True,\n",
    "    box_width=0.6,\n",
    "    fontsize=12,\n",
    "    title=None,\n",
    "    show=True\n",
    "):\n",
    "    # ---- checks ----\n",
    "    if metric not in results_df.columns:\n",
    "        raise ValueError(f\"metric='{metric}' not in results_df.columns\")\n",
    "    if pairwise_tests is None:\n",
    "        pairwise_tests = []\n",
    "\n",
    "    cluster_labels = list(cluster_dict.keys())\n",
    "\n",
    "    # palette\n",
    "    if palette is None:\n",
    "        palette = sns.color_palette(\"tab10\", n_colors=len(cluster_labels))\n",
    "    elif isinstance(palette, dict):\n",
    "        palette = [palette[k] for k in cluster_labels]\n",
    "    else:\n",
    "        if len(palette) < len(cluster_labels):\n",
    "            raise ValueError(f\"palette has {len(palette)} colors but needs {len(cluster_labels)}.\")\n",
    "        palette = palette[:len(cluster_labels)]\n",
    "\n",
    "    # ---- build plot_df ----\n",
    "    vals_list, n_points = [], []\n",
    "    for k in cluster_labels:\n",
    "        v = results_df.loc[cluster_dict[k], metric].dropna().values\n",
    "        vals_list.append(v)\n",
    "        n_points.append(len(v))\n",
    "\n",
    "    plot_df = pd.DataFrame({\n",
    "        \"Cluster\": np.repeat(cluster_labels, n_points),\n",
    "        metric: np.concatenate(vals_list) if len(vals_list) else np.array([])\n",
    "    })\n",
    "\n",
    "    # ---- plot ----\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_context(\"paper\", font_scale=1.0)\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=240)\n",
    "\n",
    "    sns.boxplot(\n",
    "        x=\"Cluster\", y=metric, data=plot_df,\n",
    "        palette=palette, width=box_width,\n",
    "        showfliers=False, linewidth=1.0,\n",
    "        showmeans=True,\n",
    "        meanprops={\"marker\": \"o\", \"markerfacecolor\": \"black\",\n",
    "                   \"markeredgecolor\": \"black\", \"markersize\": 5},\n",
    "        ax=ax\n",
    "    )\n",
    "    for patch in ax.artists:\n",
    "        patch.set_alpha(0.88)\n",
    "\n",
    "    sns.stripplot(\n",
    "        x=\"Cluster\", y=metric, data=plot_df,\n",
    "        color=point_color, alpha=point_alpha,\n",
    "        jitter=0.22, size=point_size,\n",
    "        ax=ax\n",
    "    )\n",
    "    if rasterize_points:\n",
    "        for coll in ax.collections:\n",
    "            coll.set_rasterized(True)\n",
    "\n",
    "    ax.axhline(0, color=\"black\", linewidth=2.0, alpha=0.85, linestyle=\"--\", zorder=2)\n",
    "    ax.grid(axis=\"y\", color=\"0.86\", linestyle=\"-\", linewidth=0.8)\n",
    "    ax.grid(axis=\"x\", visible=False)\n",
    "\n",
    "    #ax.set_ylabel(metric.capitalize(), fontsize=fontsize + 2)\n",
    "    ax.set_ylabel(\"Bias Residual\", fontsize=fontsize * 1.8)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"y\", labelsize=fontsize)\n",
    "\n",
    "    xticklabels = cluster_labels\n",
    "    if wrap_xticks:\n",
    "        xticklabels = [wrap_label(s, max_len=wrap_len) for s in xticklabels]\n",
    "    ax.set_xticklabels(xticklabels, rotation=35, ha=\"right\", fontsize=fontsize*1.3)\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=fontsize + 2)\n",
    "\n",
    "    # ---- prepare comparisons ----\n",
    "    def get_vals(group):\n",
    "        group = [group] if isinstance(group, str) else list(group)\n",
    "        arrs = []\n",
    "        for k in group:\n",
    "            if k not in cluster_dict:\n",
    "                continue\n",
    "            arrs.append(results_df.loc[cluster_dict[k], metric].dropna().values)\n",
    "        return np.concatenate(arrs) if len(arrs) else np.array([])\n",
    "\n",
    "    tests = []\n",
    "    for gA, gB in pairwise_tests:\n",
    "        A = get_vals(gA)\n",
    "        B = get_vals(gB)\n",
    "        if len(A) == 0 or len(B) == 0:\n",
    "            continue\n",
    "        # x positions (mean index if multi-group)\n",
    "        gA_list = [gA] if isinstance(gA, str) else list(gA)\n",
    "        gB_list = [gB] if isinstance(gB, str) else list(gB)\n",
    "        x1 = float(np.mean([cluster_labels.index(k) for k in gA_list]))\n",
    "        x2 = float(np.mean([cluster_labels.index(k) for k in gB_list]))\n",
    "        _, p = mannwhitneyu(A, B, alternative=\"two-sided\")\n",
    "        local_top = max(np.max(A), np.max(B))\n",
    "        tests.append({\"x1\": x1, \"x2\": x2, \"p\": p, \"local_top\": local_top})\n",
    "\n",
    "    if len(tests) == 0:\n",
    "        plt.subplots_adjust(bottom=0.28, top=0.92)\n",
    "        if show:\n",
    "            plt.show()\n",
    "        return plot_df\n",
    "\n",
    "    # adjust p\n",
    "    raw_p = np.array([t[\"p\"] for t in tests], dtype=float)\n",
    "    adj_p = bh_fdr(raw_p) if p_adjust == \"fdr_bh\" else raw_p\n",
    "    for t, p_adj in zip(tests, adj_p):\n",
    "        t[\"p_adj\"] = p_adj\n",
    "\n",
    "    # ---- annotate (sorted with Python, fixes your crash) ----\n",
    "    y_min = float(np.nanmin(plot_df[metric].values))\n",
    "    y_max = float(np.nanmax(plot_df[metric].values))\n",
    "    y_range = (y_max - y_min) if y_max != y_min else 1.0\n",
    "    h = 0.020 * y_range\n",
    "    clearance = 0.03 * y_range\n",
    "    y_step = 0.10 * y_range\n",
    "\n",
    "    # sort: lower brackets first, then shorter spans\n",
    "    tests_sorted = sorted(tests, key=lambda t: (t[\"local_top\"], abs(t[\"x2\"] - t[\"x1\"])))\n",
    "\n",
    "    placed = []  # (xlo, xhi, ylo, yhi)\n",
    "    for t in tests_sorted:\n",
    "        p_use = t[\"p_adj\"] if p_adjust else t[\"p\"]\n",
    "        label = p_to_star(p_use) if p_style == \"stars\" else f\"$p$={p_use:.2e}\"\n",
    "        if (label == \"ns\") and (not show_ns):\n",
    "            continue\n",
    "\n",
    "        x1, x2 = t[\"x1\"], t[\"x2\"]\n",
    "        xlo, xhi = min(x1, x2), max(x1, x2)\n",
    "\n",
    "        y = t[\"local_top\"] + clearance\n",
    "        while True:\n",
    "            yhi = y + h\n",
    "            overlap = False\n",
    "            for pxlo, pxhi, pylo, pyhi in placed:\n",
    "                if not (xhi < pxlo - 0.3 or xlo > pxhi + 0.3):\n",
    "                    if not (yhi < pylo - 0.01 or y > pyhi + 0.01):\n",
    "                        overlap = True\n",
    "                        break\n",
    "            if not overlap:\n",
    "                break\n",
    "            y += y_step\n",
    "\n",
    "        placed.append((xlo, xhi, y, y + h))\n",
    "        ax.plot([x1, x1, x2, x2], [y, y + h, y + h, y], lw=1.1, c=\"k\", alpha=0.9)\n",
    "        ax.text((x1 + x2) / 2, y + h - 2*h, label, ha=\"center\", va=\"bottom\", fontsize=fontsize*2.0)\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.28, top=0.92)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cluster_residual_boxplot(\n",
    "    ct_merged_data,\n",
    "    cluster_dict,\n",
    "    metric=\"residual\",\n",
    "    palette=plot_palette,\n",
    "    figsize=(12,8),\n",
    "    pairwise_tests=pairwise_tests,\n",
    "    p_adjust=\"fdr_bh\",\n",
    "    p_style=\"stars\",\n",
    "    show_ns=False,\n",
    "    wrap_xticks=True,\n",
    "    wrap_len=16,\n",
    "    point_size=2.2,\n",
    "    point_alpha=0.16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Extract values for PF_Cluster\n",
    "pf_values = ct_merged_data[ct_merged_data.index.isin(PF_Cluster)][\"EFFECT_ASD\"].dropna().values\n",
    "\n",
    "# Non-PF_Cluster as background\n",
    "background_values = ct_merged_data[~ct_merged_data.index.isin(PF_Cluster)][\"EFFECT_ASD\"].dropna().values\n",
    "\n",
    "# Mann-Whitney U test: alternative='greater' tests if PF_Cluster > background\n",
    "stat, pval = mannwhitneyu(pf_values, background_values, alternative='greater')\n",
    " \n",
    "print(\"Mann-Whitney U test for PF_Cluster vs others (greater):\")\n",
    "print(f\"U statistic: {stat:.2f}, p-value: {pval:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(ct_merged_data[\"class_id_label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(ct_merged_data[\"subclass_id_label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "'152 RE-Xi Nox4 Glut'\n",
    "'154 PF Fzd5 Glut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_merged_data[\"residual\"].hist(bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIP_Glut = [x for x in CT_Anno[CT_Anno['subclass_id_label'].isin(HIP)].index.tolist() if x in ct_merged_data.index]\n",
    "Other_IT_ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\n",
    "    \"D1/D2 MSN\": STR_D1D2,\n",
    "    \"CNU_LGE_GABA (Other)\": Other_LGE,\n",
    "    \"PF_RE_TH_Glut\": RU_PF,\n",
    "    \"TH_Glut (Other)\": Other_TH_Cluster,\n",
    "    \"HIP_Glut\": HIP_Glut,\n",
    "    \"AMY_Glut\": AMY_Glut,\n",
    "    \"Other_IT_ET\": Other_IT_ET,\n",
    "    \"NP_CT_L6b_Glut\": NP_Cluster,\n",
    "    \"CTX_MGE_GABA\": MGE_Cluster,\n",
    "}\n",
    "\n",
    "plot_palette = [\"orange\", \"green\", \"purple\", \"red\", \"blue\", \"yellow\", \"pink\"]\n",
    "\n",
    "pairwise_tests = [\n",
    "    (\"D1/D2 MSN\", \"CNU_LGE_GABA (Other)\"),\n",
    "    (\"PF_RE_TH_Glut\", \"TH_Glut (Other)\"),\n",
    "    #(\"CTX_CGE_GABA\", [\"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "    (\"HIP_Glut\", \"Other_IT_ET\"),\n",
    "    #(\"PF_RE_TH_Glut\", [\"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "]\n",
    "ct_merged_data = merge_ct_bias_datasets(ASD_SC_Bias, DDD_rmASD_SC_Bias, suffixes=('_ASD', '_DD'))\n",
    "_ = cluster_residual_boxplot(\n",
    "    ct_merged_data,\n",
    "    cluster_dict,\n",
    "    metric=\"residual\",\n",
    "    palette=plot_palette,\n",
    "    figsize=(12,8),\n",
    "    pairwise_tests=pairwise_tests\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all cell type classes using the shown framework\n",
    "\n",
    "# Get all unique class labels that appear in ct_merged_data\n",
    "all_class_labels = sorted(ct_merged_data[\"class_id_label\"].unique())\n",
    "\n",
    "# Build a cluster dict mapping each class label to its indices\n",
    "cluster_dict = {\n",
    "    label: [idx for idx in CT_Anno[CT_Anno['class_id_label'] == label].index if idx in ct_merged_data.index]\n",
    "    for label in all_class_labels\n",
    "}\n",
    "\n",
    "\n",
    "num_classes = len(cluster_dict)\n",
    "plot_palette = sns.color_palette(\"tab20\", num_classes)\n",
    "\n",
    "# Optionally, do not run pairwise_tests for all (too many comparisons)\n",
    "pairwise_tests = []\n",
    "\n",
    "# Re-merge (to ensure you have right columns/metrics)\n",
    "ct_merged_data = merge_ct_bias_datasets(ASD_SC_Bias, DDD_rmASD_SC_Bias, suffixes=('_ASD', '_DD'))\n",
    "\n",
    "_ = cluster_residual_boxplot(\n",
    "    ct_merged_data,\n",
    "    cluster_dict,\n",
    "    metric=\"residual\",\n",
    "    palette=plot_palette,\n",
    "    figsize=(max(12, num_classes*0.7), 8),\n",
    "    pairwise_tests=pairwise_tests\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "# Constraint Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad4 = pd.read_csv(\"/home/jw3514/Work/data/gnomad/gnomad.v4.0.constraint_metrics.tsv\", sep=\"\\t\")\n",
    "search_text = 'ENST'\n",
    "gnomad4 = gnomad4[(gnomad4[\"transcript\"].str.contains(search_text))]\n",
    "gnomad4 = gnomad4[gnomad4[\"mane_select\"]==True]\n",
    "for i, row in gnomad4.iterrows():\n",
    "    symbol = row[\"gene\"]\n",
    "    gnomad4.loc[i, \"Entrez\"] = int(GeneSymbol2Entrez.get(symbol, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad4[\"lof.oe_ci.upper\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take subset where lof.oe_ci.upper is in the bottom 10%\n",
    "bottom_10_percent_threshold = gnomad4[\"lof.oe_ci.upper\"].quantile(0.1)\n",
    "gnomad4_bottom10 = gnomad4[gnomad4[\"lof.oe_ci.upper\"] <= bottom_10_percent_threshold]\n",
    "columns_to_keep_g4 = [\"Entrez\", \"gene\", \"lof.pLI\", \"lof.z_score\", \"lof.oe_ci.upper\"]\n",
    "gnomad4_bottom10 = gnomad4_bottom10[columns_to_keep_g4]\n",
    "gnomad4_bottom10 = gnomad4_bottom10.sort_values(by=\"lof.oe_ci.upper\", ascending=True)\n",
    "\n",
    "# Make sure Entrez is int and exclude rows with Entrez = 0\n",
    "gnomad4_bottom10[\"Entrez\"] = gnomad4_bottom10[\"Entrez\"].astype(int)\n",
    "gnomad4_bottom10 = gnomad4_bottom10[gnomad4_bottom10[\"Entrez\"] != 0]\n",
    "gnomad4_bottom10_excludeASD = gnomad4_bottom10[gnomad4_bottom10[\"gene\"] != \"ENSG00000186092\"]\n",
    "gnomad4_bottom10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_10_percent_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad4_bottom10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### ASD vs Constraint with Different constraint thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### pLI 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE PLI TO DEFINE TOP CONSTRAINED GENES; AVOID VARIABLE NAME COLLISION\n",
    "gnomad4_top_PLI = gnomad4[gnomad4[\"lof.pLI\"] > 0.99]\n",
    "print(gnomad4_top_PLI.shape)\n",
    "#constraint_gw_top_PLI = dict(zip(gnomad4_top_PLI[\"Entrez\"], 1/gnomad4_top_PLI[\"lof.oe_ci.upper\"]))\n",
    "constraint_gw_top_PLI = dict(zip(gnomad4_top_PLI[\"Entrez\"], [1]*len(gnomad4_top_PLI)))\n",
    "Dict2Fil(constraint_gw_top_PLI, ProjDIR+\"/dat/Genetics/GeneWeights/\"+\"constraint_top_decile_PLI.gw\")\n",
    "constraint_top_PLI_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, constraint_gw_top_PLI)\n",
    "constraint_top_PLI_STR_Bias[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in constraint_top_PLI_STR_Bias.index.values]\n",
    "merged_data_ASD_Constraint_PLI = merge_str_bias_datasets(Spark_ASD_STR_Bias, constraint_top_PLI_STR_Bias, suffixes=('_ASD', '_Constraint'))\n",
    "plot_structure_bias_comparison(merged_data_ASD_Constraint_PLI, suffixes=('_ASD', '_Constraint'),  metric=\"EFFECT\", show_region_legend=True)\n",
    "\n",
    "merged_data_DDD_Constraint_PLI = merge_str_bias_datasets(DDD_STR_Bias, constraint_top_PLI_STR_Bias, suffixes=('_DD', '_Constraint'))\n",
    "plot_structure_bias_comparison(merged_data_DDD_Constraint_PLI, suffixes=('_DD', '_Constraint'),  metric=\"EFFECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate circuit score for pLI constraint genes\n",
    "score_Constraint = calculate_circuit_scores(constraint_top_PLI_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.5 Residual Structures: Constraint (LOEUF top 25%) vs ASD\n",
    "\n",
    "def plot_top_residual_structures(merged_data, top_n=30, top_threshold=40, \n",
    "                                name1=\"ASD\", name2=\"DD\", figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Plot brain structures with largest residuals from regression analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    merged_data : DataFrame\n",
    "        Merged dataset with residual and region information\n",
    "    top_n : int\n",
    "        Number of top structures to display\n",
    "    top_threshold : int\n",
    "        Filter to structures in top N of at least one dataset\n",
    "    name1, name2 : str\n",
    "        Names of the two datasets being compared\n",
    "    figsize : tuple\n",
    "        Figure size (width, height)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    top_diff : DataFrame\n",
    "        Top structures with largest residuals\n",
    "    \"\"\"\n",
    "    # Filter to only structures that appear in top threshold of at least one dataset\n",
    "    top_structures = merged_data[(merged_data[f\"Rank_{name1}\"] <= top_threshold) | \n",
    "                                (merged_data[f\"Rank_{name2}\"] <= top_threshold)]\n",
    "\n",
    "    print(f\"Total structures in top {top_threshold} of at least one dataset: {len(top_structures)}\")\n",
    "\n",
    "    # Sort by absolute difference for top structures only\n",
    "    top_structures = top_structures.copy()\n",
    "    top_structures[\"ABS_DIFF\"] = abs(merged_data[f\"residual\"])\n",
    "    top_structures = top_structures.sort_values('ABS_DIFF', ascending=True)\n",
    "\n",
    "    # Take the top N structures with largest differences from those in top threshold\n",
    "    top_n = min(top_n, len(top_structures))  # Use min to avoid index errors if fewer structures available\n",
    "    top_diff = top_structures.tail(top_n)  # Get largest differences\n",
    "\n",
    "    print(f\"Showing top {len(top_diff)} structures with largest differences (from top {top_threshold} filter)\")\n",
    "\n",
    "    # Define regions and colors\n",
    "    REGIONS_seq = ['Isocortex','Olfactory_areas', 'Cortical_subplate', \n",
    "                    'Hippocampus','Amygdala','Striatum', \n",
    "                    \"Thalamus\", \"Hypothalamus\", \"Midbrain\", \n",
    "                    \"Medulla\", \"Pallidum\", \"Pons\", \n",
    "                    \"Cerebellum\"]\n",
    "    REG_COR_Dic = dict(zip(REGIONS_seq, [\"#268ad5\", \"#D5DBDB\", \"#7ac3fa\", \n",
    "                                        \"#2c9d39\", \"#742eb5\", \"#ed8921\", \n",
    "                                        \"#e82315\", \"#E6B0AA\", \"#f6b26b\",  \n",
    "                                        \"#20124d\", \"#2ECC71\", \"#D2B4DE\", \n",
    "                                        \"#ffd966\", ]))\n",
    "\n",
    "    # Create publication-quality plot of residuals for top_diff structures\n",
    "    plt.rcParams.update({'font.size': 12, 'font.family': 'Arial'})\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=300)\n",
    "\n",
    "    # Sort top_diff by residuals for better visualization\n",
    "    top_diff_sorted = top_diff.sort_values('ABS_DIFF', ascending=True)\n",
    "\n",
    "    # Create colors based on region\n",
    "    colors = [REG_COR_Dic.get(region, '#808080') for region in top_diff_sorted['Region']]\n",
    "\n",
    "    # Create horizontal bar plot with better styling\n",
    "    bars = ax.barh(range(len(top_diff_sorted)), \n",
    "                   top_diff_sorted[f'residual'], \n",
    "                   color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "    # Customize the plot with publication-quality styling\n",
    "    ax.set_yticks(range(len(top_diff_sorted)))\n",
    "    ax.set_yticklabels([name.replace('_', ' ') for name in top_diff_sorted.index], \n",
    "                       fontsize=12, fontweight='normal')\n",
    "    ax.set_xlabel(f'Residuals ({name1} vs {name2})', fontsize=14, fontweight='bold')\n",
    "    #ax.set_title(f'Top {len(top_diff)} Brain Structures with Largest Residuals', \n",
    "    #             fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "    # Remove top and right spines for cleaner look\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(1)\n",
    "    ax.spines['bottom'].set_linewidth(1)\n",
    "\n",
    "    # Add subtle grid\n",
    "    ax.grid(True, axis='x', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # Add vertical line at x=0 with better styling\n",
    "    ax.axvline(x=0, color='black', linestyle='-', alpha=0.7, linewidth=1)\n",
    "\n",
    "    # Create legend for regions with better styling\n",
    "    unique_regions = sorted(list(set(top_diff_sorted['Region'])))\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=REG_COR_Dic.get(region, '#808080'), \n",
    "                                    alpha=0.8, edgecolor='black', linewidth=0.5) \n",
    "                       for region in unique_regions if region in REG_COR_Dic]\n",
    "    legend_labels = [region.replace('_', ' ') for region in unique_regions if region in REG_COR_Dic]\n",
    "\n",
    "    if legend_elements:\n",
    "        ax.legend(\n",
    "            legend_elements, legend_labels,\n",
    "            loc='center left',       # You can change this to your preferred location, e.g. 'center left'\n",
    "            bbox_to_anchor=(0.85, 0.2), # Pushes legend outside right of plot at vertical center\n",
    "            fontsize=10, \n",
    "            frameon=True,\n",
    "            fancybox=True,\n",
    "            shadow=True,\n",
    "            framealpha=0.9\n",
    "        )\n",
    "\n",
    "    # Adjust layout and margins\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.3)  # Make room for structure names\n",
    "    plt.show()\n",
    "    \n",
    "    return top_diff\n",
    "\n",
    "# Call the function\n",
    "merged_data_eval = merged_data_ASD_Constraint_PLI[merged_data_ASD_Constraint_PLI.index.isin(Circuit_STRs)]\n",
    "top_diff = plot_top_residual_structures(merged_data_eval, top_n=20, top_threshold=40,\n",
    "                                       name1=\"ASD\", name2=\"Constraint\", figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare DDD vs Constraint\n",
    "merged_data_eval = merged_data_DDD_Constraint_PLI[merged_data_DDD_Constraint_PLI.index.isin(Circuit_STRs)]\n",
    "top_diff = plot_top_residual_structures(\n",
    "    merged_data_eval, \n",
    "    top_n=20, \n",
    "    top_threshold=40,\n",
    "    name1=\"DD\", \n",
    "    name2=\"Constraint\", \n",
    "    figsize=(6, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pLI SC Bias\n",
    "pLI_SC_Bias = MouseCT_AvgZ_Weighted(CT_BiasMat, constraint_gw_top_PLI)\n",
    "pLI_SC_Bias = add_class(pLI_SC_Bias, CT_Anno)\n",
    "pLI_SC_Bias.to_csv(ProjDIR + \"/results/CT_Z2/pLI_SC_Bias.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_scatter_mouseCT(pLI_SC_Bias, ASD_SC_Bias, name1=\"Constraint Cell Type Bias\", name2=\"ASD Cell Type Bias\", effect_col1=\"EFFECT\", effect_col2=\"EFFECT\", dpi=240)\n",
    "plot_correlation_scatter_mouseCT(pLI_SC_Bias, DDD_SC_Bias, name1=\"Constraint Cell Type Bias\", name2=\"DD Cell Type Bias\", effect_col1=\"EFFECT\", effect_col2=\"EFFECT\", dpi=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CNU_LGE_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '09 CNU-LGE GABA'].index.tolist() if x in ct_merged_data.index]\n",
    "IT_ET_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '01 IT-ET Glut'].index.tolist() if x in ct_merged_data.index]\n",
    "NP_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '02 NP-CT-L6b Glut'].index.tolist() if x in ct_merged_data.index]\n",
    "CGE_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '06 CTX-CGE GABA'].index.tolist() if x in ct_merged_data.index]\n",
    "MGE_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '07 CTX-MGE GABA'].index.tolist() if x in ct_merged_data.index]\n",
    "\n",
    "\n",
    "D1D2_labels = ['061 STR D1 Gaba', '062 STR D2 Gaba']\n",
    "STR_D1D2 = [idx for idx in CT_Anno[CT_Anno['subclass_id_label'].isin(D1D2_labels)].index if idx in ct_merged_data.index]\n",
    "Other_LGE = [idx for idx in CT_Anno[CT_Anno['class_id_label'] == '09 CNU-LGE GABA'].index if idx in ct_merged_data.index and idx not in STR_D1D2]\n",
    "\n",
    "HIP = ['016 CA1-ProS Glut', '017 CA3 Glut']\n",
    "HIP_Glut = [x for x in CT_Anno[CT_Anno['subclass_id_label'].isin(HIP)].index.tolist() if x in ct_merged_data.index]\n",
    "\n",
    "\n",
    "RU_Cluster = [x for x in CT_Anno[CT_Anno['subclass_id_label'] == '152 RE-Xi Nox4 Glut'].index.tolist() if x in ct_merged_data.index]\n",
    "PF_Cluster = [x for x in CT_Anno[CT_Anno['subclass_id_label'] == '154 PF Fzd5 Glut'].index.tolist() if x in ct_merged_data.index]\n",
    "RU_PF = RU_Cluster + PF_Cluster\n",
    "Other_TH_Cluster = [x for x in CT_Anno[CT_Anno['class_id_label'] == '18 TH Glut'].index.tolist() if x in ct_merged_data.index and x not in RU_PF]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "### LOEUF top 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take subset where lof.oe_ci.upper is in the bottom 25%\n",
    "bottom_25_percent_threshold = gnomad4[\"lof.oe_ci.upper\"].quantile(0.25)\n",
    "gnomad4_bottom25 = gnomad4[gnomad4[\"lof.oe_ci.upper\"] <= bottom_25_percent_threshold]\n",
    "columns_to_keep_g4 = [\"Entrez\", \"gene\", \"lof.pLI\", \"lof.z_score\", \"lof.oe_ci.upper\"]\n",
    "gnomad4_bottom25 = gnomad4_bottom25[columns_to_keep_g4]\n",
    "gnomad4_bottom25 = gnomad4_bottom25.sort_values(by=\"lof.oe_ci.upper\", ascending=True)\n",
    "\n",
    "# Make sure Entrez is int and exclude rows with Entrez = 0\n",
    "gnomad4_bottom25[\"Entrez\"] = gnomad4_bottom25[\"Entrez\"].astype(int)\n",
    "gnomad4_bottom25 = gnomad4_bottom25[gnomad4_bottom25[\"Entrez\"] != 0]\n",
    "gnomad4_bottom25_excludeASD = gnomad4_bottom25[gnomad4_bottom25[\"gene\"] != \"ENSG00000186092\"]\n",
    "gnomad4_bottom25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE LOEUF TOP 25% TO DEFINE TOP CONSTRAINED GENES\n",
    "print(gnomad4_bottom25.shape)\n",
    "# Create gene weights (using equal weights of 1, similar to pLI analysis)\n",
    "constraint_gw_top_LOEUF25 = dict(zip(gnomad4_bottom25[\"Entrez\"], [1]*len(gnomad4_bottom25)))\n",
    "Dict2Fil(constraint_gw_top_LOEUF25, ProjDIR+\"/dat/Genetics/GeneWeights/\"+\"constraint_top25_LOEUF.gw\")\n",
    "\n",
    "# Calculate structure bias\n",
    "constraint_top_LOEUF25_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, constraint_gw_top_LOEUF25)\n",
    "constraint_top_LOEUF25_STR_Bias[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in constraint_top_LOEUF25_STR_Bias.index.values]\n",
    "\n",
    "# Compare with ASD\n",
    "merged_data_ASD_Constraint_LOEUF25 = merge_str_bias_datasets(Spark_ASD_STR_Bias, constraint_top_LOEUF25_STR_Bias, suffixes=('_ASD', '_Constraint'))\n",
    "plot_structure_bias_comparison(merged_data_ASD_Constraint_LOEUF25, suffixes=('_ASD', '_Constraint'),  metric=\"EFFECT\")\n",
    "\n",
    "# Compare with DDD\n",
    "merged_data_DDD_Constraint_LOEUF25 = merge_str_bias_datasets(DDD_rmASD_STR_Bias, constraint_top_LOEUF25_STR_Bias, suffixes=('_DD (exclude ASD)', '_Constraint'))\n",
    "plot_structure_bias_comparison(merged_data_DDD_Constraint_LOEUF25, suffixes=('_DD (exclude ASD)', '_Constraint'),  metric=\"EFFECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis: ASD vs Constraint (LOEUF top 25%)\n",
    "merged_data_eval_LOEUF25 = merged_data_ASD_Constraint_LOEUF25[merged_data_ASD_Constraint_LOEUF25.index.isin(Circuit_STRs)]\n",
    "top_diff_ASD_LOEUF25 = plot_top_residual_structures(merged_data_eval_LOEUF25, top_n=20, top_threshold=40,\n",
    "                                       name1=\"ASD\", name2=\"Constraint\", figsize=(6, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 2.6 Circuit Connectivity Scores\n",
    "\n",
    "# Calculate circuit scores\n",
    "score_ASD = calculate_circuit_scores(Spark_ASD_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n",
    "score_DDD = calculate_circuit_scores(DDD_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n",
    "score_DDD_rmASD = calculate_circuit_scores(DDD_rmASD_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n",
    "score_Constraint_LOEUF25 = calculate_circuit_scores(constraint_top_LOEUF25_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n",
    "\n",
    "# Calculate pLI constraint structure bias and circuit score\n",
    "constraint_top_PLI_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, constraint_gw_top_PLI)\n",
    "constraint_top_PLI_STR_Bias[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in constraint_top_PLI_STR_Bias.index.values]\n",
    "score_Constraint_PLI = calculate_circuit_scores(constraint_top_PLI_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n",
    "score_DDD = calculate_circuit_scores(DDD_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n",
    "score_DDD_rmASD = calculate_circuit_scores(DDD_rmASD_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n",
    "score_Constraint = calculate_circuit_scores(constraint_top_LOEUF25_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax1 = plt.subplots(1,1, dpi=480, figsize=(10,6), facecolor='none')\n",
    "\n",
    "fig.patch.set_alpha(0)\n",
    "ax1.patch.set_alpha(0)\n",
    "\n",
    "BarLen = 34.1\n",
    "#BarLen = 47.5\n",
    "\n",
    "topNs = list(range(200, 5, -1))  # Define topNs based on the range used in calculate_circuit_scores\n",
    "\n",
    "# Use different colors for each score profile\n",
    "ASD_color = \"#d62728\"  # changed ASD to red\n",
    "DDD_color = \"#1f77b4\"\n",
    "rmASD_color = \"#ff7f0e\"\n",
    "Constraint_color = \"#2ca02c\"\n",
    "siblings_color = \"grey\"\n",
    "# ax1.plot(topNs, score_ASD, color=ASD_color, marker=\"o\", markersize=5, lw=1,\n",
    "#          ls=\"dashed\", label=\"ASD\", alpha=0.5)\n",
    "# ax1.plot(topNs, score_DDD, color=DDD_color, marker=\"o\", markersize=5, lw=1,\n",
    "#          ls=\"dashed\", label=\"DD\", alpha=0.9)\n",
    "ax1.plot(topNs, score_DDD_rmASD, color=rmASD_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"DD (exclude ASD)\", alpha=0.9)\n",
    "ax1.plot(topNs, score_Constraint, color=Constraint_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"Constraint Genes\", alpha=0.9)\n",
    "\n",
    "cont = np.median(Cont_Distance, axis=0)\n",
    "lower = np.percentile(Cont_Distance, 50-BarLen, axis=0)\n",
    "upper = np.percentile(Cont_Distance, 50+BarLen, axis=0)\n",
    "ax1.errorbar(topNs, cont, color=siblings_color, marker=\"o\", markersize=1.5, lw=1,\n",
    "             yerr=(cont - lower, upper - cont), ls=\"dashed\", label=\"Siblings\")\n",
    "\n",
    "ax1.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "ax1.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "ax1.set_xlim(0, 121)\n",
    "\n",
    "# Place legend inside the figure (upper right, just inside plot)\n",
    "ax1.legend(fontsize=13, loc='upper right', frameon=True)\n",
    "plt.tight_layout()  # Adjust layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell type bias already calculated in Section 3.5```\n",
    "LOEUF25_SC_Bias = pd.read_csv(ProjDIR + \"/results/CT_Z2/Constraint_top25_LOEUF_bias_addP_random.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOEUF25_SC_Bias.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plots: LOEUF top 25% vs ASD and DDD\n",
    "plot_correlation_scatter_mouseCT(LOEUF25_SC_Bias, ASD_SC_Bias, name1=\"Constraint (LOEUF25) Cell Type Bias\", name2=\"ASD Cell Type Bias\", effect_col1=\"EFFECT\", effect_col2=\"EFFECT\", dpi=240)\n",
    "plot_correlation_scatter_mouseCT(LOEUF25_SC_Bias, DDD_rmASD_SC_Bias, name1=\"Constraint (LOEUF25) Cell Type Bias\", name2=\"DD (exclude ASD) \\nCell Type Bias\", effect_col1=\"EFFECT\", effect_col2=\"EFFECT\", dpi=240)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_dict = {\n",
    "#     \"D1/D2 MSN\": STR_D1D2,\n",
    "#     \"CNU_LGE_GABA (Other)\": Other_LGE,\n",
    "#     \"PF_RE_TH_Glut\": RU_PF,\n",
    "#     \"TH_Glut (Other)\": Other_TH_Cluster,\n",
    "#     \"CNU_HYA_Glut\": AMY_HYA_Glut,\n",
    "#     \"CNU_HYA_GABA\": AMY_HYA_GABA,\n",
    "#     \"CTX_CGE_GABA\": CGE_Cluster,\n",
    "#     \"IT_ET_Glut\": IT_ET_Cluster,\n",
    "#     \"NP_CT_L6b_Glut\": NP_Cluster,\n",
    "#     \"CTX_MGE_GABA\": MGE_Cluster,\n",
    "# }\n",
    "\n",
    "# plot_palette = [\"orange\", \"green\", \"purple\", \"red\", \"blue\", \"yellow\", \"pink\"]\n",
    "\n",
    "# pairwise_tests = [\n",
    "#     (\"D1/D2 MSN\", \"CNU_LGE_GABA (Other)\"),\n",
    "#     (\"PF_RE_TH_Glut\", \"TH_Glut (Other)\"),\n",
    "#     #(\"CTX_CGE_GABA\", [\"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "#     (\"D1/D2 MSN\", [\"CTX_CGE_GABA\", \"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "#     #(\"PF_RE_TH_Glut\", [\"CTX_CGE_GABA\", \"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "#     #(\"CNU_HYA_Glut\", [\"CTX_CGE_GABA\", \"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "#     (\"CNU_HYA_GABA\", [\"CTX_CGE_GABA\", \"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "# ]\n",
    "# _ = cluster_residual_boxplot(\n",
    "#     ct_merged_data_LOEUF25,\n",
    "#     cluster_dict,\n",
    "#     metric=\"residual\",\n",
    "#     palette=plot_palette,\n",
    "#     figsize=(12,8),\n",
    "#     pairwise_tests=pairwise_tests\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell type residual analysis: ASD vs LOEUF top 25%\n",
    "ct_merged_data_LOEUF25 = merge_ct_bias_datasets(ASD_SC_Bias, LOEUF25_SC_Bias, suffixes=('_ASD', '_Constraint'))\n",
    "plot_palette = [\n",
    "    \"orange\",   # D1/D2 MSN\n",
    "    \"green\",    # CNU_LGE_GABA (Other)\n",
    "    \"purple\",   # PF_RE_TH_Glut\n",
    "    \"red\",      # TH_Glut (Other)\n",
    "    \"blue\",     # CNU_HYA_Glut\n",
    "    \"gold\",     # CNU_HYA_GABA\n",
    "    \"pink\",     # CTX_CGE_GABA\n",
    "    \"teal\",     # IT_ET_Glut\n",
    "    \"sienna\",   # NP_CT_L6b_Glut\n",
    "    \"indigo\"    # CTX_MGE_GABA\n",
    "]\n",
    "\n",
    "\n",
    "pairwise_tests = [\n",
    "    (\"D1/D2 MSN\", \"CNU_LGE_GABA (Other)\"),\n",
    "    (\"PF_RE_TH_Glut\", \"TH_Glut (Other)\"),\n",
    "    #(\"CTX_CGE_GABA\", [\"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"])\n",
    "    (\"D1/D2 MSN\", [\"CTX_CGE_GABA\", \"CTX_MGE_GABA\", \"NP_CT_L6b_Glut\", \"IT_ET_Glut\"]),\n",
    "]\n",
    "\n",
    "_ = cluster_residual_boxplot(\n",
    "    ct_merged_data_LOEUF25,\n",
    "    cluster_dict,\n",
    "    metric=\"residual\",\n",
    "    palette=plot_palette,\n",
    "    figsize=(12,8),\n",
    "    pairwise_tests=pairwise_tests\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cluster_residual_boxplot(\n",
    "    ct_merged_data_LOEUF25,\n",
    "    cluster_dict,\n",
    "    metric=\"residual\",\n",
    "    palette=plot_palette,\n",
    "    figsize=(12,8),\n",
    "    pairwise_tests=pairwise_tests,\n",
    "    p_adjust=\"fdr_bh\",\n",
    "    p_style=\"stars\",\n",
    "    show_ns=False,\n",
    "    wrap_xticks=True,\n",
    "    wrap_len=16,\n",
    "    point_size=2.2,\n",
    "    point_alpha=0.16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate circuit scores for LOEUF top 25%\n",
    "score_DDD_rmASD = calculate_circuit_scores(DDD_rmASD_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n",
    "score_Constraint_LOEUF25 = calculate_circuit_scores(constraint_top_LOEUF25_STR_Bias, IpsiInfoMat, sort_by=\"EFFECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot circuit scores comparison with LOEUF top 25%\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax1 = plt.subplots(1,1, dpi=480, figsize=(10,6), facecolor='none')\n",
    "\n",
    "fig.patch.set_alpha(0)\n",
    "ax1.patch.set_alpha(0)\n",
    "\n",
    "BarLen = 34.1\n",
    "\n",
    "topNs = list(range(200, 5, -1))\n",
    "\n",
    "# Use different colors for each score profile\n",
    "DDD_color = \"#1f77b4\"\n",
    "rmASD_color = \"#ff7f0e\"\n",
    "Constraint_LOEUF25_color = \"#2ca02c\"\n",
    "siblings_color = \"grey\"\n",
    "\n",
    "# ax1.plot(topNs, score_DDD, color=DDD_color, marker=\"o\", markersize=5, lw=1,\n",
    "#          ls=\"dashed\", label=\"DD\", alpha=0.9)\n",
    "ax1.plot(topNs, score_DDD_rmASD, color=rmASD_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"DD (exclude ASD)\", alpha=0.9)\n",
    "ax1.plot(topNs, score_Constraint_LOEUF25, color=Constraint_LOEUF25_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"Constraint Genes (LOEUF top 25%)\", alpha=0.9)\n",
    "\n",
    "cont = np.median(Cont_Distance, axis=0)\n",
    "lower = np.percentile(Cont_Distance, 50-BarLen, axis=0)\n",
    "upper = np.percentile(Cont_Distance, 50+BarLen, axis=0)\n",
    "ax1.errorbar(topNs, cont, color=siblings_color, marker=\"o\", markersize=1.5, lw=1,\n",
    "             yerr=(cont - lower, upper - cont), ls=\"dashed\", label=\"Siblings\")\n",
    "\n",
    "ax1.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "ax1.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "ax1.set_xlim(0, 121)\n",
    "\n",
    "ax1.legend(fontsize=13, loc='upper right', frameon=True)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### Comparison: pLI≥0.99 vs LOEUF top 25%\n",
    "\n",
    "Direct comparison between the two constraint gene selection criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare pLI vs LOEUF top 25% gene selections\n",
    "pLI_genes = set(constraint_gw_top_PLI.keys())\n",
    "LOEUF25_genes = set(constraint_gw_top_LOEUF25.keys())\n",
    "\n",
    "print(f\"pLI≥0.99 genes: {len(pLI_genes)}\")\n",
    "print(f\"LOEUF top 25% genes: {len(LOEUF25_genes)}\")\n",
    "print(f\"Overlap: {len(pLI_genes & LOEUF25_genes)}\")\n",
    "print(f\"Only in pLI: {len(pLI_genes - LOEUF25_genes)}\")\n",
    "print(f\"Only in LOEUF top 25%: {len(LOEUF25_genes - pLI_genes)}\")\n",
    "print(f\"Jaccard index: {len(pLI_genes & LOEUF25_genes) / len(pLI_genes | LOEUF25_genes):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare pLI vs LOEUF top 25% structure biases directly\n",
    "merged_data_pLI_LOEUF25 = merge_str_bias_datasets(constraint_top_PLI_STR_Bias, constraint_top_LOEUF25_STR_Bias, suffixes=('_pLI', '_LOEUF25'))\n",
    "plot_structure_bias_comparison(merged_data_pLI_LOEUF25, suffixes=('_pLI', '_LOEUF25'),  metric=\"EFFECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison of correlations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Calculate correlations for pLI\n",
    "corr_pLI_ASD, pval_pLI_ASD = pearsonr(merged_data_ASD_Constraint_PLI[\"EFFECT_ASD\"], merged_data_ASD_Constraint_PLI[\"EFFECT_Constraint\"])\n",
    "corr_pLI_DDD, pval_pLI_DDD = pearsonr(merged_data_DDD_Constraint_PLI[\"EFFECT_DDD\"], merged_data_DDD_Constraint_PLI[\"EFFECT_Constraint\"])\n",
    "\n",
    "# Calculate correlations for LOEUF top 25%\n",
    "corr_LOEUF25_ASD, pval_LOEUF25_ASD = pearsonr(merged_data_ASD_Constraint_LOEUF25[\"EFFECT_ASD\"], merged_data_ASD_Constraint_LOEUF25[\"EFFECT_Constraint\"])\n",
    "corr_LOEUF25_DDD, pval_LOEUF25_DDD = pearsonr(merged_data_DDD_Constraint_LOEUF25[\"EFFECT_DDD\"], merged_data_DDD_Constraint_LOEUF25[\"EFFECT_Constraint\"])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Structure Bias Correlations\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\npLI≥0.99 ({len(pLI_genes)} genes):\")\n",
    "print(f\"  ASD correlation:  r = {corr_pLI_ASD:.3f}, p = {pval_pLI_ASD:.2e}\")\n",
    "print(f\"  DDD correlation:  r = {corr_pLI_DDD:.3f}, p = {pval_pLI_DDD:.2e}\")\n",
    "print(f\"\\nLOEUF top 25% ({len(LOEUF25_genes)} genes):\")\n",
    "print(f\"  ASD correlation:  r = {corr_LOEUF25_ASD:.3f}, p = {pval_LOEUF25_ASD:.2e}\")\n",
    "print(f\"  DDD correlation:  r = {corr_LOEUF25_DDD:.3f}, p = {pval_LOEUF25_DDD:.2e}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Type bias correlation comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"Cell Type Bias Correlations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate correlations for pLI cell type bias\n",
    "merged_pLI_ASD_CT = pd.merge(pLI_SC_Bias[['EFFECT']], ASD_SC_Bias[['EFFECT']], \n",
    "                             left_index=True, right_index=True, suffixes=('_pLI', '_ASD'))\n",
    "corr_ct_pLI_ASD, pval_ct_pLI_ASD = pearsonr(merged_pLI_ASD_CT['EFFECT_pLI'], merged_pLI_ASD_CT['EFFECT_ASD'])\n",
    "\n",
    "merged_pLI_DDD_CT = pd.merge(pLI_SC_Bias[['EFFECT']], DDD_SC_Bias[['EFFECT']], \n",
    "                             left_index=True, right_index=True, suffixes=('_pLI', '_DD'))\n",
    "corr_ct_pLI_DDD, pval_ct_pLI_DDD = pearsonr(merged_pLI_DDD_CT['EFFECT_pLI'], merged_pLI_DDD_CT['EFFECT_DDD'])\n",
    "\n",
    "# Calculate correlations for LOEUF top 25% cell type bias\n",
    "merged_LOEUF25_ASD_CT = pd.merge(LOEUF25_SC_Bias[['EFFECT']], ASD_SC_Bias[['EFFECT']], \n",
    "                                 left_index=True, right_index=True, suffixes=('_LOEUF25', '_ASD'))\n",
    "corr_ct_LOEUF25_ASD, pval_ct_LOEUF25_ASD = pearsonr(merged_LOEUF25_ASD_CT['EFFECT_LOEUF25'], merged_LOEUF25_ASD_CT['EFFECT_ASD'])\n",
    "\n",
    "merged_LOEUF25_DDD_CT = pd.merge(LOEUF25_SC_Bias[['EFFECT']], DDD_SC_Bias[['EFFECT']], \n",
    "                                 left_index=True, right_index=True, suffixes=('_LOEUF25', '_DD'))\n",
    "corr_ct_LOEUF25_DDD, pval_ct_LOEUF25_DDD = pearsonr(merged_LOEUF25_DDD_CT['EFFECT_LOEUF25'], merged_LOEUF25_DDD_CT['EFFECT_DDD'])\n",
    "\n",
    "print(f\"\\npLI≥0.99:\")\n",
    "print(f\"  ASD correlation:  r = {corr_ct_pLI_ASD:.3f}, p = {pval_ct_pLI_ASD:.2e}\")\n",
    "print(f\"  DDD correlation:  r = {corr_ct_pLI_DDD:.3f}, p = {pval_ct_pLI_DDD:.2e}\")\n",
    "print(f\"\\nLOEUF top 25%:\")\n",
    "print(f\"  ASD correlation:  r = {corr_ct_LOEUF25_ASD:.3f}, p = {pval_ct_LOEUF25_ASD:.2e}\")\n",
    "print(f\"  DDD correlation:  r = {corr_ct_LOEUF25_DDD:.3f}, p = {pval_ct_LOEUF25_DDD:.2e}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison: pLI vs LOEUF top 25% circuit scores\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=480, figsize=(18,6), facecolor='none')\n",
    "\n",
    "fig.patch.set_alpha(0)\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.patch.set_alpha(0)\n",
    "\n",
    "BarLen = 34.1\n",
    "topNs = list(range(200, 5, -1))\n",
    "\n",
    "# Color scheme\n",
    "ASD_color = \"#d62728\"\n",
    "DDD_color = \"#1f77b4\"\n",
    "rmASD_color = \"#ff7f0e\"\n",
    "Constraint_color = \"#2ca02c\"\n",
    "siblings_color = \"grey\"\n",
    "\n",
    "cont = np.median(Cont_Distance, axis=0)\n",
    "lower = np.percentile(Cont_Distance, 50-BarLen, axis=0)\n",
    "upper = np.percentile(Cont_Distance, 50+BarLen, axis=0)\n",
    "\n",
    "# Panel 1: pLI≥0.99\n",
    "ax1.plot(topNs, score_DDD, color=DDD_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"DD\", alpha=0.9)\n",
    "ax1.plot(topNs, score_DDD_rmASD, color=rmASD_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"DD (exclude ASD)\", alpha=0.9)\n",
    "ax1.plot(topNs, score_Constraint, color=Constraint_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"Constraint (pLI≥0.99)\", alpha=0.9)\n",
    "ax1.errorbar(topNs, cont, color=siblings_color, marker=\"o\", markersize=1.5, lw=1,\n",
    "             yerr=(cont - lower, upper - cont), ls=\"dashed\", label=\"Siblings\")\n",
    "ax1.set_xlabel(\"Structure Rank\", fontsize=15)\n",
    "ax1.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax1.set_title(\"pLI≥0.99\", fontsize=16, fontweight='bold')\n",
    "ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "ax1.set_xlim(0, 121)\n",
    "ax1.legend(fontsize=11, loc='upper right', frameon=True)\n",
    "\n",
    "# Panel 2: LOEUF top 25%\n",
    "ax2.plot(topNs, score_DDD, color=DDD_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"DD\", alpha=0.9)\n",
    "ax2.plot(topNs, score_DDD_rmASD, color=rmASD_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"DD (exclude ASD)\", alpha=0.9)\n",
    "ax2.plot(topNs, score_Constraint_LOEUF25, color=Constraint_color, marker=\"o\", markersize=5, lw=1,\n",
    "         ls=\"dashed\", label=\"Constraint (LOEUF top 25%)\", alpha=0.9)\n",
    "ax2.errorbar(topNs, cont, color=siblings_color, marker=\"o\", markersize=1.5, lw=1,\n",
    "             yerr=(cont - lower, upper - cont), ls=\"dashed\", label=\"Siblings\")\n",
    "ax2.set_xlabel(\"Structure Rank\", fontsize=15)\n",
    "ax2.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "ax2.set_title(\"LOEUF top 25%\", fontsize=16, fontweight='bold')\n",
    "ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "ax2.set_xlim(0, 121)\n",
    "ax2.legend(fontsize=11, loc='upper right', frameon=True)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "## Summary of pLI≥0.99 vs LOEUF top 25% Analysis\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "**Gene Selection:**\n",
    "- **pLI≥0.99**: Uses genes with high probability of being loss-of-function intolerant (pLI > 0.99)\n",
    "- **LOEUF top 25%**: Uses genes in the bottom quartile of LOEUF scores (most constrained)\n",
    "\n",
    "**Analyses Completed:**\n",
    "\n",
    "1. **Structure Bias Analysis**\n",
    "   - Calculated bias for both constraint criteria\n",
    "   - Compared correlations with ASD and DDD structure biases\n",
    "   \n",
    "2. **Residual Analysis** \n",
    "   - Identified brain structures with largest differences between ASD/DDD and constraint patterns\n",
    "   - Focused on circuit-relevant structures\n",
    "   \n",
    "3. **Cell Type Bias Analysis**\n",
    "   - Computed cell type-specific biases for both criteria\n",
    "   - Assessed correlations with ASD and DDD cell type patterns\n",
    "   - Performed residual boxplot analysis across cell type classes\n",
    "   \n",
    "4. **Circuit Connectivity Scores**\n",
    "   - Calculated circuit scores based on structure bias rankings\n",
    "   - Compared with DDD and control distributions\n",
    "\n",
    "5. **Direct Comparison**\n",
    "   - Gene overlap between the two selection criteria\n",
    "   - Correlation comparison for both structure and cell type levels\n",
    "   - Side-by-side visualization of circuit scores\n",
    "\n",
    "This comprehensive analysis allows direct comparison of results using different constraint gene selection approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPN CONSTRAINED GENES\n",
    "TOPN_CONS = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomad4_constraint_top61 = gnomad4_bottom10.head(2000)\n",
    "constraint_gw_top61 = dict(zip(gnomad4_constraint_top61[\"Entrez\"], 1/gnomad4_constraint_top61[\"lof.oe_ci.upper\"]))\n",
    "Dict2Fil(constraint_gw_top61, ProjDIR+\"/dat/Genetics/GeneWeights/\"+\"constraint_top_decile_LOEUF_top61.gw\")\n",
    "constraint_top61_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, constraint_gw_top61)\n",
    "constraint_top61_STR_Bias[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in constraint_top61_STR_Bias.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_ASD_Constraint = merge_str_bias_datasets(Spark_ASD_STR_Bias, constraint_top61_STR_Bias, suffixes=('_ASD', '_Constraint'))\n",
    "plot_structure_bias_comparison(merged_data_ASD_Constraint, suffixes=('_ASD', '_Constraint'),  metric=\"EFFECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_gw = dict(zip(gnomad4_bottom10[\"Entrez\"], 1/gnomad4_bottom10[\"lof.oe_ci.upper\"]))\n",
    "Dict2Fil(constraint_gw, ProjDIR+\"/dat/Genetics/GeneWeights/\"+\"constraint_top_decile_LOEUF.gw\")\n",
    "constraint_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, constraint_gw)\n",
    "constraint_STR_Bias[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in constraint_STR_Bias.index.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_ASD_Constraint = merge_str_bias_datasets(Spark_ASD_STR_Bias, constraint_STR_Bias, suffixes=('_ASD', '_Constraint'))\n",
    "plot_structure_bias_comparison(merged_data_ASD_Constraint, suffixes=('_ASD', '_Constraint'),  metric=\"EFFECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_DDD_Constraint = merge_str_bias_datasets(DDD_rmASD_STR_Bias, constraint_STR_Bias, suffixes=('_DD', '_Constraint'))\n",
    "plot_structure_bias_comparison(merged_data_DDD_Constraint, suffixes=('_DD', '_Constraint'),  metric=\"EFFECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_GW_filt_ASD = {k: v for k, v in constraint_gw.items() if k not in ASD_GENES}\n",
    "Dict2Fil(constraint_GW_filt_ASD, ProjDIR+\"/dat/Genetics/GeneWeights/\"+\"constraint_top_decile_LOEUF_excludeASD.gw\")\n",
    "print(len(constraint_GW_filt_ASD))\n",
    "Constraint_rmASD_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, constraint_GW_filt_ASD)\n",
    "Constraint_rmASD_STR_Bias[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in Constraint_rmASD_STR_Bias.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_ASD_Constraint_excludeASD = merge_str_bias_datasets(Spark_ASD_STR_Bias, Constraint_rmASD_STR_Bias, suffixes=('_ASD', '_Constrain_ExcludeASD'))\n",
    "plot_structure_bias_comparison(merged_data_ASD_Constraint_excludeASD, suffixes=('_ASD', '_Constrain_ExcludeASD'),  metric=\"EFFECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "### Cell Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "218 * (3**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(2, 1, figsize=(8, 8))\n",
    "# plot_boxplot_mouseCT(Constraint_CT_Bias, ClusterAnn, ALL_Mouse_Class, \"EFFECT\", ax=axes[0]) \n",
    "# plot_boxplot_mouseCT(Constraint_CT_Bias, ClusterAnn, ALL_Mouse_Class, \"-logP\", ax=axes[1]) \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Geneset = list(constraint_gw.keys())\n",
    "Weights = list(ASD_GW.values())\n",
    "tmp_bias_dfs = []\n",
    "for i in range(10000):\n",
    "    tmp_geneset = random.sample(Geneset, len(Weights))\n",
    "    tmp_gw = dict(zip(tmp_geneset, Weights))\n",
    "    tmp_bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, tmp_gw)\n",
    "    tmp_bias[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in tmp_bias.index.values]\n",
    "    tmp_bias_dfs.append(tmp_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_null_distribution_analysis(structure_name, null_dfs, observed_df, title_prefix=\"\", plot=True):\n",
    "    \"\"\"\n",
    "    Plot null distribution analysis for a given brain structure.\n",
    "    \n",
    "    Parameters:\n",
    "    - structure_name: Name of the structure to analyze\n",
    "    - null_dfs: List of dataframes containing null distribution data\n",
    "    - observed_df: Dataframe containing observed data\n",
    "    - title_prefix: Optional prefix for the plot title\n",
    "    \"\"\"\n",
    "    # Extract EFFECT values from all null datasets\n",
    "    null_effects = []\n",
    "    for df in null_dfs:\n",
    "        null_effects.append(df.loc[structure_name, \"EFFECT\"])\n",
    "\n",
    "    # Get observed value\n",
    "    observed_effect = observed_df.loc[structure_name, \"EFFECT\"] \n",
    "\n",
    "    # Calculate p-value (one-tailed test: observed > null)\n",
    "    null_effects = np.array(null_effects)\n",
    "    p_value = (np.sum(null_effects >= observed_effect) + 1) / (len(null_effects) + 1)\n",
    "\n",
    "    # Plot histogram\n",
    "    if plot:    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(null_effects, bins=50, alpha=0.7, color='lightblue', edgecolor='black', label='Null distribution (Constraint Genes)')\n",
    "        plt.axvline(observed_effect, color='red', linestyle='--', linewidth=2, label=f'Observed (Spark ASD): {observed_effect:.4f}')\n",
    "        plt.xlabel('EFFECT')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(f'{title_prefix}{structure_name} EFFECT: Null Distribution vs Observed')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.text(0.05, 0.95, f'P-value: {p_value:.4f}', transform=plt.gca().transAxes, \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Observed Spark ASD effect: {observed_effect:.4f}\")\n",
    "        print(f\"Null mean: {np.mean(null_effects):.4f}\")\n",
    "        print(f\"Null std: {np.std(null_effects):.4f}\")\n",
    "        print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    return p_value, observed_effect, null_effects\n",
    "# Run analysis for Nucleus Accumbens\n",
    "p_value, observed_effect, null_effects = plot_null_distribution_analysis(\"Nucleus_accumbens\", tmp_bias_dfs, Spark_ASD_STR_Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis for Nucleus Accumbens\n",
    "p_value, observed_effect, null_effects = plot_null_distribution_analysis(\"Caudoputamen\", tmp_bias_dfs, Spark_ASD_STR_Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis for all structures in Spark_ASD_STR_Bias\n",
    "P_constraint = {}\n",
    "for structure in Spark_ASD_STR_Bias.index:\n",
    "    p_value, observed_effect, null_effects = plot_null_distribution_analysis(structure, tmp_bias_dfs, Spark_ASD_STR_Bias, title_prefix=\"\", plot=False)\n",
    "    P_constraint[structure] = p_value\n",
    "\n",
    "# Add P_constraint to the dataframe\n",
    "Spark_ASD_STR_Bias_with_p = Spark_ASD_STR_Bias.copy()\n",
    "Spark_ASD_STR_Bias_with_p['P_constraint'] = Spark_ASD_STR_Bias_with_p.index.map(P_constraint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_ASD_STR_Bias_with_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_ASD_STR_Bias_with_p[Spark_ASD_STR_Bias_with_p[\"P_constraint\"] < 0.05].sort_values(by=\"P_constraint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_ASD_STR_Bias_with_p[Spark_ASD_STR_Bias_with_p[\"P_constraint\"] > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value, observed_effect, null_effects = plot_null_distribution_analysis(\"Facial_motor_nucleus\", tmp_bias_dfs, Spark_ASD_STR_Bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "## Comprehensive Decile Analysis\n",
    "\n",
    "This section analyzes the correlation between ASD/DDD structure bias and constraint genes across **all 10 deciles** of LOEUF (Loss-Of-Function Observed/Expected Upper Bound Fraction).\n",
    "\n",
    "**Decile Definition:**\n",
    "- **Decile 1**: Most constrained genes (lowest LOEUF values)\n",
    "- **Decile 10**: Least constrained genes (highest LOEUF values)\n",
    "\n",
    "**Analysis:**\n",
    "1. For each decile, we calculate structure bias using genes within that constraint range\n",
    "2. We compute correlation with ASD and DDD (excluding ASD genes) structure bias patterns\n",
    "3. Statistical significance is tested using Pearson correlation p-values\n",
    "\n",
    "**Key Questions:**\n",
    "- Does the correlation strength change across constraint levels?\n",
    "- Are the most constrained genes most similar to ASD/DDD patterns?\n",
    "- Is there a gradient of similarity across the constraint spectrum?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis across all 10 deciles of constraint\n",
    "# Create 10 deciles based on lof.oe_ci.upper\n",
    "decile_results = []\n",
    "\n",
    "for decile_num in range(1, 11):\n",
    "    # Calculate decile boundaries\n",
    "    lower_quantile = (decile_num - 1) / 10\n",
    "    upper_quantile = decile_num / 10\n",
    "    \n",
    "    lower_threshold = gnomad4[\"lof.oe_ci.upper\"].quantile(lower_quantile)\n",
    "    upper_threshold = gnomad4[\"lof.oe_ci.upper\"].quantile(upper_quantile)\n",
    "    \n",
    "    # Filter genes in this decile\n",
    "    gnomad4_decile = gnomad4[\n",
    "        (gnomad4[\"lof.oe_ci.upper\"] > lower_threshold) & \n",
    "        (gnomad4[\"lof.oe_ci.upper\"] <= upper_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Prepare data\n",
    "    columns_to_keep = [\"Entrez\", \"gene\", \"lof.pLI\", \"lof.z_score\", \"lof.oe_ci.upper\"]\n",
    "    gnomad4_decile = gnomad4_decile[columns_to_keep].copy()\n",
    "    gnomad4_decile[\"Entrez\"] = gnomad4_decile[\"Entrez\"].astype(int)\n",
    "    gnomad4_decile = gnomad4_decile[gnomad4_decile[\"Entrez\"] != 0]\n",
    "    \n",
    "    # Create gene weights (inverse of LOEUF)\n",
    "    constraint_gw_decile = dict(zip(gnomad4_decile[\"Entrez\"], 1/gnomad4_decile[\"lof.oe_ci.upper\"]))\n",
    "    \n",
    "    # Calculate structure bias\n",
    "    constraint_STR_Bias_decile = MouseSTR_AvgZ_Weighted(STR_BiasMat, constraint_gw_decile)\n",
    "    constraint_STR_Bias_decile[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in constraint_STR_Bias_decile.index.values]\n",
    "    \n",
    "    # Calculate correlations with ASD\n",
    "    merged_ASD = merge_str_bias_datasets(Spark_ASD_STR_Bias, constraint_STR_Bias_decile, suffixes=('_ASD', '_Constraint'))\n",
    "    corr_ASD = merged_ASD[\"EFFECT_ASD\"].corr(merged_ASD[\"EFFECT_Constraint\"])\n",
    "    \n",
    "    # Calculate correlations with DDD\n",
    "    merged_DDD = merge_str_bias_datasets(DDD_rmASD_STR_Bias, constraint_STR_Bias_decile, suffixes=('_DD', '_Constraint'))\n",
    "    corr_DDD = merged_DDD[\"EFFECT_DDD\"].corr(merged_DDD[\"EFFECT_Constraint\"])\n",
    "    \n",
    "    # Store results\n",
    "    decile_results.append({\n",
    "        'Decile': decile_num,\n",
    "        'N_genes': len(gnomad4_decile),\n",
    "        'LOEUF_min': lower_threshold,\n",
    "        'LOEUF_max': upper_threshold,\n",
    "        'LOEUF_mean': gnomad4_decile[\"lof.oe_ci.upper\"].mean(),\n",
    "        'Correlation_ASD': corr_ASD,\n",
    "        'Correlation_DDD': corr_DDD\n",
    "    })\n",
    "    \n",
    "    print(f\"Decile {decile_num}: N={len(gnomad4_decile)}, LOEUF=[{lower_threshold:.3f}, {upper_threshold:.3f}], Corr_ASD={corr_ASD:.3f}, Corr_DDD={corr_DDD:.3f}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "decile_results_df = pd.DataFrame(decile_results)\n",
    "decile_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize correlation trends across constraint deciles\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), dpi=240)\n",
    "\n",
    "# Plot 1: Correlation vs Decile\n",
    "ax1 = axes[0]\n",
    "ax1.plot(decile_results_df['Decile'], decile_results_df['Correlation_ASD'], \n",
    "         marker='o', markersize=8, linewidth=2, label='ASD vs Constraint', color='#1f77b4')\n",
    "ax1.plot(decile_results_df['Decile'], decile_results_df['Correlation_DDD'], \n",
    "         marker='s', markersize=8, linewidth=2, label='DD (excl. ASD) vs Constraint', color='#ff7f0e')\n",
    "ax1.set_xlabel('Constraint Decile\\n(1=Most Constrained, 10=Least Constrained)', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Correlation with Structure Bias', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('Correlation vs Constraint Decile', fontsize=16, fontweight='bold', pad=20)\n",
    "ax1.legend(fontsize=12, loc='best')\n",
    "ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "ax1.set_xticks(range(1, 11))\n",
    "ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 2: Correlation vs Mean LOEUF\n",
    "ax2 = axes[1]\n",
    "ax2.plot(decile_results_df['LOEUF_mean'], decile_results_df['Correlation_ASD'], \n",
    "         marker='o', markersize=8, linewidth=2, label='ASD vs Constraint', color='#1f77b4')\n",
    "ax2.plot(decile_results_df['LOEUF_mean'], decile_results_df['Correlation_DDD'], \n",
    "         marker='s', markersize=8, linewidth=2, label='DD (excl. ASD) vs Constraint', color='#ff7f0e')\n",
    "ax2.set_xlabel('Mean LOEUF\\n(Lower = More Constrained)', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Correlation with Structure Bias', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('Correlation vs Mean LOEUF', fontsize=16, fontweight='bold', pad=20)\n",
    "ax2.legend(fontsize=12, loc='best')\n",
    "ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statistical significance testing for correlations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Add p-values to the analysis\n",
    "decile_results_pval = []\n",
    "\n",
    "for decile_num in range(1, 11):\n",
    "    # Calculate decile boundaries\n",
    "    lower_quantile = (decile_num - 1) / 10\n",
    "    upper_quantile = decile_num / 10\n",
    "    \n",
    "    lower_threshold = gnomad4[\"lof.oe_ci.upper\"].quantile(lower_quantile)\n",
    "    upper_threshold = gnomad4[\"lof.oe_ci.upper\"].quantile(upper_quantile)\n",
    "    \n",
    "    # Filter genes in this decile\n",
    "    gnomad4_decile = gnomad4[\n",
    "        (gnomad4[\"lof.oe_ci.upper\"] > lower_threshold) & \n",
    "        (gnomad4[\"lof.oe_ci.upper\"] <= upper_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Prepare data\n",
    "    columns_to_keep = [\"Entrez\", \"gene\", \"lof.pLI\", \"lof.z_score\", \"lof.oe_ci.upper\"]\n",
    "    gnomad4_decile = gnomad4_decile[columns_to_keep].copy()\n",
    "    gnomad4_decile[\"Entrez\"] = gnomad4_decile[\"Entrez\"].astype(int)\n",
    "    gnomad4_decile = gnomad4_decile[gnomad4_decile[\"Entrez\"] != 0]\n",
    "    \n",
    "    # Create gene weights\n",
    "    constraint_gw_decile = dict(zip(gnomad4_decile[\"Entrez\"], 1/gnomad4_decile[\"lof.oe_ci.upper\"]))\n",
    "    \n",
    "    # Calculate structure bias\n",
    "    constraint_STR_Bias_decile = MouseSTR_AvgZ_Weighted(STR_BiasMat, constraint_gw_decile)\n",
    "    constraint_STR_Bias_decile[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in constraint_STR_Bias_decile.index.values]\n",
    "    \n",
    "    # Calculate correlations and p-values with ASD\n",
    "    merged_ASD = merge_str_bias_datasets(Spark_ASD_STR_Bias, constraint_STR_Bias_decile, suffixes=('_ASD', '_Constraint'))\n",
    "    corr_ASD, pval_ASD = pearsonr(merged_ASD[\"EFFECT_ASD\"], merged_ASD[\"EFFECT_Constraint\"])\n",
    "    \n",
    "    # Calculate correlations and p-values with DDD\n",
    "    merged_DDD = merge_str_bias_datasets(DDD_rmASD_STR_Bias, constraint_STR_Bias_decile, suffixes=('_DD', '_Constraint'))\n",
    "    corr_DDD, pval_DDD = pearsonr(merged_DDD[\"EFFECT_DDD\"], merged_DDD[\"EFFECT_Constraint\"])\n",
    "    \n",
    "    # Store results\n",
    "    decile_results_pval.append({\n",
    "        'Decile': decile_num,\n",
    "        'N_genes': len(gnomad4_decile),\n",
    "        'LOEUF_mean': gnomad4_decile[\"lof.oe_ci.upper\"].mean(),\n",
    "        'Correlation_ASD': corr_ASD,\n",
    "        'P_value_ASD': pval_ASD,\n",
    "        'Correlation_DDD': corr_DDD,\n",
    "        'P_value_DDD': pval_DDD,\n",
    "        'Sig_ASD': '***' if pval_ASD < 0.001 else '**' if pval_ASD < 0.01 else '*' if pval_ASD < 0.05 else 'ns',\n",
    "        'Sig_DDD': '***' if pval_DDD < 0.001 else '**' if pval_DDD < 0.01 else '*' if pval_DDD < 0.05 else 'ns'\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "decile_results_with_pval = pd.DataFrame(decile_results_pval)\n",
    "decile_results_with_pval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bar plot with significance annotations\n",
    "fig, ax = plt.subplots(figsize=(14, 7), dpi=240)\n",
    "\n",
    "x = np.arange(len(decile_results_with_pval))\n",
    "width = 0.35\n",
    "\n",
    "# Create bars\n",
    "bars1 = ax.bar(x - width/2, decile_results_with_pval['Correlation_ASD'], width, \n",
    "               label='ASD vs Constraint', color='#1f77b4', alpha=0.8, edgecolor='black', linewidth=1)\n",
    "bars2 = ax.bar(x + width/2, decile_results_with_pval['Correlation_DDD'], width, \n",
    "               label='DD (excl. ASD) vs Constraint', color='#ff7f0e', alpha=0.8, edgecolor='black', linewidth=1)\n",
    "\n",
    "# Add significance annotations\n",
    "for i, (idx, row) in enumerate(decile_results_with_pval.iterrows()):\n",
    "    # ASD significance\n",
    "    if row['Sig_ASD'] != 'ns':\n",
    "        ax.text(i - width/2, row['Correlation_ASD'] + 0.02 if row['Correlation_ASD'] > 0 else row['Correlation_ASD'] - 0.05, \n",
    "                row['Sig_ASD'], ha='center', va='bottom' if row['Correlation_ASD'] > 0 else 'top', \n",
    "                fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # DDD significance\n",
    "    if row['Sig_DDD'] != 'ns':\n",
    "        ax.text(i + width/2, row['Correlation_DDD'] + 0.02 if row['Correlation_DDD'] > 0 else row['Correlation_DDD'] - 0.05, \n",
    "                row['Sig_DDD'], ha='center', va='bottom' if row['Correlation_DDD'] > 0 else 'top', \n",
    "                fontsize=10, fontweight='bold')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Constraint Decile (1=Most Constrained, 10=Least Constrained)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Correlation with Structure Bias', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Structure Bias Correlation Across Constraint Deciles\\n(*** p<0.001, ** p<0.01, * p<0.05)', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{i}\\n({row[\"LOEUF_mean\"]:.2f})' for i, row in decile_results_with_pval.iterrows()], fontsize=10)\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "ax.axhline(y=0, color='black', linestyle='-', alpha=0.3, linewidth=1)\n",
    "ax.grid(True, alpha=0.3, linestyle='--', axis='y')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function to visualize specific deciles in detail\n",
    "def plot_decile_comparison(decile_num, dataset1, dataset1_name=\"ASD\", dataset2=None, dataset2_name=\"DDD\"):\n",
    "    \"\"\"\n",
    "    Plot detailed scatter comparison for a specific constraint decile.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    decile_num : int\n",
    "        Decile number (1-10) to visualize\n",
    "    dataset1 : DataFrame\n",
    "        First dataset for comparison (e.g., Spark_ASD_STR_Bias)\n",
    "    dataset1_name : str\n",
    "        Name of first dataset\n",
    "    dataset2 : DataFrame, optional\n",
    "        Second dataset for comparison (e.g., DDD_rmASD_STR_Bias)\n",
    "    dataset2_name : str\n",
    "        Name of second dataset\n",
    "    \"\"\"\n",
    "    # Calculate decile boundaries\n",
    "    lower_quantile = (decile_num - 1) / 10\n",
    "    upper_quantile = decile_num / 10\n",
    "    \n",
    "    lower_threshold = gnomad4[\"lof.oe_ci.upper\"].quantile(lower_quantile)\n",
    "    upper_threshold = gnomad4[\"lof.oe_ci.upper\"].quantile(upper_quantile)\n",
    "    \n",
    "    # Filter genes in this decile\n",
    "    gnomad4_decile = gnomad4[\n",
    "        (gnomad4[\"lof.oe_ci.upper\"] > lower_threshold) & \n",
    "        (gnomad4[\"lof.oe_ci.upper\"] <= upper_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Prepare data\n",
    "    columns_to_keep = [\"Entrez\", \"gene\", \"lof.pLI\", \"lof.z_score\", \"lof.oe_ci.upper\"]\n",
    "    gnomad4_decile = gnomad4_decile[columns_to_keep].copy()\n",
    "    gnomad4_decile[\"Entrez\"] = gnomad4_decile[\"Entrez\"].astype(int)\n",
    "    gnomad4_decile = gnomad4_decile[gnomad4_decile[\"Entrez\"] != 0]\n",
    "    \n",
    "    # Create gene weights\n",
    "    constraint_gw_decile = dict(zip(gnomad4_decile[\"Entrez\"], 1/gnomad4_decile[\"lof.oe_ci.upper\"]))\n",
    "    \n",
    "    # Calculate structure bias\n",
    "    constraint_STR_Bias_decile = MouseSTR_AvgZ_Weighted(STR_BiasMat, constraint_gw_decile)\n",
    "    constraint_STR_Bias_decile[\"Region\"] = [STR_Anno.get(ct_idx, \"Unknown\") for ct_idx in constraint_STR_Bias_decile.index.values]\n",
    "    \n",
    "    print(f\"Decile {decile_num}: N_genes={len(gnomad4_decile)}, LOEUF range=[{lower_threshold:.3f}, {upper_threshold:.3f}]\")\n",
    "    \n",
    "    # Create plots\n",
    "    n_plots = 1 if dataset2 is None else 2\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(8*n_plots, 6), dpi=240)\n",
    "    if n_plots == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot 1: dataset1 vs constraint\n",
    "    merged1 = merge_str_bias_datasets(dataset1, constraint_STR_Bias_decile, \n",
    "                                      suffixes=(f'_{dataset1_name}', '_Constraint'))\n",
    "    plot_structure_bias_comparison(merged1, suffixes=(f'_{dataset1_name}', '_Constraint'), metric='EFFECT')\n",
    "    \n",
    "    # Plot 2: dataset2 vs constraint (if provided)\n",
    "    if dataset2 is not None:\n",
    "        merged2 = merge_str_bias_datasets(dataset2, constraint_STR_Bias_decile, \n",
    "                                          suffixes=(f'_{dataset2_name}', '_Constraint'))\n",
    "        plot_structure_bias_comparison(merged2, suffixes=(f'_{dataset2_name}', '_Constraint'), metric='EFFECT')\n",
    "    \n",
    "    return constraint_STR_Bias_decile, gnomad4_decile\n",
    "\n",
    "# Example usage: Plot decile 1 (most constrained)\n",
    "# constraint_bias_d1, genes_d1 = plot_decile_comparison(1, Spark_ASD_STR_Bias, \"ASD\", DDD_rmASD_STR_Bias, \"DDD\")\n",
    "\n",
    "# Example usage: Plot decile 10 (least constrained)\n",
    "# constraint_bias_d10, genes_d10 = plot_decile_comparison(10, Spark_ASD_STR_Bias, \"ASD\", DDD_rmASD_STR_Bias, \"DDD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i in range(len(tmp_bias_dfs)):\n",
    "    top_avg_bias = tmp_bias_dfs[i].head(50)[\"EFFECT\"].mean()\n",
    "    records.append(top_avg_bias)\n",
    "#records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_effects = records\n",
    "\n",
    "# Get observed value\n",
    "observed_effect = Spark_ASD_STR_Bias.head(50)[\"EFFECT\"].mean()\n",
    "\n",
    "# Calculate p-value (one-tailed test: observed > null)\n",
    "null_effects = np.array(null_effects)\n",
    "p_value = (np.sum(null_effects >= observed_effect) + 1) / (len(null_effects) + 1)\n",
    "\n",
    "# Plot histogram\n",
    "if 1:    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(null_effects, bins=50, alpha=0.7, color='lightblue', edgecolor='black', label='Null distribution (Constraint Genes)')\n",
    "    plt.axvline(observed_effect, color='red', linestyle='--', linewidth=2, label=f'Observed (Spark ASD): {observed_effect:.4f}')\n",
    "    plt.xlabel('EFFECT')\n",
    "    plt.ylabel('Frequency')\n",
    "    #plt.title(f'{title_prefix}{structure_name} EFFECT: Null Distribution vs Observed')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.text(0.05, 0.95, f'P-value: {p_value:.4f}', transform=plt.gca().transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Observed Spark ASD effect: {observed_effect:.4f}\")\n",
    "    print(f\"Null mean: {np.mean(null_effects):.4f}\")\n",
    "    print(f\"Null std: {np.std(null_effects):.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corrs_ASD_Constraint = []\n",
    "Corrs_DDD_Constraint = []\n",
    "for i in range(len(tmp_bias_dfs)):\n",
    "    top_avg_bias = tmp_bias_dfs[i]\n",
    "\n",
    "    # ASD correlation\n",
    "    tmp_merged_data_ASD_Constraint = merge_str_bias_datasets(\n",
    "        Spark_ASD_STR_Bias, top_avg_bias, suffixes=('_ASD', '_Constraint'))\n",
    "    corr_asd = tmp_merged_data_ASD_Constraint[\"EFFECT_ASD\"].corr(\n",
    "        tmp_merged_data_ASD_Constraint[\"EFFECT_Constraint\"])\n",
    "    Corrs_ASD_Constraint.append(corr_asd)\n",
    "\n",
    "    # DDD correlation\n",
    "    tmp_merged_data_DDD_Constraint = merge_str_bias_datasets(\n",
    "        DDD_rmASD_STR_Bias, top_avg_bias, suffixes=('_DD', '_Constraint'))\n",
    "    corr_ddd = tmp_merged_data_DDD_Constraint[\"EFFECT_DDD\"].corr(\n",
    "        tmp_merged_data_DDD_Constraint[\"EFFECT_Constraint\"])\n",
    "    Corrs_DDD_Constraint.append(corr_ddd)\n",
    "\n",
    "Corrs_ASD_Constraint = np.array(Corrs_ASD_Constraint)\n",
    "Corrs_DDD_Constraint = np.array(Corrs_DDD_Constraint)\n",
    "#print(f\"Correlation between EFFECT_ASD and EFFECT_Constraint: {np.mean(Corrs_ASD_Constraint):.4f}\")\n",
    "#print(f\"Correlation between EFFECT_DDD and EFFECT_Constraint: {np.mean(Corrs_DDD_Constraint):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel 1: ASD\n",
    "null_effects_asd = Corrs_ASD_Constraint\n",
    "observed_effect_asd = 0.87\n",
    "null_effects_asd = np.array(null_effects_asd)\n",
    "p_value_asd = (np.sum(null_effects_asd >= observed_effect_asd) + 1) / (len(null_effects_asd) + 1)\n",
    "\n",
    "# Panel 2: DDD\n",
    "null_effects_ddd = Corrs_DDD_Constraint\n",
    "observed_effect_ddd = 0.90\n",
    "null_effects_ddd = np.array(null_effects_ddd)\n",
    "p_value_ddd = (np.sum(null_effects_ddd >= observed_effect_ddd) + 1) / (len(null_effects_ddd) + 1)\n",
    "\n",
    "# Plot both panels (2x1)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "# ASD panel\n",
    "ax = axes[0]\n",
    "ax.hist(null_effects_asd, bins=50, alpha=0.7, color='lightblue', edgecolor='black', label='Null distribution (Constraint Genes)')\n",
    "ax.axvline(observed_effect_asd, color='red', linestyle='--', linewidth=2, label=f'Observed (Spark ASD): {observed_effect_asd:.4f}')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.text(0.05, 0.95, f'P-value: {p_value_asd:.4f}', transform=ax.transAxes, \n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), va='top')\n",
    "ax.set_title('ASD (Spark): Correlation Null Distribution vs Observed')\n",
    "\n",
    "# DDD panel\n",
    "ax = axes[1]\n",
    "ax.hist(null_effects_ddd, bins=50, alpha=0.7, color='lightgreen', edgecolor='black', label='Null distribution (Constraint Genes)')\n",
    "ax.axvline(observed_effect_ddd, color='red', linestyle='--', linewidth=2, label=f'Observed (DDD): {observed_effect_ddd:.4f}')\n",
    "ax.set_xlabel('EFFECT')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.text(0.05, 0.95, f'P-value: {p_value_ddd:.4f}', transform=ax.transAxes, \n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), va='top')\n",
    "ax.set_title('DDD: Correlation Null Distribution vs Observed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Observed Spark ASD effect: {observed_effect_asd:.4f}\")\n",
    "print(f\"ASD Null mean: {np.mean(null_effects_asd):.4f}\")\n",
    "print(f\"ASD Null std: {np.std(null_effects_asd):.4f}\")\n",
    "print(f\"ASD P-value: {p_value_asd:.4f}\")\n",
    "print(\"\")\n",
    "print(f\"Observed DDD effect: {observed_effect_ddd:.4f}\")\n",
    "print(f\"DDD Null mean: {np.mean(null_effects_ddd):.4f}\")\n",
    "print(f\"DDD Null std: {np.std(null_effects_ddd):.4f}\")\n",
    "print(f\"DDD P-value: {p_value_ddd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gencic)",
   "language": "python",
   "name": "gencic"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
