{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "ProjDIR = \"/home/jw3514/Work/ASD_Circuits_CellType/\" # Change to your project directory\n",
    "sys.path.insert(1, f'{ProjDIR}/src/')\n",
    "from ASD_Circuits import *\n",
    "import scipy.io as sio\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "os.chdir(os.path.join(ProjDIR, \"notebooks_mouse_str\"))\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "HGNC, ENSID2Entrez, GeneSymbol2Entrez, Entrez2Symbol = LoadGeneINFO()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Mouse fMRI data validation from 16 mouse model figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_overlap(set1_range, set2_range, set1_size, set2_size, observed_overlap, n_permutations=10000):\n",
    "    \"\"\"\n",
    "    Perform a permutation test to assess the significance of overlap between two sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    set1_range : array-like\n",
    "        Range of possible values for set 1 (e.g., np.arange(1, 164))\n",
    "    set2_range : array-like\n",
    "        Range of possible values for set 2 (e.g., np.arange(1, 214))\n",
    "    set1_size : int\n",
    "        Size of set 1 sample\n",
    "    set2_size : int\n",
    "        Size of set 2 sample\n",
    "    observed_overlap : int\n",
    "        The observed overlap to test against\n",
    "    n_permutations : int, default=10000\n",
    "        Number of permutations to perform\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing test results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate all random samples at once\n",
    "    set1_samples = np.array([np.random.choice(set1_range, size=set1_size, replace=False) for _ in range(n_permutations)])\n",
    "    set2_samples = np.array([np.random.choice(set2_range, size=set2_size, replace=False) for _ in range(n_permutations)])\n",
    "\n",
    "    # Vectorized intersection calculation\n",
    "    intersections = np.array([len(np.intersect1d(set1_samples[i], set2_samples[i])) for i in range(n_permutations)])\n",
    "\n",
    "    # Calculate p-value for overlap >= observed_overlap\n",
    "    p_value = np.sum(intersections >= observed_overlap) / len(intersections)\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'intersections': intersections,\n",
    "        'mean_intersection': np.mean(intersections),\n",
    "        'std_intersection': np.std(intersections),\n",
    "        'min_intersection': np.min(intersections),\n",
    "        'max_intersection': np.max(intersections),\n",
    "        'observed_overlap': observed_overlap,\n",
    "        'p_value': p_value,\n",
    "        'n_significant': np.sum(intersections >= observed_overlap),\n",
    "        'n_permutations': n_permutations\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_permutation_results(results):\n",
    "    \"\"\"\n",
    "    Plot the results of a permutation test.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results dictionary from permutation_test_overlap function\n",
    "    \"\"\"\n",
    "    intersections = results['intersections']\n",
    "    observed_overlap = results['observed_overlap']\n",
    "    mean_intersection = results['mean_intersection']\n",
    "    n_permutations = results['n_permutations']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(intersections, bins=range(min(intersections), max(intersections)+2), \n",
    "             alpha=0.7, edgecolor='black', density=True)\n",
    "    plt.axvline(observed_overlap, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Observed overlap = {observed_overlap}')\n",
    "    plt.axvline(mean_intersection, color='blue', linestyle='--', linewidth=2, \n",
    "               label=f'Mean = {mean_intersection:.1f}')\n",
    "    plt.xlabel('Intersection Length')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title(f'Distribution of Intersections from {n_permutations} Permutations')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy to dat/\n",
    "FMRI = pd.read_excel(\"/home/jw3514/Work/FuncConnectome/ASD_Mouse/Clusters_Images/Clusters_Values.xlsx\", index_col=\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMRI.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Correlation between 4 Clusters, and top STR in common\n",
    "# Compute Spearman and Pearson correlation between Cluster1-4\n",
    "cluster_cols = ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']\n",
    "cluster_data = FMRI[cluster_cols]\n",
    "\n",
    "# Calculate Spearman and Pearson correlation matrices\n",
    "spearman_corr = cluster_data.corr(method='spearman')\n",
    "pearson_corr = cluster_data.corr(method='pearson')\n",
    "\n",
    "# Import matplotlib with explicit backend setting to avoid backend_bases error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create subplots for both correlation matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Spearman correlation heatmap\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, ax=ax1)\n",
    "ax1.set_title('Spearman Correlation between Clusters 1-4')\n",
    "\n",
    "# Pearson correlation heatmap\n",
    "sns.heatmap(pearson_corr, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, ax=ax2)\n",
    "ax2.set_title('Pearson Correlation between Clusters 1-4')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the correlation matrices\n",
    "print(\"Spearman Correlation Matrix:\")\n",
    "print(spearman_corr.round(3))\n",
    "print(\"\\nPearson Correlation Matrix:\")\n",
    "print(pearson_corr.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "GENCIC = pd.read_excel(os.path.join(ProjDIR, \"results/SupTabs.v57.xlsx\"), sheet_name=\"Table-S1- Structure Bias\", index_col=0)\n",
    "# Need Annotate Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy to dat/\n",
    "ABA_Ontology = pd.read_csv(\"/home/jw3514/Work/ASD_Circuits/dat/Other/ontology.csv\", index_col = \"KEY\")\n",
    "ABA_Ontology.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _str, row in GENCIC.iterrows():\n",
    "    if _str in ABA_Ontology.index:\n",
    "        GENCIC.loc[_str, \"acronym\"] = ABA_Ontology.loc[_str, \"acronym\"]\n",
    "    else:\n",
    "        print(f\"{_str} not in ABA_Ontology\")\n",
    "GENCIC[\"Structure\"] = GENCIC.index\n",
    "GENCIC = GENCIC.set_index(\"acronym\")\n",
    "GENCIC.to_csv('../results/GENCIC_MouseSTRBias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "for cluster in ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']:\n",
    "    # Get common acronyms between GENCIC and FMRI data\n",
    "    common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "    \n",
    "    if len(common_acronyms) > 0:\n",
    "        # Extract values for common acronyms\n",
    "        gencic_bias = GENCIC.loc[common_acronyms, 'Bias']\n",
    "        fmri_cluster = FMRI.loc[common_acronyms, cluster]\n",
    "        \n",
    "        # Calculate Spearman correlation\n",
    "        spearman_correlation, spearman_p_value = spearmanr(gencic_bias, fmri_cluster)\n",
    "        \n",
    "        # Calculate Pearson correlation\n",
    "        pearson_correlation, pearson_p_value = pearsonr(gencic_bias, fmri_cluster)\n",
    "        \n",
    "        print(f\"{cluster}:\")\n",
    "        print(f\"  Number of common regions: {len(common_acronyms)}\")\n",
    "        print(f\"  Spearman correlation: {spearman_correlation:.4f} (p = {spearman_p_value:.4f})\")\n",
    "        print(f\"  Pearson correlation: {pearson_correlation:.4f} (p = {pearson_p_value:.4f})\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{cluster}: No common acronyms found between GENCIC and FMRI data\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "for cluster in ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']:\n",
    "    # Get common acronyms between GENCIC and FMRI data\n",
    "    common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "    \n",
    "    if len(common_acronyms) > 0:\n",
    "        # Extract values for common acronyms\n",
    "        gencic_bias = GENCIC.loc[common_acronyms, 'Bias']\n",
    "        fmri_cluster = FMRI.loc[common_acronyms, cluster].abs()\n",
    "        \n",
    "        # Calculate Spearman correlation\n",
    "        spearman_correlation, spearman_p_value = spearmanr(gencic_bias, fmri_cluster)\n",
    "        \n",
    "        # Calculate Pearson correlation\n",
    "        pearson_correlation, pearson_p_value = pearsonr(gencic_bias, fmri_cluster)\n",
    "        \n",
    "        print(f\"{cluster}:\")\n",
    "        print(f\"  Number of common regions: {len(common_acronyms)}\")\n",
    "        print(f\"  Spearman correlation: {spearman_correlation:.4f} (p = {spearman_p_value:.4f})\")\n",
    "        print(f\"  Pearson correlation: {pearson_correlation:.4f} (p = {pearson_p_value:.4f})\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{cluster}: No common acronyms found between GENCIC and FMRI data\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "\n",
    "topN = 50\n",
    "\n",
    "for cluster in ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']:\n",
    "    # Get common acronyms between GENCIC and FMRI data\n",
    "    common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "    \n",
    "    if len(common_acronyms) > 0:\n",
    "        # Get top N structures from GENCIC (highest Bias values)\n",
    "        gencic_topN = GENCIC.loc[common_acronyms].nlargest(topN, 'Bias').index\n",
    "        \n",
    "        # Get top N structures from fMRI cluster (highest values)\n",
    "        fmri_topN_largest = FMRI.loc[common_acronyms].nlargest(topN, cluster).index\n",
    "        \n",
    "        # Get top N structures from fMRI cluster (lowest values)\n",
    "        fmri_topN_smallest = FMRI.loc[common_acronyms].nsmallest(topN, cluster).index\n",
    "        \n",
    "        # Calculate overlap between GENCIC top N and fMRI top N (largest)\n",
    "        overlap_largest = len(set(gencic_topN).intersection(set(fmri_topN_largest)))\n",
    "        \n",
    "        # Calculate overlap between GENCIC top N and fMRI top N (smallest)\n",
    "        overlap_smallest = len(set(gencic_topN).intersection(set(fmri_topN_smallest)))\n",
    "        \n",
    "        # Calculate p-values using hypergeometric test\n",
    "        # For largest values\n",
    "        # Population size: total common regions\n",
    "        # Successes in population: fMRI top N largest\n",
    "        # Sample size: GENCIC top N\n",
    "        # Observed successes: overlap_largest\n",
    "        pval_largest = hypergeom.sf(overlap_largest - 1, len(common_acronyms), topN, topN)\n",
    "        \n",
    "        # For smallest values\n",
    "        pval_smallest = hypergeom.sf(overlap_smallest - 1, len(common_acronyms), topN, topN)\n",
    "        \n",
    "        print(f\"{cluster}:\")\n",
    "        print(f\"  Number of common regions: {len(common_acronyms)}\")\n",
    "        print(f\"  GENCIC top {topN} overlap with fMRI top {topN} (largest): {overlap_largest} (p = {pval_largest:.4f})\")\n",
    "        print(f\"  GENCIC top {topN} overlap with fMRI top {topN} (smallest): {overlap_smallest} (p = {pval_smallest:.4f})\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{cluster}: No common acronyms found between GENCIC and FMRI data\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add average and count columns to FMRI dataframe\n",
    "FMRI['Average_Clusters'] = FMRI[['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']].mean(axis=1)\n",
    "FMRI.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4', 'Average_Clusters']:\n",
    "    # Get common acronyms between GENCIC and FMRI data\n",
    "    common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "    \n",
    "    if len(common_acronyms) > 0:\n",
    "        # Extract values for common acronyms\n",
    "        gencic_bias = GENCIC.loc[common_acronyms, 'Bias']\n",
    "        fmri_cluster = FMRI.loc[common_acronyms, cluster]\n",
    "        \n",
    "        # Calculate Spearman correlation\n",
    "        correlation, p_value = spearmanr(gencic_bias, fmri_cluster)\n",
    "        \n",
    "        print(f\"{cluster}:\")\n",
    "        print(f\"  Number of common regions: {len(common_acronyms)}\")\n",
    "        print(f\"  Spearman correlation: {correlation:.4f}\")\n",
    "        print(f\"  P-value: {p_value:.8f}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{cluster}: No common acronyms found between GENCIC and FMRI data\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Sibling-Based Permutation P-Values\n",
    "Standard correlation p-values assume independence between brain structures.\n",
    "To address potential spatial autocorrelation, we compute empirical p-values\n",
    "from the sibling mutability null distribution (10,000 simulated bias profiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, linregress, rankdata\n",
    "\n",
    "# Load sibling null bias and map structure names to acronyms\n",
    "sib_null = pd.read_parquet(os.path.join(ProjDIR, 'results/Sibling_bias/Mutability_61gene/sibling_mutability_bias.parquet'))\n",
    "str2acr = {s: ABA_Ontology.loc[s, 'acronym'] for s in sib_null.index if s in ABA_Ontology.index}\n",
    "sib_null_acr = sib_null.rename(index=str2acr)\n",
    "\n",
    "# Common acronyms between GENCIC, FMRI, and sibling null\n",
    "common_acr = GENCIC.index.intersection(FMRI.index).intersection(sib_null_acr.index)\n",
    "X_null = sib_null_acr.loc[common_acr].values  # (N_common, 10000)\n",
    "Y_fmri_null = FMRI.loc[common_acr, 'Average_Clusters'].values\n",
    "X_obs_null = GENCIC.loc[common_acr, 'Bias'].values\n",
    "\n",
    "# Observed correlations\n",
    "obs_pear_r, obs_pear_p = pearsonr(X_obs_null, Y_fmri_null)\n",
    "obs_spear_rho, obs_spear_p = spearmanr(X_obs_null, Y_fmri_null)\n",
    "\n",
    "# Vectorized Pearson null correlations\n",
    "n_sims = X_null.shape[1]\n",
    "Y_c = Y_fmri_null - Y_fmri_null.mean()\n",
    "Y_ss = np.sum(Y_c**2)\n",
    "X_means = X_null.mean(axis=0)\n",
    "X_c = X_null - X_means[np.newaxis, :]\n",
    "X_ss = np.sum(X_c**2, axis=0)\n",
    "null_pearson_r = (Y_c @ X_c) / np.sqrt(X_ss * Y_ss)\n",
    "\n",
    "# Spearman null correlations (rank-based)\n",
    "Y_ranks = rankdata(Y_fmri_null)\n",
    "null_spearman_rho = np.empty(n_sims)\n",
    "for i in range(n_sims):\n",
    "    null_spearman_rho[i] = np.corrcoef(rankdata(X_null[:, i]), Y_ranks)[0, 1]\n",
    "\n",
    "# One-tailed permutation p-values (testing negative correlation)\n",
    "p_perm_pearson = (np.sum(null_pearson_r <= obs_pear_r) + 1) / (n_sims + 1)\n",
    "p_perm_spearman = (np.sum(null_spearman_rho <= obs_spear_rho) + 1) / (n_sims + 1)\n",
    "# Two-tailed alternative:\n",
    "# p_perm_pearson = (np.sum(np.abs(null_pearson_r) >= np.abs(obs_pear_r)) + 1) / (n_sims + 1)\n",
    "# p_perm_spearman = (np.sum(np.abs(null_spearman_rho) >= np.abs(obs_spear_rho)) + 1) / (n_sims + 1)\n",
    "\n",
    "print(f\"Sibling Permutation P-values (N={len(common_acr)} structures, {n_sims} sims):\")\n",
    "print(f\"  Pearson:  r = {obs_pear_r:.4f}, p = {obs_pear_p:.4e}, p_perm = {p_perm_pearson:.4f}\")\n",
    "print(f\"  Spearman: rho = {obs_spear_rho:.4f}, p = {obs_spear_p:.4e}, p_perm = {p_perm_spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get common acronyms between GENCIC and FMRI data\n",
    "common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "\n",
    "if len(common_acronyms) > 0:\n",
    "    # Extract values for common acronyms\n",
    "    gencic_bias = GENCIC.loc[common_acronyms, 'Bias']\n",
    "    fmri_average_clusters = FMRI.loc[common_acronyms, 'Average_Clusters']\n",
    "    regions = GENCIC.loc[common_acronyms, 'REGION']\n",
    "\n",
    "    # Calculate Pearson correlation and linear regression\n",
    "    linres = linregress(gencic_bias, fmri_average_clusters)\n",
    "    pear_r, pear_p = pearsonr(gencic_bias, fmri_average_clusters)\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Define region color mapping (from DDD.ipynb)\n",
    "    REGIONS_seq = ['Isocortex','Olfactory_areas', 'Cortical_subplate', \n",
    "                    'Hippocampus','Amygdala','Striatum', \n",
    "                    \"Thalamus\", \"Hypothalamus\", \"Midbrain\", \n",
    "                    \"Medulla\", \"Pallidum\", \"Pons\", \n",
    "                    \"Cerebellum\"]\n",
    "    REG_COR_Dic = dict(zip(REGIONS_seq, [\"#268ad5\", \"#D5DBDB\", \"#7ac3fa\", \n",
    "                                        \"#2c9d39\", \"#742eb5\", \"#ed8921\", \n",
    "                                        \"#e82315\", \"#E6B0AA\", \"#f6b26b\",  \n",
    "                                        \"#20124d\", \"#2ECC71\", \"#D2B4DE\", \n",
    "                                        \"#ffd966\"]))\n",
    "    \n",
    "    # Map regions to colors\n",
    "    # Handle naming differences between GENCIC and color map\n",
    "    region_name_mapping = {\n",
    "        'Amygdalar': 'Amygdala',\n",
    "        'Olfactory': 'Olfactory_areas',\n",
    "        'Hippocampal': 'Hippocampus'\n",
    "    }\n",
    "    \n",
    "    colors = []\n",
    "    for region in regions:\n",
    "        # Apply name mapping if needed\n",
    "        mapped_region = region_name_mapping.get(region, region)\n",
    "        # Get color from dictionary, default to gray if not found\n",
    "        colors.append(REG_COR_Dic.get(mapped_region, '#808080'))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8), dpi=360)\n",
    "\n",
    "    # Plot linear fit first (behind points)\n",
    "    xfit = np.linspace(gencic_bias.min(), gencic_bias.max(), 100)\n",
    "    yfit = linres.slope * xfit + linres.intercept\n",
    "    ax.plot(\n",
    "        xfit, yfit, color=\"#e6550d\", linestyle=\"--\", linewidth=2.2,\n",
    "        label=f\"Linear fit\", zorder=1\n",
    "    )\n",
    "\n",
    "    # Create scatter plot with region colors\n",
    "    for region_name in set(regions):\n",
    "        mapped_region_name = region_name_mapping.get(region_name, region_name)\n",
    "        color = REG_COR_Dic.get(mapped_region_name, '#808080')\n",
    "        mask = regions == region_name\n",
    "        ax.scatter(\n",
    "            gencic_bias[mask], fmri_average_clusters[mask],\n",
    "            color=color, edgecolor='k', s=80, alpha=0.9, zorder=2,\n",
    "            label=region_name\n",
    "        )\n",
    "\n",
    "    # Expand x-axis to the right to give labels more room\n",
    "    #x_lo, x_hi = ax.get_xlim()\n",
    "    #ax.set_xlim(x_lo, x_hi + (x_hi - x_lo) * 0.15)\n",
    "\n",
    "    # Add text annotations: ASD 46 circuit structures (blue) and high-fMRI non-circuit (green)\n",
    "    from adjustText import adjust_text\n",
    "    circuit_46 = set(GENCIC[GENCIC[\"Circuits.46\"] == 1].index)\n",
    "    texts = []\n",
    "    for acronym in common_acronyms:\n",
    "        x = gencic_bias[acronym]\n",
    "        y = fmri_average_clusters[acronym]\n",
    "        if acronym in circuit_46:\n",
    "            texts.append(ax.text(x, y, acronym, fontsize=14, fontweight='bold',\n",
    "                                 alpha=0.9, color='blue'))\n",
    "        elif y <= -0.2:\n",
    "            texts.append(ax.text(x, y, acronym, fontsize=14, fontweight='bold',\n",
    "                                 alpha=0.9, color='green'))\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))\n",
    "\n",
    "    plt.xlabel(\"ASD Mutation Bias\", fontsize=17, fontweight='bold')\n",
    "    plt.ylabel(\"Mean fMRI connectivity alterations\", fontsize=17, fontweight='bold')\n",
    "\n",
    "    # Show Pearson correlation in annotation, with a rectangular box around it\n",
    "    stat_text = (\n",
    "        f\"r = {pear_r:.2f}\\np = {pear_p:.0e}\\n$p_{{perm}}$ = {p_perm_pearson:.4f}\"\n",
    "    )\n",
    "    plt.text(\n",
    "        0.12, 0.2, stat_text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=25,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='left',\n",
    "        bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5', alpha=0.85)\n",
    "    )\n",
    "\n",
    "    # plt.title(\n",
    "    #     \"GENCIC Bias vs FMRI Average Clusters\",\n",
    "    #     fontsize=16,\n",
    "    #     fontweight='bold'\n",
    "    # )\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend(fontsize=12, loc='best', frameon=True, ncol=2)\n",
    "    plt.grid(alpha=0.3, linestyle=\":\", zorder=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Number of common regions: {len(common_acronyms)}\")\n",
    "    print(f\"Pearson correlation: {pear_r:.4f}\")\n",
    "    print(f\"Pearson P-value: {pear_p:.8f}\")\n",
    "else:\n",
    "    print(\"No common acronyms found between GENCIC and FMRI data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create combined table with complete fMRI data and GENCIC bias for supplementary materials\n",
    "# Get common acronyms between GENCIC and FMRI data\n",
    "common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "\n",
    "# Create combined dataframe\n",
    "combined_table = FMRI.loc[common_acronyms].copy()\n",
    "\n",
    "# Add GENCIC Bias column\n",
    "combined_table['GENCIC_Bias'] = GENCIC.loc[common_acronyms, 'Bias']\n",
    "\n",
    "# Add other relevant GENCIC columns if needed (e.g., Structure name, REGION)\n",
    "if 'Structure' in GENCIC.columns:\n",
    "    combined_table['GENCIC_Structure'] = GENCIC.loc[common_acronyms, 'Structure']\n",
    "if 'REGION' in GENCIC.columns:\n",
    "    combined_table['GENCIC_REGION'] = GENCIC.loc[common_acronyms, 'REGION']\n",
    "\n",
    "# Reorder columns to put GENCIC_Bias near the beginning for easier viewing\n",
    "cols = combined_table.columns.tolist()\n",
    "if 'GENCIC_Bias' in cols:\n",
    "    cols.remove('GENCIC_Bias')\n",
    "    cols.insert(1, 'GENCIC_Bias')  # Insert after index/name column\n",
    "combined_table = combined_table[cols]\n",
    "\n",
    "# Save to file for supplementary materials\n",
    "output_file = os.path.join(ProjDIR, 'results/FMRI_GENCIC_Combined_Table.csv')\n",
    "combined_table.to_csv(output_file)\n",
    "print(f\"Combined table saved to: {output_file}\")\n",
    "print(f\"Table shape: {combined_table.shape}\")\n",
    "print(f\"Number of regions: {len(combined_table)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(combined_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMRI.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Calculate sum of absolute Z-scores for each structure across all 4 clusters\n",
    "# First, compute Z-scores for each cluster\n",
    "from scipy.stats import zscore\n",
    "\n",
    "cluster_cols = ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']\n",
    "#FMRI_zscores = FMRI[cluster_cols].apply(zscore, axis=0)\n",
    "\n",
    "# Calculate sum of absolute Z-scores\n",
    "FMRI['Sum_Abs_Zscore'] = FMRI[cluster_cols].abs().sum(axis=1)\n",
    "\n",
    "# Get common acronyms between GENCIC and FMRI data\n",
    "common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "\n",
    "if len(common_acronyms) > 0:\n",
    "    # Extract values for common acronyms\n",
    "    gencic_bias = GENCIC.loc[common_acronyms, 'Bias']\n",
    "    fmri_sum_abs_zscore = FMRI.loc[common_acronyms, 'Sum_Abs_Zscore']\n",
    "    regions = GENCIC.loc[common_acronyms, 'REGION']\n",
    "\n",
    "    # Calculate Pearson correlation and linear regression\n",
    "    from scipy.stats import pearsonr, linregress\n",
    "    linres = linregress(gencic_bias, fmri_sum_abs_zscore)\n",
    "    pear_r, pear_p = pearsonr(gencic_bias, fmri_sum_abs_zscore)\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Define region color mapping (from DDD.ipynb)\n",
    "    REGIONS_seq = ['Isocortex','Olfactory_areas', 'Cortical_subplate', \n",
    "                    'Hippocampus','Amygdala','Striatum', \n",
    "                    \"Thalamus\", \"Hypothalamus\", \"Midbrain\", \n",
    "                    \"Medulla\", \"Pallidum\", \"Pons\", \n",
    "                    \"Cerebellum\"]\n",
    "    REG_COR_Dic = dict(zip(REGIONS_seq, [\"#268ad5\", \"#D5DBDB\", \"#7ac3fa\", \n",
    "                                        \"#2c9d39\", \"#742eb5\", \"#ed8921\", \n",
    "                                        \"#e82315\", \"#E6B0AA\", \"#f6b26b\",  \n",
    "                                        \"#20124d\", \"#2ECC71\", \"#D2B4DE\", \n",
    "                                        \"#ffd966\"]))\n",
    "    \n",
    "    # Map regions to colors\n",
    "    # Handle naming differences between GENCIC and color map\n",
    "    region_name_mapping = {\n",
    "        'Amygdalar': 'Amygdala',\n",
    "        'Olfactory': 'Olfactory_areas',\n",
    "        'Hippocampal': 'Hippocampus'\n",
    "    }\n",
    "    \n",
    "    colors = []\n",
    "    for region in regions:\n",
    "        # Apply name mapping if needed\n",
    "        mapped_region = region_name_mapping.get(region, region)\n",
    "        # Get color from dictionary, default to gray if not found\n",
    "        colors.append(REG_COR_Dic.get(mapped_region, '#808080'))\n",
    "\n",
    "    plt.figure(figsize=(11,8), dpi=360)\n",
    "    \n",
    "    # Plot linear fit first (behind points)\n",
    "    xfit = np.linspace(gencic_bias.min(), gencic_bias.max(), 100)\n",
    "    yfit = linres.slope * xfit + linres.intercept\n",
    "    plt.plot(\n",
    "        xfit, yfit, color=\"#e6550d\", linestyle=\"--\", linewidth=2.2,\n",
    "        label=f\"Linear fit (slope={linres.slope:.2f})\", zorder=1\n",
    "    )\n",
    "    \n",
    "    # Create scatter plot with region colors\n",
    "    for region_name in set(regions):\n",
    "        mapped_region_name = region_name_mapping.get(region_name, region_name)\n",
    "        color = REG_COR_Dic.get(mapped_region_name, '#808080')\n",
    "        mask = regions == region_name\n",
    "        plt.scatter(\n",
    "            gencic_bias[mask], fmri_sum_abs_zscore[mask],\n",
    "            color=color, edgecolor='k', s=80, alpha=0.9, zorder=2,\n",
    "            label=region_name\n",
    "        )\n",
    "    \n",
    "    # Add text annotations for each point\n",
    "    for acronym in common_acronyms:\n",
    "        x = gencic_bias[acronym]\n",
    "        y = fmri_sum_abs_zscore[acronym]\n",
    "        plt.annotate(\n",
    "            acronym, (x, y),\n",
    "            fontsize=6, alpha=0.8,\n",
    "            xytext=(3, 3), textcoords='offset points'\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"GENCIC Bias\", fontsize=17, fontweight='bold')\n",
    "    plt.ylabel(\"fMRI Sum of Absolute Z-scores\", fontsize=17, fontweight='bold')\n",
    "\n",
    "    # Only show Pearson correlation in annotation, without a box\n",
    "    stat_text = (\n",
    "        f\"r = {pear_r:.2f}, p = {pear_p:.0e}\"\n",
    "    )\n",
    "    plt.text(\n",
    "        0.12, 0.2, stat_text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=14,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='left'\n",
    "    )\n",
    "\n",
    "    plt.title(\n",
    "        \"GENCIC Bias vs fMRI Sum of Absolute Z-scores\",\n",
    "        fontsize=16,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend(fontsize=9, loc='best', frameon=True, ncol=2)\n",
    "    plt.grid(alpha=0.3, linestyle=\":\", zorder=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Number of common regions: {len(common_acronyms)}\")\n",
    "    print(f\"Pearson correlation: {pear_r:.4f}\")\n",
    "    print(f\"Pearson P-value: {pear_p:.8f}\")\n",
    "else:\n",
    "    print(\"No common acronyms found between GENCIC and FMRI data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Get common acronyms between GENCIC and FMRI data\n",
    "common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "\n",
    "if len(common_acronyms) > 0:\n",
    "    # Extract fMRI data for common acronyms\n",
    "    fmri_average_clusters = FMRI.loc[common_acronyms, 'Average_Clusters']\n",
    "    \n",
    "    # Find all columns with \"Bias\" in the name\n",
    "    bias_columns = [col for col in GENCIC.columns if 'Bias' in col]\n",
    "    \n",
    "    print(f\"Number of common regions: {len(common_acronyms)}\")\n",
    "    print(f\"Bias columns found: {bias_columns}\")\n",
    "    print()\n",
    "    \n",
    "    # Calculate correlations for each bias column\n",
    "    for bias_col in bias_columns:\n",
    "        # Extract values for common acronyms\n",
    "        gencic_bias_values = GENCIC.loc[common_acronyms, bias_col]\n",
    "        \n",
    "        # Calculate Spearman correlation\n",
    "        spearman_correlation, spearman_p_value = spearmanr(gencic_bias_values, fmri_average_clusters)\n",
    "        \n",
    "        # Calculate Pearson correlation\n",
    "        pearson_correlation, pearson_p_value = pearsonr(gencic_bias_values, fmri_average_clusters)\n",
    "        \n",
    "        print(f\"{bias_col}:\")\n",
    "        print(f\"  Spearman correlation: {spearman_correlation:.4f}, p-value: {spearman_p_value:.2e}\")\n",
    "        print(f\"  Pearson correlation: {pearson_correlation:.4f}, p-value: {pearson_p_value:.2e}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No common acronyms found between GENCIC and FMRI data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cut = 0\n",
    "FMRI['Count_Below_Threshold'] = (FMRI[['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']] < Cut).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new 'Area' column based on SubArea if valid, otherwise MacroArea\n",
    "FMRI['Area'] = FMRI['SubArea'].where(FMRI['SubArea'].notna() & (FMRI['SubArea'] != ''), FMRI['MacroArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMRI[FMRI[\"Count_Below_Threshold\"]>=3].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Count_Below_Threshold at MacroArea level\n",
    "macro_area_aggregation = FMRI.groupby('Area')['Count_Below_Threshold'].agg(['mean', 'std', 'count']).reset_index()\n",
    "\n",
    "# Calculate total counts for each cluster below threshold by MacroArea\n",
    "cluster_counts = FMRI.groupby('Area')[['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']].apply(lambda x: (x < Cut).sum()).reset_index()\n",
    "\n",
    "# Create a stacked bar plot showing total counts for each cluster\n",
    "plt.figure(figsize=(12, 6))\n",
    "width = 0.6\n",
    "x = range(len(cluster_counts))\n",
    "\n",
    "# Define colors for each cluster\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Blue, Orange, Green, Red\n",
    "\n",
    "# Create stacked bars\n",
    "bottom = [0] * len(cluster_counts)\n",
    "for i, cluster in enumerate(['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']):\n",
    "    plt.bar(x, cluster_counts[cluster], width, bottom=bottom, \n",
    "            label=cluster, color=colors[i], alpha=0.8)\n",
    "    bottom = [b + c for b, c in zip(bottom, cluster_counts[cluster])]\n",
    "\n",
    "plt.xlabel('MaArearoArea')\n",
    "plt.ylabel('Total Count Below Threshold')\n",
    "plt.title('Total Count Below Threshold by Area (Colored by 4 Clusters)')\n",
    "plt.xticks(x, cluster_counts['Area'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the aggregation table\n",
    "print(\"Count_Below_Threshold aggregated by Area:\")\n",
    "print(macro_area_aggregation)\n",
    "print(\"\\nTotal counts for each cluster below threshold by Area:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_gt = 3\n",
    "test_set = FMRI[FMRI[\"Count_Below_Threshold\"]>=Number_gt]\n",
    "test_set_STRs = test_set.index.tolist()\n",
    "GENCIC_STRs = GENCIC[GENCIC[\"Circuits.32\"]==1].index.tolist()\n",
    "\n",
    "# Calculate overlap between test_set_STRs and GENCIC_STRs\n",
    "overlap_STRs = set(test_set_STRs).intersection(set(GENCIC_STRs))\n",
    "overlap_count = len(overlap_STRs)\n",
    "\n",
    "# Get the sizes of each dataset\n",
    "fMRI_size = len(FMRI.index)  # 163 regions\n",
    "GENCIC_size = len(GENCIC.index)  # 213 regions\n",
    "\n",
    "test_set_count = len(test_set_STRs)\n",
    "GENCIC_count = len(GENCIC_STRs)\n",
    "\n",
    "# For hypergeometric test, we need to determine the correct population\n",
    "# Since we're testing overlap between subsets from different populations,\n",
    "# we use the intersection of both datasets as our universe\n",
    "common_regions = set(FMRI.index).intersection(set(GENCIC.index))\n",
    "universe_size = len(common_regions)\n",
    "\n",
    "# Adjust counts to only include regions in the common universe\n",
    "test_set_in_universe = set(test_set_STRs).intersection(common_regions)\n",
    "GENCIC_in_universe = set(GENCIC_STRs).intersection(common_regions)\n",
    "test_set_count_adj = len(test_set_in_universe)\n",
    "GENCIC_count_adj = len(GENCIC_in_universe)\n",
    "\n",
    "from scipy.stats import hypergeom\n",
    "# P-value is probability of getting overlap_count or more overlaps by chance\n",
    "# hypergeom.sf(k-1, N, K, n) gives P(X >= k)\n",
    "# N = universe_size, K = GENCIC_count_adj, n = test_set_count_adj, k = overlap_count\n",
    "p_value = hypergeom.sf(overlap_count - 1, universe_size, GENCIC_count_adj, test_set_count_adj)\n",
    "\n",
    "print(f\"fMRI dataset size: {fMRI_size} regions\")\n",
    "print(f\"GENCIC dataset size: {GENCIC_size} regions\")\n",
    "print(f\"Common regions (universe): {universe_size} regions\")\n",
    "print(f\"Test set (Count_Below_Threshold >= {Number_gt}): {test_set_count} regions ({test_set_count_adj} in universe)\")\n",
    "print(f\"GENCIC Circuits.46 = 1: {GENCIC_count} regions ({GENCIC_count_adj} in universe)\")\n",
    "print(f\"Overlap: {overlap_count} regions\")\n",
    "print(f\"Overlap regions: {list(overlap_STRs)}\")\n",
    "print(f\"Hypergeometric test p-value: {p_value:.6f}\")\n",
    "\n",
    "# Calculate expected overlap under null hypothesis\n",
    "expected_overlap = (test_set_count_adj * GENCIC_count_adj) / universe_size\n",
    "print(f\"Expected overlap under null hypothesis: {expected_overlap:.2f}\")\n",
    "\n",
    "# Calculate overlap statistics\n",
    "overlap_percentage_test = (overlap_count / test_set_count_adj) * 100 if test_set_count_adj > 0 else 0\n",
    "overlap_percentage_GENCIC = (overlap_count / GENCIC_count_adj) * 100 if GENCIC_count_adj > 0 else 0\n",
    "\n",
    "print(f\"Overlap as % of fMRI set: {overlap_percentage_test:.2f}%\")\n",
    "print(f\"Overlap as % of GENCIC set: {overlap_percentage_GENCIC:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 67\n",
    "set2_size = 32\n",
    "observed_overlap = 14\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"Std intersection length: {results['std_intersection']:.2f}\")\n",
    "print(f\"Min intersection length: {results['min_intersection']}\")\n",
    "print(f\"Max intersection length: {results['max_intersection']}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "print(f\"Number of permutations with overlap >= {results['observed_overlap']}: {results['n_significant']}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_gt = 3\n",
    "test_set = FMRI[FMRI[\"Count_Below_Threshold\"]>=Number_gt]\n",
    "test_set_STRs = test_set.index.tolist()\n",
    "GENCIC_STRs = GENCIC[GENCIC[\"Circuits.46\"]==1].index.tolist()\n",
    "\n",
    "# Calculate overlap between test_set_STRs and GENCIC_STRs\n",
    "overlap_STRs = set(test_set_STRs).intersection(set(GENCIC_STRs))\n",
    "overlap_count = len(overlap_STRs)\n",
    "\n",
    "# Get the sizes of each dataset\n",
    "fMRI_size = len(FMRI.index)  # 163 regions\n",
    "GENCIC_size = len(GENCIC.index)  # 213 regions\n",
    "\n",
    "test_set_count = len(test_set_STRs)\n",
    "GENCIC_count = len(GENCIC_STRs)\n",
    "\n",
    "\n",
    "common_regions = set(FMRI.index).intersection(set(GENCIC.index))\n",
    "universe_size = len(common_regions)\n",
    "\n",
    "# Adjust counts to only include regions in the common universe\n",
    "test_set_in_universe = set(test_set_STRs).intersection(common_regions)\n",
    "GENCIC_in_universe = set(GENCIC_STRs).intersection(common_regions)\n",
    "test_set_count_adj = len(test_set_in_universe)\n",
    "GENCIC_count_adj = len(GENCIC_in_universe)\n",
    "\n",
    "#from scipy.stats import hypergeom\n",
    "#p_value = hypergeom.sf(overlap_count - 1, universe_size, GENCIC_count_adj, test_set_count_adj)\n",
    "\n",
    "print(f\"fMRI dataset size: {fMRI_size} regions\")\n",
    "print(f\"GENCIC dataset size: {GENCIC_size} regions\")\n",
    "print(f\"Test set (Count_Below_Threshold >= {Number_gt}): {test_set_count} regions ({test_set_count_adj} in universe)\")\n",
    "print(f\"GENCIC Circuits.46 = 1: {GENCIC_count} regions ({GENCIC_count_adj} in universe)\")\n",
    "print(f\"Overlap: {overlap_count} regions\")\n",
    "print(f\"Overlap regions: {list(overlap_STRs)}\")\n",
    "\n",
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 67\n",
    "set2_size = 46\n",
    "observed_overlap = 21\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "#SET1 = np.arange(1, 214)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 67\n",
    "set2_size = 46\n",
    "observed_overlap = 21\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"Std intersection length: {results['std_intersection']:.2f}\")\n",
    "print(f\"Min intersection length: {results['min_intersection']}\")\n",
    "print(f\"Max intersection length: {results['max_intersection']}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "print(f\"Number of permutations with overlap >= {results['observed_overlap']}: {results['n_significant']}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_permutation_results(results)\n",
    "\n",
    "# Create simple Venn diagram visualization using matplotlib\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Draw two overlapping circles\n",
    "circle1 = patches.Circle((0.35, 0.5), 0.3, alpha=0.5, color='blue', label='Set 1')\n",
    "circle2 = patches.Circle((0.65, 0.5), 0.3, alpha=0.5, color='red', label='Set 2')\n",
    "\n",
    "ax.add_patch(circle1)\n",
    "ax.add_patch(circle2)\n",
    "\n",
    "# Add text labels for each region\n",
    "ax.text(0.2, 0.5, f'{set1_size - observed_overlap}', fontsize=14, ha='center', va='center')\n",
    "ax.text(0.8, 0.5, f'{set2_size - observed_overlap}', fontsize=14, ha='center', va='center')\n",
    "ax.text(0.5, 0.5, f'{observed_overlap}', fontsize=14, ha='center', va='center', weight='bold')\n",
    "\n",
    "# Add set labels\n",
    "ax.text(0.2, 0.2, 'Set 1', fontsize=12, ha='center', va='center', weight='bold')\n",
    "ax.text(0.8, 0.2, 'Set 2', fontsize=12, ha='center', va='center', weight='bold')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title(f'Venn Diagram of Set Overlap\\nObserved Overlap: {observed_overlap}', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "title": "cell 25 code"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set threshold for analysis\n",
    "Number_gt = 3\n",
    "\n",
    "# Define test sets\n",
    "Region2Exclude = \"Thalamus\"\n",
    "FMRI_filt = FMRI[FMRI[\"MacroArea\"] != Region2Exclude]\n",
    "GENCIC_filt = GENCIC[GENCIC[\"REGION\"] != Region2Exclude]\n",
    "test_set = FMRI_filt[FMRI_filt[\"Count_Below_Threshold\"] >= Number_gt]\n",
    "test_set_STRs = test_set.index.tolist()\n",
    "GENCIC_STRs = GENCIC_filt[GENCIC_filt[\"Circuits.46\"] == 1].index.tolist()\n",
    "\n",
    "# Calculate overlap between test_set_STRs and GENCIC_STRs\n",
    "overlap_STRs = set(test_set_STRs).intersection(set(GENCIC_STRs))\n",
    "overlap_count = len(overlap_STRs)\n",
    "\n",
    "# Get dataset sizes\n",
    "fMRI_size = len(FMRI.index)  # 163 regions\n",
    "GENCIC_size = len(GENCIC.index)  # 213 regions\n",
    "test_set_count = len(test_set_STRs)\n",
    "GENCIC_count = len(GENCIC_STRs)\n",
    "\n",
    "# Define common universe and adjust counts\n",
    "common_regions = set(FMRI.index).intersection(set(GENCIC.index))\n",
    "universe_size = len(common_regions)\n",
    "\n",
    "test_set_in_universe = set(test_set_STRs).intersection(common_regions)\n",
    "GENCIC_in_universe = set(GENCIC_STRs).intersection(common_regions)\n",
    "test_set_count_adj = len(test_set_in_universe)\n",
    "GENCIC_count_adj = len(GENCIC_in_universe)\n",
    "\n",
    "# Calculate hypergeometric p-value\n",
    "from scipy.stats import hypergeom\n",
    "p_value = hypergeom.sf(overlap_count - 1, universe_size, GENCIC_count_adj, test_set_count_adj)\n",
    "\n",
    "# Print results\n",
    "print(f\"fMRI dataset size: {fMRI_size} regions\")\n",
    "print(f\"GENCIC dataset size: {GENCIC_size} regions\")\n",
    "print(f\"Test set (Count_Below_Threshold >= {Number_gt}): {test_set_count} regions ({test_set_count_adj} in universe)\")\n",
    "print(f\"GENCIC Circuits.46 = 1: {GENCIC_count} regions ({GENCIC_count_adj} in universe)\")\n",
    "print(f\"Overlap: {overlap_count} regions\")\n",
    "print(f\"Overlap regions: {list(overlap_STRs)}\")\n",
    "\n",
    "# Run permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 53\n",
    "set2_size = 38\n",
    "observed_overlap = 19\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "19 / 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 67\n",
    "set2_size = 46\n",
    "observed_overlap = 21\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"Std intersection length: {results['std_intersection']:.2f}\")\n",
    "print(f\"Min intersection length: {results['min_intersection']}\")\n",
    "print(f\"Max intersection length: {results['max_intersection']}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "print(f\"Number of permutations with overlap >= {results['observed_overlap']}: {results['n_significant']}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 67\n",
    "set2_size = 46\n",
    "observed_overlap = 21\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"Std intersection length: {results['std_intersection']:.2f}\")\n",
    "print(f\"Min intersection length: {results['min_intersection']}\")\n",
    "print(f\"Max intersection length: {results['max_intersection']}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "print(f\"Number of permutations with overlap >= {results['observed_overlap']}: {results['n_significant']}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_permutation_results(results)\n",
    "\n",
    "# Create simple Venn diagram visualization using matplotlib\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Draw two overlapping circles\n",
    "circle1 = patches.Circle((0.35, 0.5), 0.3, alpha=0.5, color='blue', label='Set 1')\n",
    "circle2 = patches.Circle((0.65, 0.5), 0.3, alpha=0.5, color='red', label='Set 2')\n",
    "\n",
    "ax.add_patch(circle1)\n",
    "ax.add_patch(circle2)\n",
    "\n",
    "# Add text labels for each region\n",
    "ax.text(0.2, 0.5, f'{set1_size - observed_overlap}', fontsize=14, ha='center', va='center')\n",
    "ax.text(0.8, 0.5, f'{set2_size - observed_overlap}', fontsize=14, ha='center', va='center')\n",
    "ax.text(0.5, 0.5, f'{observed_overlap}', fontsize=14, ha='center', va='center', weight='bold')\n",
    "\n",
    "# Add set labels\n",
    "ax.text(0.2, 0.2, 'Set 1', fontsize=12, ha='center', va='center', weight='bold')\n",
    "ax.text(0.8, 0.2, 'Set 2', fontsize=12, ha='center', va='center', weight='bold')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title(f'Venn Diagram of Set Overlap\\nObserved Overlap: {observed_overlap}', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 164)\n",
    "set1_size = 67\n",
    "set2_size = 43\n",
    "observed_overlap = 21\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"Std intersection length: {results['std_intersection']:.2f}\")\n",
    "print(f\"Min intersection length: {results['min_intersection']}\")\n",
    "print(f\"Max intersection length: {results['max_intersection']}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "print(f\"Number of permutations with overlap >= {results['observed_overlap']}: {results['n_significant']}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK Let test if each individual cluster is overlap with Test set. \n",
    "for cluster in ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']:\n",
    "    #_sub_test_set = FMRI.sort_values(by=cluster, ascending=False).head(46).index.values\n",
    "    _sub_test_set = FMRI.sort_values(by=cluster, ascending=False).tail(46).index.values\n",
    "    # Test overlap between _sub_test_set and test_set_STRs\n",
    "    _sub_overlap = set(_sub_test_set).intersection(set(test_set_STRs))\n",
    "    _sub_overlap_count = len(_sub_overlap)\n",
    "    \n",
    "    _sub_test_count = len(_sub_test_set)\n",
    "    _test_set_count = len(test_set_STRs)\n",
    "    _pool_size = 163  # total regions in the pool\n",
    "    \n",
    "    _sub_p_value = hypergeom.sf(_sub_overlap_count - 1, _pool_size, _test_set_count, _sub_test_count)\n",
    "\n",
    "    SET1 = np.arange(1, 164)\n",
    "    SET2 = np.arange(1, 164)\n",
    "    set1_size = 67\n",
    "    set2_size = 46\n",
    "    observed_overlap = _sub_overlap_count\n",
    "    perm_p_value = permutation_test_overlap(SET1, SET2, set1_size, set2_size, _sub_overlap_count, n_permutations=10000)\n",
    "    \n",
    "    print(f\"\\n{cluster} Analysis:\")\n",
    "    print(f\"Cluster regions: {_sub_test_count}\")\n",
    "    print(f\"Test set regions: {_test_set_count}\")\n",
    "    print(f\"Overlap: {_sub_overlap_count} regions\")\n",
    "    #print(f\"Overlap regions: {list(_sub_overlap)}\")\n",
    "    #print(f\"Hypergeometric p-value: {_sub_p_value:.6f}\")\n",
    "    print(f\"Permutation p-value: {perm_p_value['p_value']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another way. Under and Over connectivity above certain threshold. \n",
    "Cut = 0.5\n",
    "FMRI['Count_Below_Threshold_v2'] = (FMRI[['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']].abs() > Cut).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_gt = 2\n",
    "test_set = FMRI[FMRI[\"Count_Below_Threshold_v2\"]>=Number_gt]\n",
    "test_set_STRs = test_set.index.tolist()\n",
    "GENCIC_STRs = GENCIC[GENCIC[\"Circuits.46\"]==1].index.tolist()\n",
    "\n",
    "# Calculate overlap between test_set_STRs and GENCIC_STRs\n",
    "overlap_STRs = set(test_set_STRs).intersection(set(GENCIC_STRs))\n",
    "overlap_count = len(overlap_STRs)\n",
    "\n",
    "\n",
    "# First, let's get the union of all regions from both datasets to define our universe\n",
    "all_fMRI_regions = set(FMRI.index)\n",
    "all_GENCIC_regions = set(GENCIC.index)\n",
    "universe_regions = all_fMRI_regions.union(all_GENCIC_regions)\n",
    "universe_size = len(universe_regions)\n",
    "\n",
    "test_set_count = len(test_set_STRs)\n",
    "GENCIC_count = len(GENCIC_STRs)\n",
    "\n",
    "from scipy.stats import hypergeom\n",
    "p_value = hypergeom.sf(overlap_count - 1, universe_size, GENCIC_count, test_set_count)\n",
    "\n",
    "print(f\"Universe size (union of both datasets): {universe_size} regions\")\n",
    "print(f\"Test set (Count_Below_Threshold >= {Number_gt}): {test_set_count} regions\")\n",
    "print(f\"GENCIC Circuits.46 = 1: {GENCIC_count} regions\")\n",
    "print(f\"Overlap: {overlap_count} regions\")\n",
    "print(f\"Overlap regions: {list(overlap_STRs)}\")\n",
    "\n",
    "\n",
    "# Calculate expected overlap under null hypothesis\n",
    "expected_overlap = (test_set_count * GENCIC_count) / universe_size\n",
    "print(f\"Expected overlap under null hypothesis: {expected_overlap:.2f}\")\n",
    "\n",
    "# Calculate overlap statistics\n",
    "overlap_percentage_test = (overlap_count / test_set_count) * 100 if test_set_count > 0 else 0\n",
    "overlap_percentage_GENCIC = (overlap_count / GENCIC_count) * 100 if GENCIC_count > 0 else 0\n",
    "\n",
    "print(f\"Overlap as % of fMRI set: {overlap_percentage_test:.2f}%\")\n",
    "print(f\"Overlap as % of GENCIC set: {overlap_percentage_GENCIC:.2f}%\")\n",
    "print(f\"Hypergeometric test p-value: {p_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate FMRI dataframe with GENCIC Bias and Circuits.46 membership\n",
    "FMRI_annotated = FMRI.copy()\n",
    "\n",
    "# Add GENCIC Bias column\n",
    "FMRI_annotated['GENCIC_Bias'] = FMRI_annotated.index.map(GENCIC['Bias'])\n",
    "FMRI_annotated['GENCIC_Circuits_46'] = FMRI_annotated.index.map(GENCIC['Circuits.46'])\n",
    "FMRI_annotated['FullName'] = FMRI_annotated.index.map(GENCIC['Structure'])\n",
    "\n",
    "# Fill NaN values with 0 for regions not in GENCIC\n",
    "FMRI_annotated['GENCIC_Bias'] = FMRI_annotated['GENCIC_Bias'].fillna(0)\n",
    "FMRI_annotated['GENCIC_Circuits_46'] = FMRI_annotated['GENCIC_Circuits_46'].fillna(0)\n",
    "\n",
    "FMRI_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy to dat/\n",
    "FMRI_annotated.to_csv('/home/jw3514/Work/FuncConnectome/ASD_Mouse/Clusters_Images/FMRI_annotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMRI_annotated.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "# Conncetion overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_connectivity_data(score_mat_dir):\n",
    "    \"\"\"Load connectivity matrices\"\"\"\n",
    "    ipsi_info_mat = pd.read_csv(score_mat_dir + \"InfoMat.Ipsi.csv\", index_col=0)\n",
    "    weight_mat = pd.read_csv(score_mat_dir + \"WeightMat.Ipsi.csv\", index_col=0)\n",
    "    ipsi_info_mat_short = pd.read_csv(score_mat_dir + \"InfoMat.Ipsi.Short.3900.csv\", index_col=0)\n",
    "    ipsi_info_mat_long = pd.read_csv(score_mat_dir + \"InfoMat.Ipsi.Long.3900.csv\", index_col=0)\n",
    "    \n",
    "    return ipsi_info_mat, weight_mat, ipsi_info_mat_short, ipsi_info_mat_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mat_dir = os.path.join(ProjDIR, \"dat/allen-mouse-conn/ConnectomeScoringMat/\")\n",
    "ipsi_info_mat, weight_mat, ipsi_info_mat_short, ipsi_info_mat_long = load_connectivity_data(score_mat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cir_struc = GENCIC.loc[GENCIC[\"Circuits.46\"]==1, \"Structure\"]\n",
    "cir_struc_wm = weight_mat.loc[cir_struc, cir_struc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cir_fmri = FMRI_annotated.loc[FMRI_annotated[\"Count_Below_Threshold\"]>=3, \"FullName\"]\n",
    "cir_fmri_wm = weight_mat.loc[cir_fmri, cir_fmri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_struc = set(cir_struc_wm.index) | set(cir_fmri_wm.index)\n",
    "print(len(all_struc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# initialize counters and flags\n",
    "common = 0\n",
    "gencic_only = 0\n",
    "fmri_only = 0\n",
    "\n",
    "for str_i in all_struc:\n",
    "    for str_j in all_struc:\n",
    "        if str_i == str_j:\n",
    "            continue\n",
    "\n",
    "        gencic_flag = False\n",
    "        fmri_flag = False\n",
    "\n",
    "        if str_i in cir_struc_wm.index and str_j in cir_struc_wm.index:\n",
    "            if cir_struc_wm.loc[str_i, str_j] != 0:\n",
    "                gencic_flag = True\n",
    "        if str_i in cir_fmri_wm.index and str_j in cir_fmri_wm.index:\n",
    "            if cir_fmri_wm.loc[str_i, str_j] != 0:\n",
    "                fmri_flag = True\n",
    "\n",
    "        if gencic_flag and fmri_flag:\n",
    "            common += 1\n",
    "        elif gencic_flag:\n",
    "            gencic_only += 1\n",
    "        elif fmri_flag:\n",
    "            fmri_only += 1\n",
    "                \n",
    "print(f\"Common: {common}\")\n",
    "print(f\"Gencic only: {gencic_only}\")\n",
    "print(f\"Fmri only: {fmri_only}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "# Mouse Model fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy to dat/\n",
    "DataDIR = \"/home/jw3514/Work/FuncConnectome/ASD_Mouse/OneDrive_1_7-31-2025/\"\n",
    "data_csf = sio.loadmat(DataDIR + \"global_connectivity_allsubjs_CSF.mat\")\n",
    "data_gsr = sio.loadmat(DataDIR + \"global_connectivity_allsubjs_GSR.mat\")\n",
    "\n",
    "parcel_indices = pd.read_csv(DataDIR + \"parcel_indices_424.csv\")\n",
    "parcel_labels = pd.read_csv(DataDIR + \"parc_labels_424_LR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_csf = data_csf['global_connectivity_allsubjs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_csf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class MouseGlobalConnectivity:\n",
    "    def __init__(self, mat_file, parcel_idx_file, parcel_label_file):\n",
    "        self.mat_file = Path(mat_file)\n",
    "        self.mouse_models = ['shank3b', 'chd8', 'cntnap2', 'mecp2']\n",
    "        self.genotypes = ['mutant', 'wt']\n",
    "\n",
    "        # Load parcel metadata\n",
    "        self.parcel_indices = pd.read_csv(parcel_idx_file, header=None, names=['index'])  # 1-based indices\n",
    "        self.parcel_labels = pd.read_csv(parcel_label_file)  # has 'name' column\n",
    "\n",
    "        # Map indices to names (adjust 1-based to 0-based indexing)\n",
    "        idx_zero_based = self.parcel_indices['index'].values - 1\n",
    "        self.parcel_names = self.parcel_labels.iloc[idx_zero_based]['name'].tolist()\n",
    "\n",
    "        # Load MATLAB data\n",
    "        self.data = self._load_mat()\n",
    "\n",
    "    def _load_mat(self):\n",
    "        \"\"\"Load MATLAB .mat file (v7.2 or older)\"\"\"\n",
    "        mat = sio.loadmat(self.mat_file, squeeze_me=True)\n",
    "        return {k: v for k, v in mat.items() if not k.startswith('__')}\n",
    "\n",
    "    def get_connectivity(self, mouse_model, genotype):\n",
    "        \"\"\"Return connectivity matrix for a given mouse model and genotype\"\"\"\n",
    "        if mouse_model not in self.mouse_models:\n",
    "            raise ValueError(f\"Unknown mouse model: {mouse_model}\")\n",
    "        if genotype not in self.genotypes:\n",
    "            raise ValueError(f\"Genotype must be one of {self.genotypes}\")\n",
    "\n",
    "        arr = self.data['global_connectivity_allsubjs']  # 42 array of matrices\n",
    "        row = self.mouse_models.index(mouse_model)\n",
    "        col = self.genotypes.index(genotype)\n",
    "\n",
    "        mat = arr[row, col]\n",
    "        return np.array(mat)\n",
    "\n",
    "    def _merge_hemispheres(self, df, strategy=\"average\"):\n",
    "        \"\"\"Merge left/right hemisphere parcels. If only one side exists, keep as is.\"\"\"\n",
    "        base_names = df.index.str.replace(r'_(L|R)$', '', regex=True)\n",
    "\n",
    "        if strategy == \"average\":\n",
    "            # For each base name, average L/R if both exist, else just keep the one present\n",
    "            df = df.copy()\n",
    "            df['__base__'] = base_names\n",
    "            merged = []\n",
    "            for base, group in df.groupby('__base__'):\n",
    "                if len(group) == 2:\n",
    "                    merged_row = group.drop(columns='__base__').mean()\n",
    "                else:\n",
    "                    merged_row = group.drop(columns='__base__').iloc[0]\n",
    "                merged.append((base, merged_row))\n",
    "            merged_df = pd.DataFrame([row for _, row in merged], index=[base for base, _ in merged])\n",
    "            return merged_df\n",
    "\n",
    "        elif strategy == \"concat\":\n",
    "            # For each base name, concat L and R columns if both exist, else just keep the one present\n",
    "            left_mask = df.index.str.endswith('_L')\n",
    "            right_mask = df.index.str.endswith('_R')\n",
    "            left_df = df[left_mask].copy()\n",
    "            right_df = df[right_mask].copy()\n",
    "\n",
    "            left_df.index = left_df.index.str.replace(r'_L$', '', regex=True)\n",
    "            right_df.index = right_df.index.str.replace(r'_R$', '', regex=True)\n",
    "\n",
    "            left_df.columns = [f\"{c}_L\" for c in left_df.columns]\n",
    "            right_df.columns = [f\"{c}_R\" for c in right_df.columns]\n",
    "\n",
    "            # Find all base names\n",
    "            all_bases = set(left_df.index) | set(right_df.index)\n",
    "            concat_rows = []\n",
    "            concat_index = []\n",
    "            for base in sorted(all_bases):\n",
    "                left_row = left_df.loc[base] if base in left_df.index else None\n",
    "                right_row = right_df.loc[base] if base in right_df.index else None\n",
    "                if left_row is not None and right_row is not None:\n",
    "                    row = pd.concat([left_row, right_row])\n",
    "                elif left_row is not None:\n",
    "                    row = left_row\n",
    "                elif right_row is not None:\n",
    "                    row = right_row\n",
    "                else:\n",
    "                    continue  # Should not happen\n",
    "                concat_rows.append(row)\n",
    "                concat_index.append(base)\n",
    "            expanded = pd.DataFrame(concat_rows, index=concat_index)\n",
    "            expanded = expanded.sort_index()\n",
    "            return expanded\n",
    "\n",
    "        elif strategy is None:\n",
    "            return df\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"merge strategy must be 'average', 'concat', or None\")\n",
    "\n",
    "    def get_dataframe(self, mouse_model, genotype, merge=None):\n",
    "        \"\"\"\n",
    "        Return DataFrame with parcel names and connectivity values.\n",
    "        merge: None, 'average', or 'concat'\n",
    "        \"\"\"\n",
    "        mat = self.get_connectivity(mouse_model, genotype)\n",
    "        df = pd.DataFrame(\n",
    "            mat,\n",
    "            index=self.parcel_names,\n",
    "            columns=[f\"subj_{i+1}\" for i in range(mat.shape[1])]\n",
    "        )\n",
    "        df.index.name = 'parcel_name'\n",
    "\n",
    "        if merge is not None:\n",
    "            df = self._merge_hemispheres(df, strategy=merge)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "def connectivity_test(data, method, gene):\n",
    "    mut_df = data[method][gene][\"mutant\"]\n",
    "    wt_df = data[method][gene][\"wt\"]\n",
    "    results = []\n",
    "    for i, _str in enumerate(mut_df.index.values):\n",
    "        mut_conn = mut_df.iloc[i, :]\n",
    "        wt_conn = wt_df.iloc[i, :]\n",
    "        # Exclude invalid values (NaN, inf, -inf)\n",
    "        mut_conn_valid = mut_conn[~np.isnan(mut_conn) & np.isfinite(mut_conn)]\n",
    "        wt_conn_valid = wt_conn[~np.isnan(wt_conn) & np.isfinite(wt_conn)]\n",
    "        mut_conn_mean = mut_conn_valid.mean()\n",
    "        wt_conn_mean = wt_conn_valid.mean()\n",
    "        mut_conn_std = mut_conn_valid.std()\n",
    "        wt_conn_std = wt_conn_valid.std()\n",
    "        # Cohen's D\n",
    "        if len(mut_conn_valid) > 1 and len(wt_conn_valid) > 1:\n",
    "            # pooled std\n",
    "            n1 = len(mut_conn_valid)\n",
    "            n2 = len(wt_conn_valid)\n",
    "            s1 = mut_conn_std\n",
    "            s2 = wt_conn_std\n",
    "            pooled_std = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2)) if (n1 + n2 - 2) > 0 else np.nan\n",
    "            cohens_d = (mut_conn_mean - wt_conn_mean) / pooled_std if pooled_std > 0 else np.nan\n",
    "        else:\n",
    "            cohens_d = np.nan\n",
    "        # Only perform test if both groups have at least one valid value\n",
    "        if len(mut_conn_valid) > 0 and len(wt_conn_valid) > 0:\n",
    "            stat, p = mannwhitneyu(mut_conn_valid, wt_conn_valid, alternative='two-sided')\n",
    "        else:\n",
    "            p = np.nan\n",
    "        results.append({\n",
    "            'parcel_name': _str,\n",
    "            'mut_mean': mut_conn_mean,\n",
    "            'wt_mean': wt_conn_mean,\n",
    "            'conn_diff': mut_conn_mean - wt_conn_mean,\n",
    "            'mut_std': mut_conn_std,\n",
    "            'wt_std': wt_conn_std,\n",
    "            'mwu_p': p,\n",
    "            \"cohens_d\": cohens_d\n",
    "        })\n",
    "    results_df = pd.DataFrame(results).set_index('parcel_name')\n",
    "    results_df = results_df.sort_values(by='mwu_p')\n",
    "    return results_df\n",
    "\n",
    "def collapse_hemispheres(df, strategy='mean'):\n",
    "    if strategy == 'mean':\n",
    "        # Strip _L / _R suffix from parcel names\n",
    "        collapsed = df.copy()\n",
    "        collapsed.index = collapsed.index.str.replace(r'_(L|R)$', '', regex=True)\n",
    "        # Group by the new parcel name and take the mean across L and R\n",
    "        collapsed = collapsed.groupby(collapsed.index).mean()\n",
    "        return collapsed\n",
    "    elif strategy == 'concat':\n",
    "        # Strip _L / _R suffix from parcel names\n",
    "        collapsed = df.copy()\n",
    "        collapsed.index = collapsed.index.str.replace(r'_(L|R)$', '', regex=True)\n",
    "        # Group by the new parcel name and take the mean across L and R\n",
    "        collapsed = collapsed.groupby(collapsed.index).mean()\n",
    "        return collapsed\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid strategy: {strategy}\")\n",
    "        \n",
    "def print_data_treeview(data, indent=0):\n",
    "    for preproc in data:\n",
    "        print(\"  \" * indent + f\"{preproc}/\")\n",
    "        for gene in data[preproc]:\n",
    "            print(\"  \" * (indent + 1) + f\"{gene}/\")\n",
    "            for group in data[preproc][gene]:\n",
    "                print(\"  \" * (indent + 2) + f\"{group}: DataFrame shape {data[preproc][gene][group].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned up data structure: use nested dicts for easy access\n",
    "# Structure: data[preproc][gene][group] = dataframe\n",
    "\n",
    "data = {}\n",
    "for preproc, loader in {\n",
    "    \"CSF\": MouseGlobalConnectivity(\n",
    "        mat_file=DataDIR + \"global_connectivity_allsubjs_CSF.mat\",\n",
    "        parcel_idx_file=DataDIR + \"parcel_indices_424.csv\",\n",
    "        parcel_label_file=DataDIR + \"parc_labels_424_LR.csv\"\n",
    "    ),\n",
    "    \"GSR\": MouseGlobalConnectivity(\n",
    "        mat_file=DataDIR + \"global_connectivity_allsubjs_GSR.mat\",\n",
    "        parcel_idx_file=DataDIR + \"parcel_indices_424.csv\",\n",
    "        parcel_label_file=DataDIR + \"parc_labels_424_LR.csv\"\n",
    "    )\n",
    "}.items():\n",
    "    data[preproc] = {}\n",
    "    for gene in [\"shank3b\", \"cntnap2\", \"chd8\", \"mecp2\"]:\n",
    "        data[preproc][gene] = {}\n",
    "        for group in [\"mutant\", \"wt\"]:\n",
    "            data[preproc][gene][group] = loader.get_dataframe(gene, group, merge=None)\n",
    "print_data_treeview(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LR_merge = {}\n",
    "for preproc, loader in {\n",
    "    \"CSF\": MouseGlobalConnectivity(\n",
    "        mat_file=DataDIR + \"global_connectivity_allsubjs_CSF.mat\",\n",
    "        parcel_idx_file=DataDIR + \"parcel_indices_424.csv\",\n",
    "        parcel_label_file=DataDIR + \"parc_labels_424_LR.csv\"\n",
    "    ),\n",
    "    \"GSR\": MouseGlobalConnectivity(\n",
    "        mat_file=DataDIR + \"global_connectivity_allsubjs_GSR.mat\",\n",
    "        parcel_idx_file=DataDIR + \"parcel_indices_424.csv\",\n",
    "        parcel_label_file=DataDIR + \"parc_labels_424_LR.csv\"\n",
    "    )\n",
    "}.items():\n",
    "    data_LR_merge[preproc] = {}\n",
    "    for gene in [\"shank3b\", \"cntnap2\", \"chd8\", \"mecp2\"]:\n",
    "        data_LR_merge[preproc][gene] = {}\n",
    "        for group in [\"mutant\", \"wt\"]:\n",
    "            data_LR_merge[preproc][gene][group] = loader.get_dataframe(gene, group, merge=\"average\")\n",
    "print_data_treeview(data_LR_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shank3b_mut.head(5)\n",
    "data[\"CSF\"][\"shank3b\"][\"mutant\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSF_shank3b_res = connectivity_test(data, \"CSF\", \"shank3b\")\n",
    "CSF_chd8_res = connectivity_test(data, \"CSF\", \"chd8\")\n",
    "CSF_cntnap2_res = connectivity_test(data, \"CSF\", \"cntnap2\")\n",
    "CSF_mecp2_res = connectivity_test(data, \"CSF\", \"mecp2\")\n",
    "\n",
    "GSR_shank3b_res = connectivity_test(data, \"GSR\", \"shank3b\")\n",
    "GSR_chd8_res = connectivity_test(data, \"GSR\", \"chd8\")\n",
    "GSR_cntnap2_res = connectivity_test(data, \"GSR\", \"cntnap2\")\n",
    "GSR_mecp2_res = connectivity_test(data, \"GSR\", \"mecp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSF_shank3b_res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def compare_lr_correlations(results_df, plot=True, title=None):\n",
    "    \"\"\"\n",
    "    Compare left vs right hemisphere correlation for cohens_d and mwu_p,\n",
    "    and make scatter plots of L vs R for both cohens_d and -log10(mwu_p).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_df : pd.DataFrame\n",
    "        Must have index with `_L` and `_R` suffixes and columns 'cohens_d' and 'mwu_p'.\n",
    "    plot : bool\n",
    "        If True, show scatter plots.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Spearman correlations for cohens_d and mwu_p.\n",
    "    \"\"\"\n",
    "    # Make sure we only use parcels with both L and R\n",
    "    base_names = results_df.index.str.replace(r'_(L|R)$', '', regex=True)\n",
    "    results_df = results_df.assign(base=base_names)\n",
    "    \n",
    "    left_df = results_df[results_df.index.str.endswith('_L')].copy()\n",
    "    right_df = results_df[results_df.index.str.endswith('_R')].copy()\n",
    "    \n",
    "    # Align on base name\n",
    "    left_df.index = left_df['base']\n",
    "    right_df.index = right_df['base']\n",
    "    \n",
    "    # Intersect bases to be safe\n",
    "    common = left_df.index.intersection(right_df.index)\n",
    "    left_df = left_df.loc[common]\n",
    "    right_df = right_df.loc[common]\n",
    "    \n",
    "    # Spearman correlations\n",
    "    rho_cd, p_cd = spearmanr(left_df['cohens_d'], right_df['cohens_d'])\n",
    "    rho_pval, p_pval = spearmanr(left_df['mwu_p'], right_df['mwu_p'])\n",
    "    \n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        \n",
    "        # Scatter for cohens_d\n",
    "        axs[0].scatter(left_df['cohens_d'], right_df['cohens_d'], alpha=0.7)\n",
    "        axs[0].set_xlabel('Left cohens_d')\n",
    "        axs[0].set_ylabel('Right cohens_d')\n",
    "        axs[0].set_title(f'cohens_d L vs R\\nSpearman r={rho_cd:.2f}, p={p_cd:.2g}')\n",
    "        axs[0].axline((0, 0), slope=1, color='gray', linestyle='--', linewidth=1)\n",
    "        \n",
    "        # Scatter for -log10(mwu_p)\n",
    "        left_logp = -np.log10(left_df['mwu_p'].clip(lower=1e-20))\n",
    "        right_logp = -np.log10(right_df['mwu_p'].clip(lower=1e-20))\n",
    "        axs[1].scatter(left_logp, right_logp, alpha=0.7)\n",
    "        axs[1].set_xlabel('-log10(mwu_p) Left')\n",
    "        axs[1].set_ylabel('-log10(mwu_p) Right')\n",
    "        axs[1].set_title(f'-log10(mwu_p) L vs R\\nSpearman r={rho_pval:.2f}, p={p_pval:.2g}')\n",
    "        axs[1].axline((0, 0), slope=1, color='gray', linestyle='--', linewidth=1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if title is not None:\n",
    "            fig.suptitle(title)\n",
    "            plt.subplots_adjust(top=0.85)\n",
    "        plt.show()\n",
    "    \n",
    "    res = {\n",
    "        \"n_pairs\": len(common),\n",
    "        \"cohens_d_spearman_rho\": rho_cd,\n",
    "        \"cohens_d_pval\": p_cd,\n",
    "        \"mwu_p_spearman_rho\": rho_pval,\n",
    "        \"mwu_p_pval\": p_pval\n",
    "    }\n",
    "    return pd.DataFrame([res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res_df, name in zip([CSF_shank3b_res, GSR_shank3b_res, CSF_chd8_res, GSR_chd8_res, CSF_cntnap2_res, GSR_cntnap2_res, CSF_mecp2_res, GSR_mecp2_res], [\"CSF Shank3b\", \"GSR Shank3b\", \"CSF Chd8\", \"GSR Chd8\", \"CSF Cntnap2\", \"GSR Cntnap2\", \"CSF Mepc2\", \"GSR Mepc2\"]) :\n",
    "    lr_corr = compare_lr_correlations(res_df, title=name)\n",
    "#print(lr_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate each parcel's L and R entries into separate DataFrames for all 4 models, assuming index ends with \"_L\" or \"_R\"\n",
    "CSF_shank3b_L = CSF_shank3b_res[CSF_shank3b_res.index.str.endswith(\"_L\")].copy()\n",
    "CSF_shank3b_L.index = CSF_shank3b_L.index.str[:-2]\n",
    "\n",
    "CSF_shank3b_R = CSF_shank3b_res[CSF_shank3b_res.index.str.endswith(\"_R\")].copy()\n",
    "CSF_shank3b_R.index = CSF_shank3b_R.index.str[:-2]\n",
    "\n",
    "CSF_chd8_L = CSF_chd8_res[CSF_chd8_res.index.str.endswith(\"_L\")].copy()\n",
    "CSF_chd8_L.index = CSF_chd8_L.index.str[:-2]\n",
    "\n",
    "CSF_chd8_R = CSF_chd8_res[CSF_chd8_res.index.str.endswith(\"_R\")].copy()\n",
    "CSF_chd8_R.index = CSF_chd8_R.index.str[:-2]\n",
    "\n",
    "CSF_cntnap2_L = CSF_cntnap2_res[CSF_cntnap2_res.index.str.endswith(\"_L\")].copy()\n",
    "CSF_cntnap2_L.index = CSF_cntnap2_L.index.str[:-2]\n",
    "\n",
    "CSF_cntnap2_R = CSF_cntnap2_res[CSF_cntnap2_res.index.str.endswith(\"_R\")].copy()\n",
    "CSF_cntnap2_R.index = CSF_cntnap2_R.index.str[:-2]\n",
    "\n",
    "CSF_mecp2_L = CSF_mecp2_res[CSF_mecp2_res.index.str.endswith(\"_L\")].copy()\n",
    "CSF_mecp2_L.index = CSF_mecp2_L.index.str[:-2]\n",
    "\n",
    "CSF_mecp2_R = CSF_mecp2_res[CSF_mecp2_res.index.str.endswith(\"_R\")].copy()\n",
    "CSF_mecp2_R.index = CSF_mecp2_R.index.str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store L/R separated DataFrames in a dict: Data[gene][\"L\"], Data[gene][\"R\"]\n",
    "genes = ['shank3b', 'chd8', 'cntnap2', 'mecp2']\n",
    "csf_results = {\n",
    "    'shank3b': CSF_shank3b_res,\n",
    "    'chd8': CSF_chd8_res,\n",
    "    'cntnap2': CSF_cntnap2_res,\n",
    "    'mecp2': CSF_mecp2_res\n",
    "}\n",
    "\n",
    "Data = {}\n",
    "for gene in genes:\n",
    "    Data[gene] = {}\n",
    "    df = csf_results[gene]\n",
    "    Data[gene]['L'] = df[df.index.str.endswith('_L')].copy()\n",
    "    Data[gene]['L'].index = Data[gene]['L'].index.str[:-2]\n",
    "    Data[gene]['R'] = df[df.index.str.endswith('_R')].copy()\n",
    "    Data[gene]['R'].index = Data[gene]['R'].index.str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[\"shank3b\"][\"L\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to collect cohens_d for each gene, left hemisphere (L)\n",
    "cohens_d_L = pd.DataFrame({\n",
    "    gene: Data[gene][\"L\"][\"cohens_d\"] for gene in ['shank3b', 'chd8', 'cntnap2', 'mecp2']\n",
    "})\n",
    "# Add a column indicating the number of negative values (0-4) for each row across the 4 genes\n",
    "cohens_d_L[\"Count_Negative\"] = (cohens_d_L < 0).sum(axis=1)\n",
    "\n",
    "# Create a DataFrame to collect cohens_d for each gene, right hemisphere (R)\n",
    "cohens_d_R = pd.DataFrame({\n",
    "    gene: Data[gene][\"R\"][\"cohens_d\"] for gene in ['shank3b', 'chd8', 'cntnap2', 'mecp2']\n",
    "})\n",
    "cohens_d_R[\"Count_Negative\"] = (cohens_d_R < 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Find parcels with at least 3 negative values in L and R\n",
    "cohens_d_L_gt3 = cohens_d_L[cohens_d_L[\"Count_Negative\"] >= 3].index.values\n",
    "cohens_d_R_gt3 = cohens_d_R[cohens_d_R[\"Count_Negative\"] >= 3].index.values\n",
    "\n",
    "# Find the overlap (intersection) between L and R\n",
    "overlap_parcels = np.intersect1d(cohens_d_L_gt3, cohens_d_R_gt3)\n",
    "n_overlap = len(overlap_parcels)\n",
    "\n",
    "# Compute the p-value: \n",
    "# Null hypothesis: overlap as large as observed or greater occurs by chance,\n",
    "# given the sizes of two sets (hypergeometric test)\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "M = len(cohens_d_L.index)        # total number of parcels (universe)\n",
    "n = len(cohens_d_L_gt3)          # L \"successes\"\n",
    "N = len(cohens_d_R_gt3)          # R \"draws\"\n",
    "X = n_overlap                    # observed overlap\n",
    "\n",
    "# p-value: probability of overlap >= X by chance\n",
    "p_overlap = hypergeom.sf(X-1, M, n, N)\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of parcels with >=3 negative values (L):\", n)\n",
    "print(\"Number of parcels with >=3 negative values (R):\", N)\n",
    "print(\"Number of parcels overlapping (L  R):\", n_overlap)\n",
    "print(\"Overlapping parcels:\", overlap_parcels)\n",
    "print(\"Hypergeometric p-value for this overlap:\", p_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "44 / 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d_R_gt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSF_merge_shank3b_res = connectivity_test(data_LR_merge, \"CSF\", \"shank3b\")\n",
    "CSF_merge_chd8_res = connectivity_test(data_LR_merge, \"CSF\", \"chd8\")\n",
    "CSF_merge_cntnap2_res = connectivity_test(data_LR_merge, \"CSF\", \"cntnap2\")\n",
    "CSF_merge_mecp2_res = connectivity_test(data_LR_merge, \"CSF\", \"mecp2\")\n",
    "\n",
    "GSR_merge_shank3b_res = connectivity_test(data_LR_merge, \"GSR\", \"shank3b\")\n",
    "GSR_merge_chd8_res = connectivity_test(data_LR_merge, \"GSR\", \"chd8\")\n",
    "GSR_merge_cntnap2_res = connectivity_test(data_LR_merge, \"GSR\", \"cntnap2\")\n",
    "GSR_merge_mecp2_res = connectivity_test(data_LR_merge, \"GSR\", \"mecp2\")\n",
    "\n",
    "merge_res_dict = {\n",
    "    \"CSF_merge\": {\n",
    "        \"shank3b\": CSF_merge_shank3b_res,\n",
    "        \"chd8\": CSF_merge_chd8_res,\n",
    "        \"cntnap2\": CSF_merge_cntnap2_res,\n",
    "        \"mecp2\": CSF_merge_mecp2_res\n",
    "    },\n",
    "    \"GSR_merge\": {\n",
    "        \"shank3b\": GSR_merge_shank3b_res,\n",
    "        \"chd8\": GSR_merge_chd8_res,\n",
    "        \"cntnap2\": GSR_merge_cntnap2_res,\n",
    "        \"mecp2\": GSR_merge_mecp2_res\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_res_dict[\"CSF_merge\"][\"shank3b\"].sort_values(by=\"conn_diff\").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_res_dict[\"CSF_merge\"][\"chd8\"].sort_values(by=\"conn_diff\").tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_spearman(merge_results_dict, stat_type=\"conn_diff\", merge_key=\"CSF_merge\"):\n",
    "    \"\"\"\n",
    "    Compare models pairwise by Spearman correlation of MWU p-values using the new merge_res_dict structure.\n",
    "\n",
    "    merge_results_dict: dict\n",
    "        Outer keys = merge type (e.g., \"CSF_merge\", \"GSR_merge\")\n",
    "        Inner keys = model name (str)\n",
    "        Inner values = results DataFrame (must have 'conn_diff' column and same index)\n",
    "    stat_type: str\n",
    "        The column to use for correlation (default \"conn_diff\")\n",
    "    merge_key: str\n",
    "        Which merge type to use from merge_results_dict (default \"CSF_merge\")\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of pairwise Spearman correlation coefficients.\n",
    "    \"\"\"\n",
    "    # Use the specified merge_key to get the inner dict of models\n",
    "    results_dict = merge_results_dict[merge_key]\n",
    "    models = list(results_dict.keys())\n",
    "    corr_df = pd.DataFrame(index=models, columns=models, dtype=float)\n",
    "\n",
    "    for m1, m2 in combinations(models, 2):\n",
    "        # Align by parcel_name index\n",
    "        s1 = results_dict[m1][stat_type]\n",
    "        s2 = results_dict[m2][stat_type]\n",
    "        aligned = pd.concat([s1, s2], axis=1, join='inner').dropna()\n",
    "\n",
    "        rho, _ = spearmanr(aligned.iloc[:, 0], aligned.iloc[:, 1])\n",
    "\n",
    "        corr_df.loc[m1, m2] = rho\n",
    "        corr_df.loc[m2, m1] = rho\n",
    "\n",
    "    # Fill diagonal\n",
    "    for m in models:\n",
    "        corr_df.loc[m, m] = 1.0\n",
    "\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_table = compare_models_spearman(merge_res_dict, merge_key=\"CSF_merge\")\n",
    "sns.heatmap(rho_table.astype(float), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Spearman correlation of MWU p-values across models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_table = compare_models_spearman(merge_res_dict, merge_key=\"GSR_merge\")\n",
    "sns.heatmap(rho_table.astype(float), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Spearman correlation of MWU p-values across models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_topN_overlap(results_dict, N=50, merge_key=None):\n",
    "    \"\"\"\n",
    "    Compare models by % overlap of top-N parcels (lowest MWU p-values).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_dict : dict\n",
    "        If merge_key is None:\n",
    "            Keys = model name (str)\n",
    "            Values = results DataFrame (must have 'mwu_p' column)\n",
    "        If merge_key is not None:\n",
    "            Outer keys = merge type (e.g., \"CSF_merge\", \"GSR_merge\")\n",
    "            Inner keys = model name (str)\n",
    "            Inner values = results DataFrame (must have 'mwu_p' column)\n",
    "    N : int\n",
    "        Number of top parcels to compare.\n",
    "    merge_key : str or None\n",
    "        If not None, use this key to select the inner dict from results_dict.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Pairwise % overlap of top-N parcels.\n",
    "    \"\"\"\n",
    "    # Handle merge_res_dict format if merge_key is provided\n",
    "    if merge_key is not None:\n",
    "        results_dict = results_dict[merge_key]\n",
    "\n",
    "    models = list(results_dict.keys())\n",
    "    overlap_df = pd.DataFrame(index=models, columns=models, dtype=float)\n",
    "\n",
    "    # Precompute top-N sets for each model\n",
    "    top_sets = {}\n",
    "    for model, df in results_dict.items():\n",
    "        top_sets[model] = set(df.sort_values('mwu_p').head(N).index)\n",
    "\n",
    "    for m1, m2 in combinations(models, 2):\n",
    "        overlap_count = len(top_sets[m1] & top_sets[m2])\n",
    "        overlap_pct = overlap_count / N\n",
    "        overlap_df.loc[m1, m2] = overlap_pct\n",
    "        overlap_df.loc[m2, m1] = overlap_pct\n",
    "\n",
    "    # Fill diagonal with 1.0\n",
    "    for m in models:\n",
    "        overlap_df.loc[m, m] = 1.0\n",
    "\n",
    "    return overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models_topN_overlap(merge_res_dict, merge_key=\"CSF_merge\", N=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models_topN_overlap(merge_res_dict, merge_key=\"GSR_merge\", N=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC = pd.read_excel(os.path.join(ProjDIR, \"results/SupTabs.v57.xlsx\"), sheet_name=\"Table-S1- Structure Bias\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "CommonSTRs = merge_res_dict[\"CSF_merge\"][\"shank3b\"].index.intersection(GENCIC.index)\n",
    "GENCIC_intersect = GENCIC.loc[CommonSTRs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate conn_diff and mwu_p for each mouse model and each method to GENCIC DataFrame\n",
    "\n",
    "# Define the methods and mouse models to annotate\n",
    "methods = [\"CSF_merge\", \"GSR_merge\"]\n",
    "mouse_models = list(merge_res_dict[\"CSF_merge\"].keys())\n",
    "\n",
    "for method in methods:\n",
    "    for model in mouse_models:\n",
    "        # Prepare column names for conn_diff and mwu_p\n",
    "        conn_col = f\"{model}_{method}_conn_diff\"\n",
    "        pval_col = f\"{model}_{method}_mwu_p\"\n",
    "        # Initialize columns if not present\n",
    "        if conn_col not in GENCIC_intersect.columns:\n",
    "            GENCIC_intersect[conn_col] = pd.NA\n",
    "        if pval_col not in GENCIC_intersect.columns:\n",
    "            GENCIC_intersect[pval_col] = pd.NA\n",
    "        # Get the result DataFrame for this model/method\n",
    "        res_df = merge_res_dict[method][model]\n",
    "        for STR in GENCIC_intersect.index:\n",
    "            if STR in res_df.index:\n",
    "                GENCIC_intersect.at[STR, conn_col] = res_df.at[STR, \"conn_diff\"] if \"conn_diff\" in res_df.columns else pd.NA\n",
    "                GENCIC_intersect.at[STR, pval_col] = res_df.at[STR, \"mwu_p\"] if \"mwu_p\" in res_df.columns else pd.NA\n",
    "            else:\n",
    "                GENCIC_intersect.at[STR, conn_col] = pd.NA\n",
    "                GENCIC_intersect.at[STR, pval_col] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC_intersect.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC_intersect.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mousemodels = [\"shank3b\", \"chd8\", \"cntnap2\", \"mecp2\"]\n",
    "methods = [\"CSF_merge\", \"GSR_merge\"]\n",
    "\n",
    "fig, axes = plt.subplots(len(mousemodels), len(methods), figsize=(10, 16), dpi=150, sharex=True, sharey=False)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "for i, mousemodel in enumerate(mousemodels):\n",
    "    for j, method in enumerate(methods):\n",
    "        ax = axes[i, j]\n",
    "        x = GENCIC_intersect[\"Bias\"]\n",
    "        y = GENCIC_intersect[f\"{mousemodel}_{method}_conn_diff\"]\n",
    "        valid = x.notna() & y.notna()\n",
    "        if valid.sum() > 1:\n",
    "            corr, p = spearmanr(x[valid], y[valid])\n",
    "            ax.scatter(x[valid], y[valid], alpha=0.7, s=20)\n",
    "            ax.set_title(f\"{mousemodel} - {method}\")\n",
    "            ax.annotate(f\"r={corr:.2f}\\np={p:.2g}\", xy=(0.05, 0.85), xycoords=\"axes fraction\", fontsize=10,\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"gray\", alpha=0.7))\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"Not enough data\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "            ax.set_title(f\"{mousemodel} - {method}\")\n",
    "        if i == len(mousemodels) - 1:\n",
    "            ax.set_xlabel(\"GENCIC Bias\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"Conn Diff\")\n",
    "plt.suptitle(\"GENCIC Bias vs Mouse Model Conn Diff\\n(Spearman r and p shown)\", fontsize=16, y=0.92)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Collect all relevant columns for pairwise correlation\n",
    "cols = [\"Bias\"]\n",
    "for mousemodel in [\"shank3b\", \"chd8\", \"cntnap2\", \"mecp2\"]:\n",
    "    for method in [\"CSF_merge\", \"GSR_merge\"]:\n",
    "        col = f\"{mousemodel}_{method}_conn_diff\"\n",
    "        if col in GENCIC_intersect.columns:\n",
    "            cols.append(col)\n",
    "\n",
    "# Subset and drop rows with all-NA\n",
    "df_corr = GENCIC_intersect[cols].copy()\n",
    "df_corr = df_corr.dropna(how=\"all\", subset=cols)\n",
    "\n",
    "# Compute pairwise Spearman correlation\n",
    "corr_matrix = df_corr.corr(method=\"spearman\")\n",
    "\n",
    "# Cluster the correlation matrix and show clustered heatmap\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute linkage for rows and columns\n",
    "linkage_rows = linkage(corr_matrix, method='average')\n",
    "linkage_cols = linkage(corr_matrix.T, method='average')\n",
    "\n",
    "# Get the order of rows and columns after clustering\n",
    "row_order = leaves_list(linkage_rows)\n",
    "col_order = leaves_list(linkage_cols)\n",
    "\n",
    "# Reorder the correlation matrix\n",
    "corr_matrix_clustered = corr_matrix.iloc[row_order, col_order]\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "sns.heatmap(\n",
    "    corr_matrix_clustered, annot=True, cmap=\"vlag\", center=0,\n",
    "    linewidths=0.5, cbar_kws={\"label\": \"Spearman r\"}\n",
    ")\n",
    "plt.title(\"Clustered Spearman Correlation: GENCIC Bias & Mouse Model Conn Diff\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Top HypoConnected vs GENCIC Bias \n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "def compute_hypergeometric_pvalue(N_total, N_set1, N_set2, N_common):\n",
    "    \"\"\"\n",
    "    Compute the p-value for observing at least N_common overlap between two sets\n",
    "    of size N_set1 and N_set2 drawn from a population of size N_total.\n",
    "    \"\"\"\n",
    "    # P(X >= N_common)\n",
    "    # sf is \"survival function\" = 1 - cdf, so sf(N_common-1) = P(X >= N_common)\n",
    "    pval = hypergeom.sf(N_common-1, N_total, N_set1, N_set2)\n",
    "    return pval\n",
    "\n",
    "GENCIC_STRs = GENCIC_intersect[GENCIC_intersect[\"Circuits.46\"] == 1].index.values\n",
    "N_total_STR = 211\n",
    "N_GENCIC = len(GENCIC_STRs)\n",
    "N_top = 44\n",
    "N_bottom = 44\n",
    "\n",
    "for mousemodel in [\"shank3b\", \"chd8\", \"cntnap2\", \"mecp2\"]:\n",
    "    for method in [\"CSF_merge\", \"GSR_merge\"]:\n",
    "        col = f\"{mousemodel}_{method}_conn_diff\"\n",
    "        col = GENCIC_intersect[col].sort_values(ascending=False)\n",
    "        top46 = col.head(N_top)\n",
    "        bottom44 = col.tail(N_bottom)\n",
    "        Common_hyper = set(GENCIC_STRs).intersection(set(top46.index))\n",
    "        Common_hypo = set(GENCIC_STRs).intersection(set(bottom44.index))\n",
    "        pval_hyper = compute_hypergeometric_pvalue(N_total_STR, N_GENCIC, N_top, len(Common_hyper))\n",
    "        pval_hypo = compute_hypergeometric_pvalue(N_total_STR, N_GENCIC, N_bottom, len(Common_hypo))\n",
    "        print(f\"{mousemodel} {method} | Hyper: {len(Common_hyper)} (p={pval_hyper:.4g}), Hypo: {len(Common_hypo)} (p={pval_hypo:.4g})\")\n",
    "        #print(Common_hyper)\n",
    "        #print(Common_hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "gencic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
