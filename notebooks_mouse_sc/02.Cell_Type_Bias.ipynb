{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Cell-Type Bias Calculation (Allen Brain Cell Atlas)\n",
    "\n",
    "Computes ASD and DDD cell-type bias using the cluster-level Z2 expression\n",
    "specificity matrix. The pipeline:\n",
    "\n",
    "1. Compute per-gene V2-V3 chemistry correlation (10x Chromium)\n",
    "2. Create DN (DeNoise) gene weights: `weight_DN = weight_ISH × (V2_V3_CT_Corr)²`\n",
    "3. Compute weighted bias per cluster\n",
    "4. Test ASD-specific residuals (relative to DDD) in striatal CNU-LGE GABA clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "sys.path.insert(1, '../src')\n",
    "from ASD_Circuits import (LoadGeneINFO, Fil2Dict, Dict2Fil,\n",
    "                          MouseCT_AvgZ_Weighted, add_class,\n",
    "                          merge_bias_datasets, fit_structure_bias_linear_model)\n",
    "from plot import cluster_residual_boxplot\n",
    "\n",
    "HGNC, ENSID2Entrez, GeneSymbol2Entrez, Entrez2Symbol = LoadGeneINFO()\n",
    "\n",
    "with open(\"../config/config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "ProjDIR = config[\"ProjDIR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. V2-V3 Subclass Expression Correlation\n",
    "\n",
    "For each gene, compute Spearman correlation of expression across 338 subclasses\n",
    "between 10x V2 and V3 chemistry. Also compute ISH-MERFISH structure correlation.\n",
    "This identifies genes with inconsistent expression across platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORR_FILE = f\"../{config['data_files']['gene_cross_platform_corr']}\"\n",
    "EXPECTED_GENES = 16870\n",
    "\n",
    "if os.path.exists(CORR_FILE):\n",
    "    CorrDF = pd.read_csv(CORR_FILE, index_col=\"Genes\")\n",
    "    if len(CorrDF) == EXPECTED_GENES:\n",
    "        print(f\"Loaded cached correlation: {CorrDF.shape} from {CORR_FILE}\")\n",
    "    else:\n",
    "        print(f\"WARNING: cached file has {len(CorrDF)} genes, expected {EXPECTED_GENES}. Recomputing.\")\n",
    "        CorrDF = None\n",
    "else:\n",
    "    CorrDF = None\n",
    "\n",
    "if CorrDF is None:\n",
    "    # Load expression matrices\n",
    "    V2_Exp = pd.read_csv(f\"../{config['data_files']['subclass_v2_exp']}\", index_col=0)\n",
    "    V3_Exp = pd.read_csv(f\"../{config['data_files']['subclass_v3_exp']}\", index_col=0)\n",
    "    ISH_Exp = pd.read_csv(f\"../{config['data_files']['ish_log_mean_exp']}\", index_col=0)\n",
    "    MERFISH_Exp = pd.read_csv(f\"../{config['data_files']['merfish_cell_mean_umi']}\", index_col=0)\n",
    "\n",
    "    print(f\"V2: {V2_Exp.shape}, V3: {V3_Exp.shape}, ISH: {ISH_Exp.shape}, MERFISH: {MERFISH_Exp.shape}\")\n",
    "\n",
    "    # Shared genes across all four matrices\n",
    "    shared_genes = (set(ISH_Exp.index) & set(MERFISH_Exp.index)\n",
    "                    & set(V2_Exp.index) & set(V3_Exp.index))\n",
    "    # Shared structures between ISH and MERFISH\n",
    "    ish_cols = set(ISH_Exp.columns)\n",
    "    merfish_cols = set(MERFISH_Exp.columns)\n",
    "    shared_strs = sorted(ish_cols & merfish_cols)\n",
    "    # Shared subclasses between V2 and V3\n",
    "    shared_subs = sorted(set(V2_Exp.columns) & set(V3_Exp.columns))\n",
    "\n",
    "    print(f\"Shared genes: {len(shared_genes)}, shared structures: {len(shared_strs)}, \"\n",
    "          f\"shared subclasses: {len(shared_subs)}\")\n",
    "\n",
    "    rows = []\n",
    "    for gene in sorted(shared_genes):\n",
    "        ish_vals = ISH_Exp.loc[gene, shared_strs].values.astype(float)\n",
    "        mer_vals = MERFISH_Exp.loc[gene, shared_strs].values.astype(float)\n",
    "        v2_vals = V2_Exp.loc[gene, shared_subs].values.astype(float)\n",
    "        v3_vals = V3_Exp.loc[gene, shared_subs].values.astype(float)\n",
    "\n",
    "        corr_ish_mer = spearmanr(ish_vals, mer_vals).correlation\n",
    "        corr_v2_v3 = spearmanr(v2_vals, v3_vals).correlation\n",
    "        symbol = Entrez2Symbol.get(gene, \"\")\n",
    "\n",
    "        rows.append({\n",
    "            'Genes': gene,\n",
    "            'Corr': corr_ish_mer,\n",
    "            'Symbol': symbol,\n",
    "            'ISH_exp': np.mean(ish_vals),\n",
    "            'MERFISH_exp': np.mean(mer_vals),\n",
    "            'V2_V3_CT_Corr': corr_v2_v3,\n",
    "        })\n",
    "\n",
    "    CorrDF = pd.DataFrame(rows).set_index('Genes')\n",
    "    CorrDF.to_csv(CORR_FILE)\n",
    "    print(f\"Computed and saved correlation: {CorrDF.shape}\")\n",
    "\n",
    "print(f\"Median V2-V3 correlation: {CorrDF['V2_V3_CT_Corr'].median():.4f}\")\n",
    "print(f\"Median ISH-MERFISH correlation: {CorrDF['Corr'].median():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. DN Gene Weights\n",
    "\n",
    "Transform ISH gene weights by V2-V3 correlation to downweight genes\n",
    "with inconsistent expression across 10x chemistry versions:\n",
    "\n",
    "`weight_DN = weight_ISH × (V2_V3_CT_Corr)²`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../dat/Genetics/GeneWeights_DN\", exist_ok=True)\n",
    "\n",
    "v2v3_corr = CorrDF['V2_V3_CT_Corr']\n",
    "\n",
    "# ASD DN weights (gene_sets paths are absolute in config)\n",
    "ASD_GW_raw = Fil2Dict(config['gene_sets']['ASD_All']['geneweights'])\n",
    "ASD_GW_DN = {}\n",
    "for gene, weight in ASD_GW_raw.items():\n",
    "    if gene in v2v3_corr.index:\n",
    "        ASD_GW_DN[gene] = weight * (v2v3_corr.loc[gene] ** 2)\n",
    "\n",
    "asd_dn_path = f\"../{config['data_files']['asd_gene_weights_dn']}\"\n",
    "Dict2Fil(ASD_GW_DN, asd_dn_path)\n",
    "print(f\"ASD: {len(ASD_GW_raw)} raw genes -> {len(ASD_GW_DN)} DN genes -> {asd_dn_path}\")\n",
    "\n",
    "# DDD DN weights\n",
    "DDD_GW_raw = Fil2Dict(config['gene_sets']['DDD_293_ExcludeASD']['geneweights'])\n",
    "DDD_GW_DN = {}\n",
    "for gene, weight in DDD_GW_raw.items():\n",
    "    if gene in v2v3_corr.index:\n",
    "        DDD_GW_DN[gene] = weight * (v2v3_corr.loc[gene] ** 2)\n",
    "\n",
    "ddd_dn_path = f\"../{config['data_files']['ddd_gene_weights_dn']}\"\n",
    "Dict2Fil(DDD_GW_DN, ddd_dn_path)\n",
    "print(f\"DDD: {len(DDD_GW_raw)} raw genes -> {len(DDD_GW_DN)} DN genes -> {ddd_dn_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate against existing DN files\n",
    "for label, computed_gw, existing_path in [\n",
    "    (\"ASD\", ASD_GW_DN, asd_dn_path),\n",
    "    (\"DDD\", DDD_GW_DN, ddd_dn_path),\n",
    "]:\n",
    "    existing_gw = Fil2Dict(existing_path)\n",
    "    assert set(computed_gw.keys()) == set(existing_gw.keys()), f\"{label}: gene sets differ\"\n",
    "    max_diff = max(abs(computed_gw[g] - existing_gw[g]) for g in computed_gw)\n",
    "    print(f\"{label} DN validation: {len(computed_gw)} genes, max weight diff = {max_diff:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster annotations (5312 clusters with class/subclass labels)\n",
    "ClusterAnn = pd.read_csv(f\"../{config['data_files']['mouse_ct_annotation']}\", index_col=\"cluster_id_label\")\n",
    "\n",
    "# Cell type hierarchy -> Class2Cluster mapping\n",
    "CellTypesDF = pd.read_csv(f\"../{config['data_files']['cell_type_hierarchy']}\")\n",
    "Class2Cluster = {}\n",
    "for _, row in CellTypesDF.iterrows():\n",
    "    _cluster, _class = row.iloc[0], row.iloc[1]\n",
    "    Class2Cluster.setdefault(_class, []).append(_cluster)\n",
    "print(f\"Loaded {len(ClusterAnn)} clusters, {len(Class2Cluster)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z2 expression specificity matrix (16916 genes x 5312 clusters)\n",
    "MouseSC_Z2 = pd.read_parquet(f\"../{config['analysis_types']['CT_Z2']['expr_matrix']}\")\n",
    "print(f\"Z2 matrix: {MouseSC_Z2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4. Compute ASD and DDD Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../results/CT_Z2\", exist_ok=True)\n",
    "\n",
    "# ASD bias (60 DN genes)\n",
    "ASD_GW = Fil2Dict(f\"../{config['data_files']['asd_gene_weights_dn']}\")\n",
    "ASD_SC_Bias = MouseCT_AvgZ_Weighted(MouseSC_Z2, ASD_GW)\n",
    "ASD_SC_Bias = add_class(ASD_SC_Bias, ClusterAnn)\n",
    "ASD_SC_Bias.to_csv(\"../results/CT_Z2/ASD_Spark61_DN.csv\")\n",
    "print(f\"ASD bias: {ASD_SC_Bias.shape}, top cluster: {ASD_SC_Bias.index[0]}, \"\n",
    "      f\"EFFECT = {ASD_SC_Bias['EFFECT'].iloc[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# DDD bias (204 DN genes)\n",
    "DDD_GW = Fil2Dict(f\"../{config['data_files']['ddd_gene_weights_dn']}\")\n",
    "DDD_SC_Bias = MouseCT_AvgZ_Weighted(MouseSC_Z2, DDD_GW)\n",
    "DDD_SC_Bias = add_class(DDD_SC_Bias, ClusterAnn)\n",
    "DDD_SC_Bias.to_csv(\"../results/CT_Z2/DDD_293_ExcludeASD_DN.csv\")\n",
    "print(f\"DDD bias: {DDD_SC_Bias.shape}, top cluster: {DDD_SC_Bias.index[0]}, \"\n",
    "      f\"EFFECT = {DDD_SC_Bias['EFFECT'].iloc[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 5. Bias Boxplots by Cell Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_by_class(DF, Class2Cluster, title='Bias Across Cell Classes'):\n",
    "    \"\"\"Horizontal boxplot of bias EFFECT sorted by median, one box per class.\"\"\"\n",
    "    Class = sorted(Class2Cluster.keys())\n",
    "    dat, medians = [], []\n",
    "    for _CT in Class:\n",
    "        subdf = DF[DF[\"class_id_label\"] == _CT]\n",
    "        vals = subdf[\"EFFECT\"].dropna().values\n",
    "        dat.append(vals)\n",
    "        medians.append(np.median(vals) if len(vals) > 0 else 0)\n",
    "\n",
    "    order = np.argsort(medians)\n",
    "    fig, ax = plt.subplots(dpi=240, figsize=(8, 8))\n",
    "    fig.patch.set_alpha(0)\n",
    "    ax.patch.set_alpha(0)\n",
    "    bp = ax.boxplot([dat[i] for i in order],\n",
    "                    tick_labels=[Class[i] for i in order],\n",
    "                    vert=False, patch_artist=True)\n",
    "    colors = sns.color_palette(\"muted\", len(Class))\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    ax.set_xlabel('Bias (EFFECT)')\n",
    "    ax.set_title(title, weight='bold')\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_bias_by_class(ASD_SC_Bias, Class2Cluster, title='ASD Bias by Cell Class')\n",
    "plot_bias_by_class(DDD_SC_Bias, Class2Cluster, title='DDD Bias by Cell Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 6. ASD vs DDD Residual Analysis\n",
    "\n",
    "Fit linear model: ASD_EFFECT ~ DDD_EFFECT, then examine residuals.\n",
    "Positive residuals = clusters with higher ASD bias than expected from DDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merge_bias_datasets(ASD_SC_Bias, DDD_SC_Bias, suffixes=('_ASD', '_DDD'),\n",
    "                                  cols1=['Rank', 'EFFECT'], cols2=['Rank', 'EFFECT'])\n",
    "print(f\"Merged: {merged_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cell class groups for comparison\n",
    "class_groups = {\n",
    "    'CNU_LGE_GABA': '09 CNU-LGE GABA',\n",
    "    'IT_ET_Glut': '01 IT-ET Glut',\n",
    "    'NP_CT_L6b_Glut': '02 NP-CT-L6b Glut',\n",
    "    'CTX_CGE_GABA': '06 CTX-CGE GABA',\n",
    "    'CTX_MGE_GABA': '07 CTX-MGE GABA',\n",
    "    'TH_Glut': '18 TH Glut',\n",
    "}\n",
    "cluster_dict = {}\n",
    "for name, class_label in class_groups.items():\n",
    "    cluster_dict[name] = [x for x in ClusterAnn[ClusterAnn['class_id_label'] == class_label].index\n",
    "                          if x in merged_data.index]\n",
    "\n",
    "palette = [\"orange\", \"green\", \"purple\", \"red\", \"blue\", \"yellow\"]\n",
    "ref = \"CNU_LGE_GABA\"\n",
    "pairwise = [(ref, g) for g in class_groups if g != ref]\n",
    "_ = cluster_residual_boxplot(merged_data, cluster_dict, metric=\"residual\",\n",
    "                             palette=palette, pairwise_tests=pairwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 7. Permutation Test (Gene Label Shuffling)\n",
    "\n",
    "Shuffle gene labels between ASD and DDD 1000 times.\n",
    "For each permutation, recompute bias and residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "CACHE_FILE = \"../results/cache/CT_permutation_residuals.npz\"\n",
    "os.makedirs(\"../results/cache\", exist_ok=True)\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    print(f\"Loading cached permutation results from {CACHE_FILE}\")\n",
    "    cached = np.load(CACHE_FILE, allow_pickle=True)\n",
    "    perm_residuals = cached['residuals']\n",
    "    perm_index = cached['index']\n",
    "    n_perms = perm_residuals.shape[0]\n",
    "    print(f\"  {n_perms} permutations, {len(perm_index)} clusters\")\n",
    "else:\n",
    "    import random\n",
    "    n_perms = 1000\n",
    "    all_genes = list(ASD_GW.keys()) + list(DDD_GW.keys())\n",
    "    all_weights = list(ASD_GW.values()) + list(DDD_GW.values())\n",
    "    n_asd = len(ASD_GW)\n",
    "\n",
    "    perm_residuals_list = []\n",
    "    perm_index = None\n",
    "    for i in range(n_perms):\n",
    "        random.seed(i)\n",
    "        shuffled = all_genes.copy()\n",
    "        random.shuffle(shuffled)\n",
    "        perm_asd = dict(zip(shuffled[:n_asd], all_weights[:n_asd]))\n",
    "        perm_ddd = dict(zip(shuffled[n_asd:], all_weights[n_asd:]))\n",
    "\n",
    "        perm_asd_bias = MouseCT_AvgZ_Weighted(MouseSC_Z2, perm_asd)\n",
    "        perm_ddd_bias = MouseCT_AvgZ_Weighted(MouseSC_Z2, perm_ddd)\n",
    "        perm_merged = merge_bias_datasets(perm_asd_bias, perm_ddd_bias,\n",
    "                                          suffixes=('_ASD', '_DDD'),\n",
    "                                          cols1=['Rank', 'EFFECT'], cols2=['Rank', 'EFFECT'])\n",
    "        if perm_index is None:\n",
    "            perm_index = perm_merged.index.values\n",
    "        perm_residuals_list.append(perm_merged.loc[perm_index, 'residual'].values)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Permutation {i+1}/{n_perms}\")\n",
    "\n",
    "    perm_residuals = np.array(perm_residuals_list)\n",
    "    np.savez_compressed(CACHE_FILE, residuals=perm_residuals, index=perm_index)\n",
    "    print(f\"Saved {n_perms} permutations to {CACHE_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Permutation Null Distribution for Top CNU-LGE GABA Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_permutation_null(obs_residuals, perm_residuals, perm_index, cluster_id):\n",
    "    \"\"\"Plot permutation null for a single cluster's residual.\"\"\"\n",
    "    idx = np.where(perm_index == cluster_id)[0][0]\n",
    "    obs = obs_residuals.loc[cluster_id]\n",
    "    null = perm_residuals[:, idx]\n",
    "    pval = (np.sum(np.abs(null) >= np.abs(obs)) + 1) / (len(null) + 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    fig.patch.set_alpha(0)\n",
    "    ax.patch.set_alpha(0)\n",
    "    ax.hist(null, bins=20, color=\"skyblue\", edgecolor=\"k\", alpha=0.7)\n",
    "    ax.axvline(obs, color=\"red\", linestyle=\"--\", lw=2, label=f\"Observed: {obs:.3f}\")\n",
    "    ax.set_xlabel(\"Residual\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(f\"{cluster_id}\\nperm p = {pval:.3g}\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return pval\n",
    "\n",
    "\n",
    "cnu_lge = cluster_dict.get('CNU_LGE_GABA', [])\n",
    "if cnu_lge:\n",
    "    cnu_residuals = merged_data.loc[cnu_lge, 'residual'].sort_values(ascending=False)\n",
    "    print(\"Top CNU-LGE GABA residuals:\")\n",
    "    for ct in cnu_residuals.head(3).index:\n",
    "        pval = plot_permutation_null(merged_data['residual'], perm_residuals, perm_index, ct)\n",
    "        print(f\"  {ct}: residual={merged_data.loc[ct, 'residual']:.4f}, perm p={pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 8. Validation vs Existing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against pipeline-produced bias (same Z2 matrix and DN weights)\n",
    "pipeline_file = \"../results/CT_Z2/ASD_All_bias_addP_random.csv\"\n",
    "if os.path.exists(pipeline_file):\n",
    "    pipeline_bias = pd.read_csv(pipeline_file, index_col=0)\n",
    "    shared_idx = ASD_SC_Bias.index.intersection(pipeline_bias.index)\n",
    "    r_pipeline = np.corrcoef(ASD_SC_Bias.loc[shared_idx, 'EFFECT'],\n",
    "                             pipeline_bias.loc[shared_idx, 'EFFECT'])[0, 1]\n",
    "    max_diff = np.max(np.abs(ASD_SC_Bias.loc[shared_idx, 'EFFECT'] - pipeline_bias.loc[shared_idx, 'EFFECT']))\n",
    "    print(f\"Pipeline comparison: {len(shared_idx)} shared clusters, Pearson r = {r_pipeline:.6f}, \"\n",
    "          f\"max |diff| = {max_diff:.2e}\")\n",
    "else:\n",
    "    print(f\"Pipeline file not found: {pipeline_file} (run Snakefile.bias first)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against legacy results\n",
    "legacy_file = \"/mnt/data0/home_backup/Work/CellType_Psy/AllenBrainCellAtlas/dat/Bias/ASD.ClusterV3.top60.UMI.Z2.z1clip3.addP.csv\"\n",
    "if os.path.exists(legacy_file):\n",
    "    legacy_bias = pd.read_csv(legacy_file, index_col=0)\n",
    "    shared_idx = ASD_SC_Bias.index.intersection(legacy_bias.index)\n",
    "    r_legacy = np.corrcoef(ASD_SC_Bias.loc[shared_idx, 'EFFECT'],\n",
    "                           legacy_bias.loc[shared_idx, 'EFFECT'])[0, 1]\n",
    "    print(f\"Legacy comparison: {len(shared_idx)} shared clusters, Pearson r = {r_legacy:.6f}\")\n",
    "\n",
    "    # Top-10 side by side\n",
    "    top10 = ASD_SC_Bias.head(10).index\n",
    "    comparison = pd.DataFrame({\n",
    "        'EFFECT_new': ASD_SC_Bias.loc[top10, 'EFFECT'],\n",
    "        'EFFECT_legacy': legacy_bias.loc[top10, 'EFFECT'] if all(t in legacy_bias.index for t in top10) else np.nan,\n",
    "    })\n",
    "    print(\"\\nTop-10 clusters (new vs legacy):\")\n",
    "    print(comparison.to_string())\n",
    "else:\n",
    "    print(f\"Legacy file not found: {legacy_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 9. Sibling Pipeline Note\n",
    "\n",
    "The sibling control analysis for cell-type bias is run via Snakemake:\n",
    "\n",
    "```bash\n",
    "snakemake -s Snakefile.bias --configfile config/config.SC.DN.yaml --cores 10\n",
    "```\n",
    "\n",
    "This produces:\n",
    "- `results/CT_Z2/ASD_All_bias_addP_sibling.csv` — sibling null p-values\n",
    "- `results/CT_Z2/ASD_All_bias_addP_random.csv` — random null p-values\n",
    "\n",
    "The config points to DN gene weight files under `dat/Genetics/GeneWeights_DN/`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (gencic)",
   "language": "python",
   "name": "gencic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
