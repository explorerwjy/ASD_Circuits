{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook demonstrating CENCIC algorithm for circuit search with using ASD mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirement data file:\n",
    "1. ASD mutation bias file: \"Spark_Meta_EWS.Z2.bias.FDR.csv\"\n",
    "2. Information Score for connetome \"Spark_Meta_EWS.Z2.info.csv\"\n",
    "\n",
    "Scripts used in this notebook:\n",
    "1. script.Pareto.generate_bias_lim.py\n",
    "2. script.Pareto.generate_bias_lim.py\n",
    "3. script.Pareto.generate_bias_lim.py\n",
    "4. script.Pareto.generate_bias_lim.py\n",
    "5. script.Pareto.generate_bias_lim.py\n",
    "6. script.Pareto.generate_bias_lim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/jw3514/Work/ASD_Circuits_CellType/notebooks_mouse_str\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "RootDIR = \"/home/jw3514/Work/ASD_Circuits_CellType/\" # put this in the right place\n",
    "os.chdir(RootDIR + \"/notebooks_mouse_str\") # put this in the right place\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "sys.path.insert(1, RootDIR + 'src')\n",
    "# Need to add src directory to Python path first\n",
    "\n",
    "#sys.path.append(\"../src\")\n",
    "from ASD_Circuits import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calculate mutation strcture biases with ASD mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EFFECT</th>\n",
       "      <th>REGION</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Pvalue</th>\n",
       "      <th>Z_Match</th>\n",
       "      <th>qvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nucleus_accumbens</th>\n",
       "      <td>0.504843</td>\n",
       "      <td>Striatum</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>3.78551</td>\n",
       "      <td>0.025557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbital_area_lateral_part</th>\n",
       "      <td>0.502925</td>\n",
       "      <td>Isocortex</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.87780</td>\n",
       "      <td>0.021298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             EFFECT     REGION  Rank  Pvalue  Z_Match  \\\n",
       "STR                                                                     \n",
       "Nucleus_accumbens          0.504843   Striatum     1  0.0004  3.78551   \n",
       "Orbital_area_lateral_part  0.502925  Isocortex     2  0.0001  3.87780   \n",
       "\n",
       "                            qvalues  \n",
       "STR                                  \n",
       "Nucleus_accumbens          0.025557  \n",
       "Orbital_area_lateral_part  0.021298  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spark_ASD_STR_Bias = pd.read_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.FDR.csv\", index_col=0)\n",
    "Spark_ASD_STR_Bias.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 16 + 7400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate CCS scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Circuit Search with SA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Calculate Biaslim for SA search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate bias limits for different circuit sizes. In our paper we use size 46 as main search size since it has highest CCS score.\n",
    "\n",
    "The bias step size is 0.05 when bias > 0.3, 0.1 when bias > 0.2 and 0.5 when bias <= 0.2, to decrease computation burden. (we care less about the bias limits for low bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bias limits for different circuit sizes\n",
    "OutDIR = \"../dat/CircuitSearch/Biaslims/\"\n",
    "BiasDF = Spark_ASD_STR_Bias\n",
    "\n",
    "sizes = np.arange(10, 100, 1)\n",
    "for i, t in enumerate(sizes):\n",
    "    fout = open(OutDIR + \"biaslim.size.{}.txt\".format(t), 'w')\n",
    "    writer = csv.writer(fout)\n",
    "    lims = BiasLim(BiasDF, t)\n",
    "    for size, bias in lims:\n",
    "        writer.writerow([size, bias])\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 run bash script to search circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit Search Using Simulated Annealing\n",
    "Now we can run the bash script `scripts/submit_job_run_pareto.SI.sh` to search for circuits using the selected bias limits.\n",
    "\n",
    "This is a computationally intensive process that may take 1-2 days to complete, depending on:\n",
    "- Number of parallel threads used\n",
    "- Size of the search space\n",
    "- Number of bias limits being explored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of files/variables used in the bash script:\n",
    "- `BiasDF=../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.FDR.csv`: ASD mutation bias file\n",
    "- `AdjMat=../dat/allen-mouse-conn/ScoreingMat_jw_v3/WeightMat.Ipsi.csv`: Connection weights for connetome\n",
    "- `InfoMat=../dat/allen-mouse-conn/ScoreingMat_jw_v3/InfoMat.Ipsi.csv`: Information Score for connetome\n",
    "- `BiasLim=../dat/CircuitSearch/Biaslims/biaslim.size.46.txt`: Bias limits for different circuit sizes\n",
    "- `DIR=../dat/CircuitSearch/results/ASD_Pareto_46`:  Output directory\n",
    "- `NJob`: Number of total searches to complete the Pareto front (number of bias limits), calculated using `wc -l $BiasLim | cut -f 1 -d ' '`\n",
    "- `Nparallel=20`: Number of parallel threads used\n",
    "\n",
    "Fill the variables and run the bash script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3Collect results and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions used for collecting results and visualizing\n",
    "def normtoUnit(x, xmin, xmax):\n",
    "    return (x-xmin)/(xmax-xmin)\n",
    "\n",
    "def searchFil(text, DIR):\n",
    "    RES = []\n",
    "    for file in os.listdir(DIR):\n",
    "        if text in file:\n",
    "            RES.append(file)\n",
    "    return RES\n",
    "\n",
    "def LoadSA3(fname, DIR, InfoMat, minbias, topL=100):\n",
    "    fin = open(DIR+fname, 'rt')\n",
    "    max_score, max_bias, max_STRs = 0, 0, []\n",
    "    for i, l in enumerate(fin):\n",
    "        if i > topL:\n",
    "            break\n",
    "        l = l.strip().split()\n",
    "        bias = float(l[1])\n",
    "        if bias < minbias:\n",
    "            continue\n",
    "        STRs = l[2].split(\",\")\n",
    "        score = ScoreCircuit_SI_Joint(STRs, InfoMat)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_bias = bias\n",
    "            max_STRs = STRs\n",
    "    return max_score, max_bias, max_STRs\n",
    "\n",
    "def GetData2(params, size, DIR, adj_mat, InfoMat):\n",
    "    SCORES, CutBias, RealBias, STRS = [],[],[],[]\n",
    "    for i, row in params.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        score, real_minbias, STRs = LoadSA3(fil, DIR, InfoMat, row[\"bias\"])\n",
    "        score = ScoreCircuit_SI_Joint(STRs, InfoMat)\n",
    "        if score == 0:\n",
    "            continue\n",
    "        SCORES.append(score)\n",
    "        CutBias.append(row[\"bias\"])\n",
    "        RealBias.append(real_minbias)\n",
    "        STRS.append(STRs)\n",
    "    return SCORES, CutBias, RealBias, STRS\n",
    "\n",
    "def XXXX_cont(BiasDF, BiasDF2, biaslim_df, size, DIR, adj_mat, InfoMat):\n",
    "    #fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, bias), DIR)[0]\n",
    "    SCORES, CutBias, RealBias, STRS = GetData2(biaslim_df, size, DIR, adj_mat, InfoMat)\n",
    "    New_RealBias = []\n",
    "    for STRSET in STRS:\n",
    "        xx = BiasDF.loc[STRSET, \"EFFECT\"].mean()\n",
    "        New_RealBias.append(xx)\n",
    "    # Add top size STRs\n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_SI_Joint(topNSTRs, InfoMat)\n",
    "    SCORES.append(score)\n",
    "    CutBias.append(bias)\n",
    "    New_RealBias.append(bias)\n",
    "    STRS.append(topNSTRs)    \n",
    "    return SCORES, CutBias, New_RealBias, STRS\n",
    "\n",
    "def search_target_swap(size, BiasDF, NSwap, biaslim_df, adj_mat, \n",
    "                       ProbMat1, ProbMat1_short, ProbMat1_long, \n",
    "                       ProbMat2, ProbMat2_short, ProbMat2_long, DIR):\n",
    "    # TopN targets \n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_v7(topNSTRs, adj_mat, ProbMat1, ProbMat2)\n",
    "    # search along the profile\n",
    "    for i, row in biaslim_df.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        cohe, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat, ProbMat1, ProbMat2)\n",
    "        score = ScoreCircuit_v7(STRs, adj_mat, ProbMat1, ProbMat2)\n",
    "\n",
    "        bias = BiasDF.loc[STRs, \"EFFECT\"].mean()\n",
    "        NDiff = len(set(STRs).difference(topNSTRs))\n",
    "        if abs(NDiff-NSwap) < 2:\n",
    "\n",
    "            score1 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_short, ProbMat2_short)\n",
    "            score2 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_long, ProbMat2_long)\n",
    "            if score > 0.714:\n",
    "                #print(RegionDistributionsList(STRs))\n",
    "                print(score, score1, score2)\n",
    "            return bias, score, score1, score2\n",
    "    return None, None, None, None\n",
    "\n",
    "def search_target_swap2(size, BiasDF, biaslim, biaslim_df, adj_mat, \n",
    "                       ProbMat1, ProbMat1_short, ProbMat1_long, \n",
    "                       ProbMat2, ProbMat2_short, ProbMat2_long, DIR):\n",
    "    # TopN targets \n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_v7(topNSTRs, adj_mat, ProbMat1, ProbMat2)\n",
    "    # search along the profile\n",
    "    for i, row in biaslim_df.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        cohe, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat, ProbMat1, ProbMat2)\n",
    "        score = ScoreCircuit_v7(STRs, adj_mat, ProbMat1, ProbMat2)\n",
    "\n",
    "        bias = BiasDF.loc[STRs, \"EFFECT\"].mean()\n",
    "        #print(round(real_minbias,3), biaslim)\n",
    "        if round(real_minbias,3) == biaslim:\n",
    "            score1 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_short, ProbMat2_short)\n",
    "            score2 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_long, ProbMat2_long)\n",
    "            if score2 > 0.673:\n",
    "                #print()\n",
    "                print(RegionDistributionsList(STRs))\n",
    "            return bias, score, score1, score2\n",
    "    return None, None, None, None\n",
    "\n",
    "def LoadProfiles(BiasDF, BiasDF2, biaslim_df, size, DIR, adj_mat, InfoMat):\n",
    "    Scores, CutBias, RealBias, STRS = GetData2(biaslim_df, size, DIR, adj_mat, InfoMat)\n",
    "    # Add top size STRs\n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF2.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_SI_Joint(topNSTRs, InfoMat)\n",
    "    Scores.append(score)\n",
    "    CutBias.append(bias)\n",
    "    RealBias.append(bias)\n",
    "    STRS.append(topNSTRs)    \n",
    "    return Scores, CutBias, RealBias, STRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 46\n",
    "#biaslim_df = pd.read_csv(biaslim_dir + \"biaslim.size.{}.txt\".format(size), names=[\"size\", \"bias\"])\n",
    "ASD_DIR = \"../dat/Circuits/SA/ASD_Pareto_SI_v2_Size46_Nov2023/\"\n",
    "ASD_BiasDF = pd.read_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.csv\", index_col=\"STR\")\n",
    "biaslim_df = pd.read_csv(\n",
    "    \"../dat/Circuits/SA/biaslims2/biaslim.size.46.top17.txt\", names=[\"size\", \"bias\"])\n",
    "COHESPeak, CutBiasPeak, RealBiasPeak, STRSPeak = LoadProfiles(ASD_BiasDF, ASD_BiasDF, biaslim_df, size, \n",
    "                                              ASD_DIR, adj_mat, InfoMat)\n",
    "ASD_DFPeak = pd.DataFrame(data={\"Cohe\":COHESPeak, \"minBias\":CutBiasPeak, \"Bias\":RealBiasPeak})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Annoate resulting circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
