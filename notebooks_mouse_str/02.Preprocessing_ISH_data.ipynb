{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ProjDIR = \"/home/jw3514/Work/ASD_Circuits_CellType\"\n",
    "sys.path.insert(1, os.path.join(ProjDIR, \"src\"))\n",
    "from ASD_Circuits import ZscoreConverting\n",
    "\n",
    "os.chdir(os.path.join(ProjDIR, \"notebooks_mouse_str\"))\n",
    "print(f\"Project root: {ProjDIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config for data paths\n",
    "with open(os.path.join(ProjDIR, \"config/config.yaml\"), \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "BIAS_DIR = os.path.join(ProjDIR, \"dat/BiasMatrices\")\n",
    "ALLEN_DIR = os.path.join(ProjDIR, \"dat/allen-mouse-exp\")\n",
    "os.makedirs(BIAS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Preprocessing ISH Expression Data\n",
    "\n",
    "This notebook transforms the expression energy matrix into the Z2\n",
    "expression-matched z-score matrix used for all structure-level bias analyses.\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "1. **Load** Jon's log2+QN expression matrix (R-generated, 17,208 genes × 213 structures)\n",
    "2. **Z1** — per-gene z-score across structures\n",
    "3. **Expression features** — quantile ranks for expression matching\n",
    "4. **Z2** — expression-matched z-score (parallelized via `script_compute_Z2.py`)\n",
    "\n",
    "**Why Jon's R QN?** Python's quantile normalization differs from R's\n",
    "`preprocessCore::normalize.quantiles` in tie-breaking (r=0.993 between them).\n",
    "This difference propagates through Z1→Z2→bias and shifts the CCS local peak\n",
    "away from size 46, the circuit size used in the paper.\n",
    "Using Jon's R-generated QN preserves the exact CCS profile.\n",
    "See `notebook_validation/Validate_ISH_Z2_Pipeline` for the comparison.\n",
    "\n",
    "**Input**: `dat/allen-mouse-exp/Jon_ExpMat.log2.qn.csv`\n",
    "\n",
    "**Output**: `dat/BiasMatrices/AllenMouseBrain_Z2bias.parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Load Expression Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jon's log2+QN expression matrix (R-generated)\n",
    "# Raw expression: arithmetic mean of ISH expression energy across sections per gene\n",
    "# Then: log2(1+x) → R quantile normalization (preprocessCore::normalize.quantiles)\n",
    "jon_qn_path = os.path.join(ProjDIR, config[\"data_files\"][\"jon_exp_log2_qn\"])\n",
    "ExpMat = pd.read_csv(jon_qn_path, index_col=\"ROW\")\n",
    "print(f\"Expression matrix (log2+QN): {ExpMat.shape}\")\n",
    "print(f\"  Value range: [{np.nanmin(ExpMat.values):.4f}, {np.nanmax(ExpMat.values):.4f}]\")\n",
    "print(f\"  NaN fraction: {ExpMat.isna().sum().sum() / ExpMat.size:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Compute Z1 Matrix (Per-Gene Z-Score)\n",
    "\n",
    "For each gene, z-score its expression values across the 213 structures.\n",
    "This normalizes each gene to have mean=0, std=1 across structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_path = os.path.join(BIAS_DIR, \"AllenMouseBrain_Z1.parquet\")\n",
    "\n",
    "z1_data = []\n",
    "z1_genes = []\n",
    "for gene in ExpMat.index:\n",
    "    z1 = ZscoreConverting(ExpMat.loc[gene].values)\n",
    "    if not np.all(np.isnan(z1)):\n",
    "        z1_data.append(z1)\n",
    "        z1_genes.append(gene)\n",
    "\n",
    "Z1Mat = pd.DataFrame(\n",
    "    data=np.array(z1_data),\n",
    "    index=z1_genes,\n",
    "    columns=ExpMat.columns\n",
    ")\n",
    "Z1Mat.index.name = None\n",
    "\n",
    "Z1Mat.to_parquet(z1_path)\n",
    "print(f\"Z1 matrix: {Z1Mat.shape}\")\n",
    "print(f\"  NaN count: {Z1Mat.isna().sum().sum()}\")\n",
    "print(f\"  Range: [{Z1Mat.min().min():.3f}, {Z1Mat.max().max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 3. Expression Feature Table\n",
    "\n",
    "Build expression features for the Z2 computation script.\n",
    "Root expression = mean expression across all 213 structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_features_path = os.path.join(ALLEN_DIR, \"ExpMatchFeatures.csv\")\n",
    "\n",
    "root_exp = ExpMat.loc[Z1Mat.index].mean(axis=1, skipna=True)\n",
    "exp_features = pd.DataFrame({\"Genes\": Z1Mat.index, \"EXP\": root_exp.values})\n",
    "exp_features = exp_features.dropna(subset=[\"EXP\"]).reset_index(drop=True)\n",
    "exp_features = exp_features.sort_values(\"EXP\", ascending=True).reset_index(drop=True)\n",
    "exp_features[\"Rank\"] = exp_features.index + 1\n",
    "exp_features[\"quantile\"] = exp_features[\"Rank\"] / len(exp_features)\n",
    "exp_features = exp_features.set_index(\"Genes\")\n",
    "\n",
    "exp_features.to_csv(exp_features_path)\n",
    "print(f\"Expression features: {exp_features.shape[0]} genes\")\n",
    "print(f\"  Saved: {exp_features_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 4. Compute Z2 Matrix (Expression-Matched Z-Score)\n",
    "\n",
    "For each gene *g* and structure *s*:\n",
    "\n",
    "$$Z2(g, s) = \\frac{Z1(g, s) - \\text{mean}(Z1(\\text{matched}, s))}{\\text{std}(Z1(\\text{matched}, s))}$$\n",
    "\n",
    "Uses legacy expression match files (10,000 samples with replacement per gene,\n",
    "±5% quantile window). These are the same match files used to produce the\n",
    "original published Z2.\n",
    "\n",
    "Computation is parallelized via `scripts/script_compute_Z2.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2_path = os.path.join(BIAS_DIR, \"AllenMouseBrain_Z2bias.parquet\")\n",
    "MATCH_DIR = os.path.join(ProjDIR, config[\"data_files\"][\"legacy_match_dir\"])\n",
    "\n",
    "if os.path.exists(z2_path) and os.path.getmtime(z2_path) > os.path.getmtime(z1_path):\n",
    "    print(f\"Loading cached Z2 from {z2_path}\")\n",
    "    Z2Mat = pd.read_parquet(z2_path)\n",
    "else:\n",
    "    print(f\"Computing Z2 via scripts/script_compute_Z2.py ...\")\n",
    "    print(f\"  Match dir: {MATCH_DIR}\")\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        os.path.join(ProjDIR, \"scripts/script_compute_Z2.py\"),\n",
    "        \"--z1\", z1_path,\n",
    "        \"--exp-features\", exp_features_path,\n",
    "        \"--output\", z2_path,\n",
    "        \"--n-jobs\", \"10\",\n",
    "        \"--also-csv\",\n",
    "        \"--match-dir\", MATCH_DIR,\n",
    "    ]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"STDERR: {result.stderr}\")\n",
    "        raise RuntimeError(f\"Z2 computation failed with exit code {result.returncode}\")\n",
    "\n",
    "    Z2Mat = pd.read_parquet(z2_path)\n",
    "\n",
    "print(f\"Z2 matrix: {Z2Mat.shape}\")\n",
    "print(f\"  NaN count: {Z2Mat.isna().sum().sum()}\")\n",
    "print(f\"  Range: [{Z2Mat.min().min():.4f}, {Z2Mat.max().max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 5. Cell Composition-Normalized Matrices\n",
    "\n",
    "Produce Z2 matrices normalized by neuronal density and neuron-to-glia ratio.\n",
    "These are used as confound controls in notebook 04 (Section 8).\n",
    "\n",
    "**Source**: Cell Atlas for the Mouse Brain (Erö et al. 2018, Frontiers in Neuroinformatics).\n",
    "Provides neuron/glia cell density (cells/mm³) per brain structure.\n",
    "\n",
    "**Normalization**:\n",
    "- **Neuron density**: `expression / neuron_density × 10⁵` — expression per neuron\n",
    "- **Neuro-to-glia ratio**: `expression / (neuron_density / glia_density)` — expression adjusted for cell composition\n",
    "\n",
    "Both are then Z1-scored per gene and Z2-matched using the same expression features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def modify_str(x):\n",
    "    \"\"\"Standardize cell atlas region names to match Allen ISH structure names.\"\"\"\n",
    "    x = re.sub(\"[()]\", \"\", x)\n",
    "    x = re.sub(\"-\", \"_\", x)\n",
    "    x = re.sub(\"reunions\", \"reuniens\", x)\n",
    "    x = \"_\".join(x.split(\" \"))\n",
    "    return x\n",
    "\n",
    "# Load raw (pre-log, pre-QN) expression for normalization\n",
    "jon_raw_path = os.path.join(ProjDIR, config[\"data_files\"][\"jon_exp_raw\"])\n",
    "ExpRaw = pd.read_csv(jon_raw_path, index_col=\"ROW\")\n",
    "print(f\"Raw expression: {ExpRaw.shape}, range [{ExpRaw.min().min():.2f}, {ExpRaw.max().max():.2f}]\")\n",
    "\n",
    "# Load cell composition densities\n",
    "cell_comp_path = os.path.join(ProjDIR, \"dat/cell_composition/Cell_Atlas_for_the_Mouse_brain_2.csv\")\n",
    "cell_comp = pd.read_csv(cell_comp_path, index_col=\"Regions\")\n",
    "cell_comp.index = [modify_str(x) for x in cell_comp.index]\n",
    "\n",
    "# Filter to our 213 structures\n",
    "cell_comp_213 = cell_comp.loc[ExpRaw.columns]\n",
    "print(f\"Cell composition: {cell_comp_213.shape[0]} structures matched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Neuron density normalization: expression / neuron_density * 1e5\n",
    "neuron_density = cell_comp_213[\"Neurons [mm-3]\"]\n",
    "neuroden_norm = ExpRaw.div(neuron_density, axis=1) * 1e5\n",
    "\n",
    "# Neuro-to-glia ratio normalization: expression / (neuron/glia ratio)\n",
    "ng_ratio = cell_comp_213[\"Neurons [mm-3]\"] / cell_comp_213[\"Glia [mm-3]\"]\n",
    "neuro2glia_norm = ExpRaw.div(ng_ratio, axis=1)\n",
    "\n",
    "print(f\"NeuroDen norm range: [{neuroden_norm.min().min():.2f}, {neuroden_norm.max().max():.2f}]\")\n",
    "print(f\"Neuro2Glia norm range: [{neuro2glia_norm.min().min():.2f}, {neuro2glia_norm.max().max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z1 conversion (per-gene z-score across structures)\n",
    "def z1_convert_matrix(mat):\n",
    "    z1_data, z1_genes = [], []\n",
    "    for gene in mat.index:\n",
    "        z1 = ZscoreConverting(mat.loc[gene].values)\n",
    "        if not np.all(np.isnan(z1)):\n",
    "            z1_data.append(z1)\n",
    "            z1_genes.append(gene)\n",
    "    return pd.DataFrame(data=np.array(z1_data), index=z1_genes, columns=mat.columns)\n",
    "\n",
    "NeuroDen_Z1 = z1_convert_matrix(neuroden_norm)\n",
    "Neuro2Glia_Z1 = z1_convert_matrix(neuro2glia_norm)\n",
    "\n",
    "neuroden_z1_path = os.path.join(BIAS_DIR, \"NeuroDensityNorm_Z1.parquet\")\n",
    "neuro2glia_z1_path = os.path.join(BIAS_DIR, \"Neuro2GliaNorm_Z1.parquet\")\n",
    "NeuroDen_Z1.to_parquet(neuroden_z1_path)\n",
    "Neuro2Glia_Z1.to_parquet(neuro2glia_z1_path)\n",
    "print(f\"NeuroDen Z1: {NeuroDen_Z1.shape}\")\n",
    "print(f\"Neuro2Glia Z1: {Neuro2Glia_Z1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z2 computation for both cell-composition-normalized matrices\n",
    "# Uses the same expression features and match files as the standard Z2\n",
    "for label, z1_in, z1_out_path in [\n",
    "    (\"NeuroDensityNorm\", neuroden_z1_path, os.path.join(BIAS_DIR, \"NeuroDensityNorm_Z2.parquet\")),\n",
    "    (\"Neuro2GliaNorm\", neuro2glia_z1_path, os.path.join(BIAS_DIR, \"Neuro2GliaNorm_Z2.parquet\")),\n",
    "]:\n",
    "    if os.path.exists(z1_out_path) and os.path.getmtime(z1_out_path) > os.path.getmtime(z1_in):\n",
    "        print(f\"{label} Z2: loading cached {z1_out_path}\")\n",
    "    else:\n",
    "        print(f\"{label} Z2: computing via script_compute_Z2.py ...\")\n",
    "        cmd = [\n",
    "            sys.executable,\n",
    "            os.path.join(ProjDIR, \"scripts/script_compute_Z2.py\"),\n",
    "            \"--z1\", z1_in,\n",
    "            \"--exp-features\", exp_features_path,\n",
    "            \"--output\", z1_out_path,\n",
    "            \"--n-jobs\", \"10\",\n",
    "            \"--match-dir\", MATCH_DIR,\n",
    "        ]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        print(result.stdout[-200:] if result.stdout else \"\")\n",
    "        if result.returncode != 0:\n",
    "            print(f\"STDERR: {result.stderr}\")\n",
    "            raise RuntimeError(f\"{label} Z2 computation failed\")\n",
    "\n",
    "    z2_check = pd.read_parquet(z1_out_path)\n",
    "    print(f\"  {label} Z2: {z2_check.shape}, NaN={z2_check.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Step | Output | Shape | Path |\n",
    "|------|--------|-------|------|\n",
    "| Z1 | Per-gene z-score | 17,208 × 213 | `dat/BiasMatrices/AllenMouseBrain_Z1.parquet` |\n",
    "| Z2 | Exp-matched z-score | 17,208 × 213 | `dat/BiasMatrices/AllenMouseBrain_Z2bias.parquet` |\n",
    "| NeuroDen Z2 | Neuron density-normalized | 17,208 × 213 | `dat/BiasMatrices/NeuroDensityNorm_Z2.parquet` |\n",
    "| Neuro2Glia Z2 | Neuro-to-glia ratio-normalized | 17,208 × 213 | `dat/BiasMatrices/Neuro2GliaNorm_Z2.parquet` |\n",
    "\n",
    "**Input**: Jon's log2+QN expression (`dat/allen-mouse-exp/Jon_ExpMat.log2.qn.csv`)\n",
    "\n",
    "**Match files**: Legacy expression match files (`dat/allen-mouse-exp/ExpMatch_Legacy/`)\n",
    "\n",
    "**Note**: Python QN was tested but shifts the CCS local peak away from size 46.\n",
    "See `notebook_validation/Validate_ISH_Z2_Pipeline` for details."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "gencic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
