{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook demonstrating CENCIC algorithm for circuit search with using ASD mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirement data file:\n",
    "1. ASD mutation bias file: \"Spark_Meta_EWS.Z2.bias.FDR.csv\"\n",
    "2. Information Score for connetome \"Spark_Meta_EWS.Z2.info.csv\"\n",
    "\n",
    "Scripts used in this notebook:\n",
    "1. script.Pareto.generate_bias_lim.py\n",
    "2. script.Pareto.generate_bias_lim.py\n",
    "3. script.Pareto.generate_bias_lim.py\n",
    "4. script.Pareto.generate_bias_lim.py\n",
    "5. script.Pareto.generate_bias_lim.py\n",
    "6. script.Pareto.generate_bias_lim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "RootDIR = \"/home/jw3514/Work/ASD_Circuits_CellType/\" # put this in the right place\n",
    "os.chdir(RootDIR + \"/notebooks_mouse_str\") # put this in the right place\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "sys.path.insert(1, RootDIR + 'src')\n",
    "# Need to add src directory to Python path first\n",
    "\n",
    "#sys.path.append(\"../src\")\n",
    "from ASD_Circuits import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calculate mutation strcture biases with ASD mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_ASD_STR_Bias = pd.read_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.FDR.csv\", index_col=0)\n",
    "Spark_ASD_STR_Bias.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_ASD_STR_Bias.head(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate CCS scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Circuit Search with SA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Calculate Biaslim for SA search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate bias limits for different circuit sizes. In our paper we use size 46 as main search size since it has highest CCS score.\n",
    "\n",
    "The bias step size is 0.005 when bias > 0.3, 0.01 when bias > 0.2 and 0.05 when bias <= 0.2, to decrease computation burden. (we care less about the bias limits for low bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bias limits for different circuit sizes\n",
    "OutDIR = \"../dat/CircuitSearch/Biaslims/\"\n",
    "BiasDF = Spark_ASD_STR_Bias\n",
    "\n",
    "sizes = np.arange(10, 100, 1)\n",
    "for i, t in enumerate(sizes):\n",
    "    fout = open(OutDIR + \"biaslim.size.{}.txt\".format(t), 'w')\n",
    "    writer = csv.writer(fout)\n",
    "    lims = BiasLim(BiasDF, t)\n",
    "    for size, bias in lims:\n",
    "        writer.writerow([size, bias])\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_BiasLim = pd.read_csv(OutDIR + \"biaslim.size.46.txt\", names=[\"size\", \"bias\"])\n",
    "Selected_BiasLim = Selected_BiasLim[Selected_BiasLim[\"bias\"] >= 0.3] # select bias >= 0.3 to reduce number of jobs\n",
    "Selected_BiasLim.reset_index(inplace=True, drop=True)\n",
    "Selected_BiasLim.to_csv(OutDIR + \"biaslim.size.46.top17.txt\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_BiasLim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 run bash script to search circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit Search Using Simulated Annealing\n",
    "Now we can run the bash script `scripts/submit_job_run_pareto.SI.sh` to search for circuits using the selected bias limits.\n",
    "\n",
    "This is a computationally intensive process that may take 1-2 days to complete, depending on:\n",
    "- Number of parallel threads used\n",
    "- Size of the search space\n",
    "- Number of bias limits being explored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of files/variables used in the bash script:\n",
    "- `BiasDF=../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.FDR.csv`: ASD mutation bias file\n",
    "- `AdjMat=../dat/allen-mouse-conn/ScoreingMat_jw_v3/WeightMat.Ipsi.csv`: Connection weights for connetome\n",
    "- `InfoMat=../dat/allen-mouse-conn/ScoreingMat_jw_v3/InfoMat.Ipsi.csv`: Information Score for connetome\n",
    "- `BiasLim=../dat/CircuitSearch/Biaslims/biaslim.size.46.txt`: Bias limits for different circuit sizes\n",
    "- `DIR=../dat/CircuitSearch/results/ASD_Pareto_46`:  Output directory\n",
    "- `NJob`: Number of total searches to complete the Pareto front (number of bias limits), calculated using `wc -l $BiasLim | cut -f 1 -d ' '`\n",
    "- `Nparallel=20`: Number of parallel threads used\n",
    "\n",
    "Fill the variables and run the bash script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Collect results and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normtoUnit(x, xmin, xmax):\n",
    "    return (x-xmin)/(xmax-xmin)\n",
    "\n",
    "def searchFil(text, DIR):\n",
    "    #print(text)\n",
    "    RES = []\n",
    "    for file in os.listdir(DIR):\n",
    "        if text in file:\n",
    "            RES.append(file)\n",
    "    return RES\n",
    "\n",
    "def LoadSA3(fname, DIR, InfoMat, minbias, topL=100):\n",
    "    fin = open(DIR+fname, 'rt')\n",
    "    max_score, max_bias, max_STRs = 0, 0, []\n",
    "    for i, l in enumerate(fin):\n",
    "        if i > topL:\n",
    "            break\n",
    "        l = l.strip().split()\n",
    "        bias = float(l[1])\n",
    "        if bias < minbias:\n",
    "            continue\n",
    "        STRs = l[2].split(\",\")\n",
    "        score = ScoreCircuit_SI_Joint(STRs, InfoMat)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_bias = bias\n",
    "            max_STRs = STRs\n",
    "    return max_score, max_bias, max_STRs\n",
    "\n",
    "def GetData2(params, size, DIR, adj_mat, InfoMat):\n",
    "    SCORES, CutBias, RealBias, STRS = [],[],[],[]\n",
    "    for i, row in params.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        score, real_minbias, STRs = LoadSA3(fil, DIR, InfoMat, row[\"bias\"])\n",
    "        score = ScoreCircuit_SI_Joint(STRs, InfoMat)\n",
    "        if score == 0:\n",
    "            continue\n",
    "        SCORES.append(score)\n",
    "        CutBias.append(row[\"bias\"])\n",
    "        RealBias.append(real_minbias)\n",
    "        STRS.append(STRs)\n",
    "    return SCORES, CutBias, RealBias, STRS\n",
    "\n",
    "def XXXX_cont(BiasDF, BiasDF2, biaslim_df, size, DIR, adj_mat, InfoMat):\n",
    "    #fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, bias), DIR)[0]\n",
    "    SCORES, CutBias, RealBias, STRS = GetData2(biaslim_df, size, DIR, adj_mat, InfoMat)\n",
    "    New_RealBias = []\n",
    "    for STRSET in STRS:\n",
    "        xx = BiasDF.loc[STRSET, \"EFFECT\"].mean()\n",
    "        New_RealBias.append(xx)\n",
    "    # Add top size STRs\n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_SI_Joint(topNSTRs, InfoMat)\n",
    "    SCORES.append(score)\n",
    "    CutBias.append(bias)\n",
    "    New_RealBias.append(bias)\n",
    "    STRS.append(topNSTRs)    \n",
    "    return SCORES, CutBias, New_RealBias, STRS\n",
    "\n",
    "def search_target_swap(size, BiasDF, NSwap, biaslim_df, adj_mat, \n",
    "                       ProbMat1, ProbMat1_short, ProbMat1_long, \n",
    "                       ProbMat2, ProbMat2_short, ProbMat2_long, DIR):\n",
    "    # TopN targets \n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_v7(topNSTRs, adj_mat, ProbMat1, ProbMat2)\n",
    "    # search along the profile\n",
    "    for i, row in biaslim_df.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        cohe, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat, ProbMat1, ProbMat2)\n",
    "        score = ScoreCircuit_v7(STRs, adj_mat, ProbMat1, ProbMat2)\n",
    "\n",
    "        bias = BiasDF.loc[STRs, \"EFFECT\"].mean()\n",
    "        NDiff = len(set(STRs).difference(topNSTRs))\n",
    "        if abs(NDiff-NSwap) < 2:\n",
    "\n",
    "            score1 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_short, ProbMat2_short)\n",
    "            score2 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_long, ProbMat2_long)\n",
    "            if score > 0.714:\n",
    "                #print(RegionDistributionsList(STRs))\n",
    "                print(score, score1, score2)\n",
    "            return bias, score, score1, score2\n",
    "    return None, None, None, None\n",
    "\n",
    "def search_target_swap2(size, BiasDF, biaslim, biaslim_df, adj_mat, \n",
    "                       ProbMat1, ProbMat1_short, ProbMat1_long, \n",
    "                       ProbMat2, ProbMat2_short, ProbMat2_long, DIR):\n",
    "    # TopN targets \n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_v7(topNSTRs, adj_mat, ProbMat1, ProbMat2)\n",
    "    # search along the profile\n",
    "    for i, row in biaslim_df.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        cohe, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat, ProbMat1, ProbMat2)\n",
    "        score = ScoreCircuit_v7(STRs, adj_mat, ProbMat1, ProbMat2)\n",
    "\n",
    "        bias = BiasDF.loc[STRs, \"EFFECT\"].mean()\n",
    "        #print(round(real_minbias,3), biaslim)\n",
    "        if round(real_minbias,3) == biaslim:\n",
    "            score1 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_short, ProbMat2_short)\n",
    "            score2 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_long, ProbMat2_long)\n",
    "            if score2 > 0.673:\n",
    "                #print()\n",
    "                print(RegionDistributionsList(STRs))\n",
    "            return bias, score, score1, score2\n",
    "    return None, None, None, None\n",
    "\n",
    "def LoadProfiles(BiasDF, BiasDF2, biaslim_df, size, DIR, adj_mat, InfoMat):\n",
    "    Scores, CutBias, RealBias, STRS = GetData2(biaslim_df, size, DIR, adj_mat, InfoMat)\n",
    "    # Add top size STRs\n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF2.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_SI_Joint(topNSTRs, InfoMat)\n",
    "    Scores.append(score)\n",
    "    CutBias.append(bias)\n",
    "    RealBias.append(bias)\n",
    "    STRS.append(topNSTRs)    \n",
    "    return Scores, CutBias, RealBias, STRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read connectome files\n",
    "InfoMat = pd.read_csv(\"../dat/allen-mouse-conn/ConnectomeScoringMat/InfoMat.Ipsi.csv\", index_col=0)\n",
    "adj_mat = pd.read_csv(\"../dat/allen-mouse-conn/ConnectomeScoringMat/WeightMat.Ipsi.csv\", index_col=0)\n",
    "InfoMat_short = pd.read_csv(\"../dat/allen-mouse-conn/ConnectomeScoringMat/InfoMat.Ipsi.short.csv\", index_col=0)\n",
    "InfoMat_long = pd.read_csv(\"../dat/allen-mouse-conn/ConnectomeScoringMat/InfoMat.Ipsi.long.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 46\n",
    "#biaslim_df = pd.read_csv(biaslim_dir + \"biaslim.size.{}.txt\".format(size), names=[\"size\", \"bias\"])\n",
    "ASD_DIR = \"../dat/CircuitSearch/SA/ASD_Pareto_SI_Size46/\"\n",
    "ASD_BiasDF = Spark_ASD_STR_Bias\n",
    "biaslim_df = pd.read_csv(OutDIR + \"biaslim.size.46.top17.txt\")\n",
    "COHESPeak, CutBiasPeak, RealBiasPeak, STRSPeak = LoadProfiles(ASD_BiasDF, ASD_BiasDF, biaslim_df, size, \n",
    "                                              ASD_DIR, adj_mat, InfoMat)\n",
    "ASD_DFPeak = pd.DataFrame(data={\"Cohe\":COHESPeak, \"minBias\":CutBiasPeak, \"Bias\":RealBiasPeak})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120, figsize=(5,5))\n",
    "plt.plot(ASD_DFPeak[\"Cohe\"].values, ASD_DFPeak[\"Bias\"].values, marker=\".\", color=\"#542788\",  lw=2, markersize=8,\n",
    "             ls = \"-\", label=\"ASD\")\n",
    "plt.scatter(ASD_DFPeak[\"Cohe\"].values[-3], ASD_DFPeak[\"Bias\"].values[-3], marker=\"x\", s=50, color=\"red\",\n",
    "           zorder=100, label=\"Selected Circuits\")\n",
    "\n",
    "plt.xlabel(\"Circuit Score\")\n",
    "plt.ylabel(\"Mean Structure bias\")\n",
    "plt.grid()\n",
    "plt.ylim((0.05, 0.4))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the selected circuits\n",
    "print(RegionDistributionsList(STRSPeak[-3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting ASD and Sibling Circuit Data\n",
    "\n",
    "The following analysis compares ASD circuits with sibling control data.\n",
    "\n",
    "**Note:** The sibling data shown here is for visualization purposes only. The full analysis used data generated by running simulated annealing (SA) search with the same procedure on 10,000 subsampled sibling sets, which is too large to include here.\n",
    "\n",
    "To generate your own sibling data:\n",
    "1. Use the bash script `scripts/submit_job_run_pareto.SI.sh` \n",
    "2. Run it with different sibling sets as input\n",
    "\n",
    "For details on the original procedure used to generate these profiles, see `Optimized_Circuits_Information_Score.ipynb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from numpy file\n",
    "sibling_data = np.load('../dat/CircuitSearch/SA/ASD_Pareto_SI_Size46/circuit_analysis_data.sibling.SA.npz')\n",
    "meanbias = sibling_data['meanbias']\n",
    "meanSI = sibling_data['meanSI']\n",
    "topbias_sub = sibling_data['topbias_sub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=480, figsize=(4.2,4))\n",
    "\n",
    "ax.plot(ASD_DFPeak[\"Cohe\"].values, ASD_DFPeak[\"Bias\"].values, marker=\".\", color=\"#542788\",  lw=2, markersize=8,\n",
    "             ls = \"-\", label=\"ASD\")\n",
    "ax.scatter(ASD_DFPeak[\"Cohe\"].values[-4], ASD_DFPeak[\"Bias\"].values[-4], marker=\"x\", s=70, color=\"red\", lw=2,\n",
    "           zorder=100)\n",
    "ax.text(ASD_DFPeak[\"Cohe\"].values[-4], 0.01 + ASD_DFPeak[\"Bias\"].values[-4], s=\"Selected\\n Circuit\")\n",
    "\n",
    "ax.plot(topbias_sub[:,0,:].T, topbias_sub[:,1,:].T, color=\"grey\", markersize=1, lw=0.5,\n",
    "             ls = \"-\", alpha=0.05)\n",
    "#ax.plot(topbias_sub[0,0,:].T, topbias_sub[0,1,:].T, color=\"grey\", markersize=1, lw=1,\n",
    "#             ls = \"-\", alpha=1, label=\"Sibling Circuit\")\n",
    "\n",
    "ax.plot(meanSI, meanbias, marker=\".\", color=\"Orange\", lw=2, markersize=8,\n",
    "             ls = \"-\", alpha=1, label=\"Average Sibling Circuit\")\n",
    "ax.plot(meanSI, meanbias, color=\"grey\", lw=2, markersize=8,\n",
    "             ls = \"-\", alpha=1, label=\"Sibling Circuit\", zorder=0)\n",
    "\n",
    "#box = ax.get_position()\n",
    "#ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "#ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.9))\n",
    "ax.legend(loc=\"lower left\", frameon=False)\n",
    "\n",
    "plt.xlabel(\"Circuit Connectivity Score\", fontsize=14)\n",
    "plt.ylabel(\"Average Mutation Bias\", fontsize=14)\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.ylim(0.05, 0.42)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Annoate resulting circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrape ASD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Extract and Visualize Bootstrap Pareto Fronts\n",
    "\n",
    "In this section, we extract pareto front data from all bootstrap samples and visualize the variability across different bootstrap replicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all pareto front CSV files from different boot IDs\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Find all pareto front CSV files\n",
    "Boot_DIR = \"../results/CircuitSearch_Bootstrap/\"\n",
    "pareto_files = glob.glob(Boot_DIR + \"*/pareto_fronts/*_pareto_front.csv\")\n",
    "pareto_files.sort()\n",
    "\n",
    "print(f\"Found {len(pareto_files)} pareto front files:\")\n",
    "for f in pareto_files:\n",
    "    print(f\"  - {os.path.basename(os.path.dirname(os.path.dirname(f)))}: {os.path.basename(f)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and combine all pareto front CSV files\n",
    "all_pareto_data = []\n",
    "\n",
    "for pf_file in pareto_files:\n",
    "    # Extract boot ID from directory name\n",
    "    boot_id = os.path.basename(os.path.dirname(os.path.dirname(pf_file)))\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(pf_file)\n",
    "    \n",
    "    # Add boot_id column to track which bootstrap sample this is from\n",
    "    df['boot_id'] = boot_id\n",
    "    \n",
    "    all_pareto_data.append(df)\n",
    "    print(f\"Loaded {boot_id}: {len(df)} rows\")\n",
    "\n",
    "# Combine all dataframes\n",
    "combined_pareto_df = pd.concat(all_pareto_data, ignore_index=True)\n",
    "print(f\"\\nTotal rows in combined dataframe: {len(combined_pareto_df)}\")\n",
    "print(f\"Columns: {list(combined_pareto_df.columns)}\")\n",
    "\n",
    "combined_pareto_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boot_DIR = \"../results/CircuitSearch_Bootstrap/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of pareto front data by boot_id\n",
    "summary_by_boot = combined_pareto_df.groupby('boot_id').size().reset_index(name='num_points')\n",
    "print(\"Number of pareto front points per bootstrap sample:\")\n",
    "summary_by_boot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Copy individual pareto front files to summary directory\n",
    "# (Uncomment if you want to keep separate files)\n",
    "\"\"\"\n",
    "for pf_file in pareto_files:\n",
    "    dest_file = summary_dir + os.path.basename(pf_file)\n",
    "    shutil.copy2(pf_file, dest_file)\n",
    "    print(f\"Copied {os.path.basename(pf_file)} to summary directory\")\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize all bootstrap pareto fronts\n",
    "# fig, ax = plt.subplots(dpi=120, figsize=(8, 6))\n",
    "\n",
    "# # Plot each boot_id as a separate line\n",
    "# boot_ids = combined_pareto_df['boot_id'].unique()\n",
    "# colors = plt.cm.tab20(np.linspace(0, 1, len(boot_ids)))\n",
    "\n",
    "# for i, boot_id in enumerate(sorted(boot_ids)):\n",
    "#     boot_data = combined_pareto_df[combined_pareto_df['boot_id'] == boot_id]\n",
    "#     # Sort by circuit_score for better line plotting\n",
    "#     boot_data = boot_data.sort_values('circuit_score')\n",
    "    \n",
    "#     ax.plot(boot_data['circuit_score'], boot_data['mean_bias'], \n",
    "#             marker='.', markersize=6, lw=1.5, alpha=0.7,\n",
    "#             label=boot_id, color=colors[i])\n",
    "\n",
    "# ax.set_xlabel(\"Circuit Connectivity Score\", fontsize=12)\n",
    "# ax.set_ylabel(\"Average Mutation Bias\", fontsize=12)\n",
    "# ax.set_title(\"Bootstrap Pareto Fronts (All Boot IDs)\", fontsize=14)\n",
    "# ax.grid(True, alpha=0.3)\n",
    "# ax.legend(loc='best', fontsize=8, ncol=2)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alternative visualization: Show bootstrap variability similar to sibling plot style\n",
    "# fig, ax = plt.subplots(dpi=120, figsize=(7, 6))\n",
    "\n",
    "# # Plot each boot_id as a gray line with low alpha to show variability\n",
    "# boot_ids = combined_pareto_df['boot_id'].unique()\n",
    "\n",
    "# for boot_id in sorted(boot_ids):\n",
    "#     boot_data = combined_pareto_df[combined_pareto_df['boot_id'] == boot_id]\n",
    "#     boot_data = boot_data.sort_values('circuit_score')\n",
    "    \n",
    "#     ax.plot(boot_data['circuit_score'], boot_data['mean_bias'], \n",
    "#             color='grey', lw=1, alpha=0.3, zorder=1)\n",
    "\n",
    "# # Calculate mean pareto front across all bootstraps\n",
    "# mean_pareto = combined_pareto_df.groupby('bias_limit').agg({\n",
    "#     'circuit_score': 'mean',\n",
    "#     'mean_bias': 'mean'\n",
    "# }).reset_index().sort_values('circuit_score')\n",
    "\n",
    "# ax.plot(mean_pareto['circuit_score'], mean_pareto['mean_bias'], \n",
    "#         marker='o', markersize=6, lw=2.5, color='#542788',\n",
    "#         label='Mean Bootstrap Pareto Front', zorder=10)\n",
    "\n",
    "# ax.set_xlabel(\"Circuit Connectivity Score\", fontsize=12)\n",
    "# ax.set_ylabel(\"Average Mutation Bias\", fontsize=12)\n",
    "# ax.set_title(\"Bootstrap Pareto Front Variability\", fontsize=14)\n",
    "# ax.grid(True, alpha=0.3)\n",
    "# ax.legend(loc='best', fontsize=10)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate plot for ASD_Boot samples vs main SPARK samples with 95% CI\n",
    "from scipy import interpolate\n",
    "\n",
    "fig, ax = plt.subplots(dpi=120, figsize=(8, 6))\n",
    "\n",
    "# Filter to get only bootstrap samples (exclude SPARK_Main and SPARK_61)\n",
    "boot_samples = [f'ASD_Boot{i}' for i in range(1000)]\n",
    "boot_samples_in_data = [bid for bid in boot_samples if bid in combined_pareto_df['boot_id'].values]\n",
    "\n",
    "# Create a common grid of circuit_score values for interpolation\n",
    "all_circuit_scores = []\n",
    "for boot_id in boot_samples_in_data:\n",
    "    boot_data = combined_pareto_df[combined_pareto_df['boot_id'] == boot_id]\n",
    "    all_circuit_scores.extend(boot_data['circuit_score'].values)\n",
    "\n",
    "# Define interpolation grid\n",
    "circuit_score_min = np.min(all_circuit_scores)\n",
    "circuit_score_max = np.max(all_circuit_scores)\n",
    "circuit_score_grid = np.linspace(circuit_score_min, circuit_score_max, 100)\n",
    "\n",
    "# Interpolate each bootstrap sample onto the common grid\n",
    "interpolated_bias_values = []\n",
    "for boot_id in boot_samples_in_data:\n",
    "    boot_data = combined_pareto_df[combined_pareto_df['boot_id'] == boot_id]\n",
    "    boot_data = boot_data.sort_values('circuit_score')\n",
    "    \n",
    "    # Only interpolate if we have enough points\n",
    "    if len(boot_data) >= 2:\n",
    "        # Linear interpolation\n",
    "        f_interp = interpolate.interp1d(\n",
    "            boot_data['circuit_score'].values, \n",
    "            boot_data['mean_bias'].values,\n",
    "            kind='linear',\n",
    "            bounds_error=False,\n",
    "            fill_value=np.nan\n",
    "        )\n",
    "        interpolated_bias = f_interp(circuit_score_grid)\n",
    "        interpolated_bias_values.append(interpolated_bias)\n",
    "\n",
    "# Convert to array: shape (n_bootstrap, n_grid_points)\n",
    "interpolated_bias_array = np.array(interpolated_bias_values)\n",
    "\n",
    "# Compute 95% CI (ignoring NaN values)\n",
    "lower_ci = np.nanpercentile(interpolated_bias_array, 2.5, axis=0)\n",
    "upper_ci = np.nanpercentile(interpolated_bias_array, 97.5, axis=0)\n",
    "median_bias = np.nanmedian(interpolated_bias_array, axis=0)\n",
    "\n",
    "# Plot 95% CI as shaded region\n",
    "ax.fill_between(circuit_score_grid, lower_ci, upper_ci, \n",
    "                color='grey', alpha=0.3, label='95% CI (Bootstrap)', zorder=1)\n",
    "\n",
    "# Plot median bootstrap pareto front\n",
    "ax.plot(circuit_score_grid, median_bias, \n",
    "        color='grey', lw=2, ls='--', label='Median Bootstrap', zorder=5)\n",
    "\n",
    "# Plot main SPARK samples in color\n",
    "spark_samples = ['ASD_SPARK_Main', 'ASD_SPARK_61']\n",
    "colors_spark = ['#542788', '#d95f02']\n",
    "for i, spark_id in enumerate(spark_samples):\n",
    "    if spark_id in combined_pareto_df['boot_id'].values:\n",
    "        spark_data = combined_pareto_df[combined_pareto_df['boot_id'] == spark_id]\n",
    "        spark_data = spark_data.sort_values('circuit_score')\n",
    "        ax.plot(spark_data['circuit_score'], spark_data['mean_bias'], \n",
    "                marker='o', markersize=6, lw=2, \n",
    "                label=spark_id, color=colors_spark[i], zorder=10)\n",
    "\n",
    "ax.set_xlabel(\"Circuit Connectivity Score\", fontsize=12)\n",
    "ax.set_ylabel(\"Average Mutation Bias\", fontsize=12)\n",
    "ax.set_title(\"Bootstrap Pareto Fronts with 95% CI\", fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Computed 95% CI from {len(interpolated_bias_values)} bootstrap samples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative plot: Show individual bootstrap lines WITH 95% CI\n",
    "fig, ax = plt.subplots(dpi=120, figsize=(8, 6))\n",
    "\n",
    "# Plot individual bootstrap samples as gray lines with low alpha\n",
    "for boot_id in boot_samples_in_data[:100]:  # Show subset to avoid overcrowding\n",
    "    boot_data = combined_pareto_df[combined_pareto_df['boot_id'] == boot_id]\n",
    "    boot_data = boot_data.sort_values('circuit_score')\n",
    "    ax.plot(boot_data['circuit_score'], boot_data['mean_bias'], \n",
    "            color='grey', lw=0.5, alpha=0.15, zorder=1)\n",
    "\n",
    "# Plot 95% CI as shaded region (on top of individual lines)\n",
    "ax.fill_between(circuit_score_grid, lower_ci, upper_ci, \n",
    "                color='lightblue', alpha=0.5, label='95% CI (Bootstrap)', zorder=5)\n",
    "\n",
    "# Plot median bootstrap pareto front\n",
    "ax.plot(circuit_score_grid, median_bias, \n",
    "        color='navy', lw=2.5, ls='-', label='Median Bootstrap', zorder=8)\n",
    "\n",
    "# Plot main SPARK samples in color\n",
    "for i, spark_id in enumerate(spark_samples):\n",
    "    if spark_id in combined_pareto_df['boot_id'].values:\n",
    "        spark_data = combined_pareto_df[combined_pareto_df['boot_id'] == spark_id]\n",
    "        spark_data = spark_data.sort_values('circuit_score')\n",
    "        ax.plot(spark_data['circuit_score'], spark_data['mean_bias'], \n",
    "                marker='o', markersize=6, lw=2.5, \n",
    "                label=spark_id, color=colors_spark[i], zorder=10)\n",
    "\n",
    "ax.set_xlabel(\"Circuit Connectivity Score\", fontsize=12)\n",
    "ax.set_ylabel(\"Average Mutation Bias\", fontsize=12)\n",
    "ax.set_title(\"Bootstrap Pareto Fronts: Individual Lines + 95% CI\", fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined pareto front data to a summary file\n",
    "summary_dir = \"../results/CircuitSearch_Bootstrap_Summary/\"\n",
    "os.makedirs(summary_dir, exist_ok=True)\n",
    "\n",
    "output_file = summary_dir + \"all_pareto_fronts_size_46_combined.csv\"\n",
    "combined_pareto_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved combined pareto front data to: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pareto_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 46\n",
    "\n",
    "# biaslim_df = pd.read_csv(\n",
    "#     \"../dat/Circuits/SA/biaslims2/biaslim.size.46.top17.txt\", names=[\"size\", \"bias\"])\n",
    "\n",
    "SIB_SA_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Circuits/SA/SubSib_Score_SI_Nov27_2023/\"\n",
    "SIB_BIAS_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Unionize_bias/SubSampleSib/\"\n",
    "\n",
    "dat_score = []\n",
    "dat_bias = []\n",
    "\n",
    "for i, file in enumerate(os.listdir(SIB_SA_DIR)):\n",
    "    #try:\n",
    "    d = os.path.join(SIB_SA_DIR, file)\n",
    "    if os.path.isdir(d):\n",
    "        biasdf = SIB_BIAS_DIR + file + \".csv\"\n",
    "        Sib_BiasDF = pd.read_csv(biasdf, index_col=\"STR\")\n",
    "        try:\n",
    "            ASD_cont_Dir = SIB_SA_DIR + file + \"/\"\n",
    "            COHES55, CutBias55, RealBias55, STRS55 = XXXX_cont(Sib_BiasDF, ASD_BiasDF, Selected_BiasLim, size, \n",
    "                                                          ASD_cont_Dir, adj_mat, InfoMat)\n",
    "            dat_score.append(COHES55)\n",
    "            dat_bias.append(RealBias55)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_score = np.array(dat_score)\n",
    "dat_score_flat = dat_score.flatten()\n",
    "dat_bias = np.array(dat_bias)\n",
    "dat_bias_flat = dat_bias.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sib_DF55 = pd.DataFrame(data={\"SI score\":dat_score_flat, \"Bias\":dat_bias_flat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = []\n",
    "for bias, score in zip(dat_bias, dat_score):\n",
    "    meanbias = np.mean(bias)\n",
    "    meanscore = np.mean(score)\n",
    "    meantotal = meanbias + meanscore\n",
    "    profiles.append([meanbias, meanscore, meantotal, bias, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_bias = sorted(profiles, key = lambda x:x[0], reverse=True)\n",
    "rank_score = sorted(profiles, key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topbias = []\n",
    "for i in range(len(profiles)):\n",
    "    topbias.append((rank_bias[i][4], rank_bias[i][3]))\n",
    "topbias = np.array(topbias)\n",
    "topSI = []\n",
    "for i in range(len(profiles)):\n",
    "    topSI.append((rank_score[i][4], rank_score[i][3]))\n",
    "topSI = np.array(topSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanbias = []\n",
    "meanSI = []\n",
    "xerr = []\n",
    "yerr = []\n",
    "for i in range(topbias.shape[2]):\n",
    "    meanbias.append(np.nanmean(topbias[:,1,i]))\n",
    "    meanSI.append(np.nanmean(topbias[:,0,i]))\n",
    "    xerr.append(topbias[:,0,i].std())\n",
    "    yerr.append(topbias[:,1,i].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_indexes = np.random.randint(0, topbias.shape[0], 1000)\n",
    "topbias_sub = topbias[rand_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=480, figsize=(4.2,4))\n",
    "\n",
    "ax.plot(ASD_DFPeak[\"Cohe\"].values, ASD_DFPeak[\"Bias\"].values, marker=\".\", color=\"#542788\",  lw=2, markersize=8,\n",
    "             ls = \"-\", label=\"ASD\")\n",
    "ax.scatter(ASD_DFPeak[\"Cohe\"].values[-4], ASD_DFPeak[\"Bias\"].values[-4], marker=\"x\", s=70, color=\"red\", lw=2,\n",
    "           zorder=100)\n",
    "# Plot 95% CI as shaded region (on top of individual lines)\n",
    "ax.fill_between(circuit_score_grid, lower_ci, upper_ci, \n",
    "                color='lightblue', alpha=0.5, label='95% CI (Bootstrap)', zorder=5)\n",
    "\n",
    "ax.plot(topbias_sub[:,0,:].T, topbias_sub[:,1,:].T, color=\"grey\", markersize=1, lw=0.5,\n",
    "             ls = \"-\", alpha=0.05)\n",
    "#ax.plot(topbias_sub[0,0,:].T, topbias_sub[0,1,:].T, color=\"grey\", markersize=1, lw=1,\n",
    "#             ls = \"-\", alpha=1, label=\"Sibling Circuit\")\n",
    "\n",
    "ax.plot(meanSI, meanbias, marker=\".\", color=\"Orange\", lw=2, markersize=8,\n",
    "             ls = \"-\", alpha=1, label=\"Average Sibling Circuit\")\n",
    "ax.plot(meanSI, meanbias, color=\"grey\", lw=2, markersize=8,\n",
    "             ls = \"-\", alpha=1, label=\"Sibling Circuit\", zorder=0)\n",
    "\n",
    "# Draw the label ON TOP OF ALL LAYERS by setting high zorder\n",
    "ax.text(\n",
    "    ASD_DFPeak[\"Cohe\"].values[-4],\n",
    "    0.01 + ASD_DFPeak[\"Bias\"].values[-4],\n",
    "    s=\"Selected\\n Circuit\",\n",
    "    zorder=1000,  # greater than any other element\n",
    "    fontsize=12,\n",
    "    ha='left'\n",
    ")\n",
    "\n",
    "#box = ax.get_position()\n",
    "#ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "#ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.9))\n",
    "ax.legend(loc=\"lower left\", frameon=False)\n",
    "\n",
    "plt.xlabel(\"Circuit Connectivity Score\", fontsize=14)\n",
    "plt.ylabel(\"Average Mutation Bias\", fontsize=14)\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.ylim(0.00, 0.44)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Pareto_45 = pd.read_csv(\"/home/jw3514/Work/ASD_Circuits_CellType/results/CircuitSearch/ASD_SPARK_61/pareto_fronts/ASD_SPARK_61_size_45_pareto_front.csv\")\n",
    "ASD_Pareto_45 = ASD_Pareto_45.sort_values('mean_bias', ascending=False).reset_index(drop=True)\n",
    "ASD_Pareto_45.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot main SPARK samples in color\n",
    "fig, ax = plt.subplots(dpi=120, figsize=(8, 6))\n",
    "ax.plot(ASD_Pareto_45['circuit_score'], ASD_Pareto_45['mean_bias'], \n",
    "        marker='o', markersize=6, lw=2, \n",
    "        label=spark_id, color=colors_spark[i], zorder=10)\n",
    "\n",
    "ax.set_xlabel(\"Circuit Connectivity Score\", fontsize=12)\n",
    "ax.set_ylabel(\"Average Mutation Bias\", fontsize=12)\n",
    "ax.set_title(\"Bootstrap vs Main SPARK Pareto Fronts\", fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ASD_Pareto_45.loc[3, \"mean_bias\"], ASD_Pareto_45.loc[3, \"circuit_score\"])\n",
    "print(RegionDistributionsList(ASD_Pareto_45.loc[3, \"structures\"].split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the selected circuits\n",
    "print(RegionDistributionsList(STRSPeak[-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Pareto_41 = pd.read_csv(\"/home/jw3514/Work/ASD_Circuits_CellType/results/CircuitSearch/ASD_SPARK_61/pareto_fronts/ASD_SPARK_61_size_41_pareto_front.csv\")\n",
    "ASD_Pareto_41 = ASD_Pareto_41.sort_values('mean_bias', ascending=False).reset_index(drop=True)\n",
    "ASD_Pareto_41.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot main SPARK samples in color\n",
    "fig, ax = plt.subplots(dpi=120, figsize=(8, 6))\n",
    "ax.plot(ASD_Pareto_41['circuit_score'], ASD_Pareto_41['mean_bias'], \n",
    "        marker='o', markersize=6, lw=2, \n",
    "        label=spark_id, color=colors_spark[i], zorder=10)\n",
    "\n",
    "ax.set_xlabel(\"Circuit Connectivity Score\", fontsize=12)\n",
    "ax.set_ylabel(\"Average Mutation Bias\", fontsize=12)\n",
    "ax.set_title(\"Bootstrap vs Main SPARK Pareto Fronts\", fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RegionDistributionsList(ASD_Pareto_41.loc[2, \"structures\"].split(\",\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Overlap Analysis: Selected vs Bootstrap Circuits\n",
    "\n",
    "This section compares structure overlap between:\n",
    "1. The selected circuit (3rd point on main pareto front)\n",
    "2. Each bootstrap circuit (3rd point on each bootstrap pareto front)\n",
    "\n",
    "Also analyzes how frequently the top 10 structures (by bias) from the main circuit appear in bootstrap circuits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected circuit structures (3rd point from end, which is index -3)\n",
    "selected_circuit_structures = set(STRSPeak[-3])\n",
    "print(f\"Selected circuit has {len(selected_circuit_structures)} structures\")\n",
    "print(f\"Selected circuit structures: {sorted(selected_circuit_structures)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 3rd point (index 2) from each bootstrap pareto front\n",
    "# Sort each bootstrap's pareto front by mean_bias descending to match the main circuit ordering\n",
    "bootstrap_3rd_point_structures = []\n",
    "bootstrap_3rd_point_data = []\n",
    "\n",
    "boot_ids = combined_pareto_df['boot_id'].unique()\n",
    "boot_ids = [bid for bid in boot_ids if bid.startswith('ASD_Boot')]  # Filter to bootstrap samples only\n",
    "boot_ids.sort()\n",
    "\n",
    "for boot_id in boot_ids:\n",
    "    boot_data = combined_pareto_df[combined_pareto_df['boot_id'] == boot_id].copy()\n",
    "    # Sort by mean_bias descending (highest bias first, matching main circuit order)\n",
    "    boot_data = boot_data.sort_values('mean_bias', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    if len(boot_data) >= 3:  # Make sure we have at least 3 points\n",
    "        # Get the 3rd point (index 2, 0-indexed)\n",
    "        third_point = boot_data.iloc[2]\n",
    "        structures_str = third_point['structures']\n",
    "        structures_set = set(structures_str.split(','))\n",
    "        \n",
    "        bootstrap_3rd_point_structures.append(structures_set)\n",
    "        bootstrap_3rd_point_data.append({\n",
    "            'boot_id': boot_id,\n",
    "            'structures': structures_set,\n",
    "            'mean_bias': third_point['mean_bias'],\n",
    "            'circuit_score': third_point['circuit_score']\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Warning: {boot_id} has only {len(boot_data)} points, skipping\")\n",
    "\n",
    "print(f\"Extracted 3rd point from {len(bootstrap_3rd_point_structures)} bootstrap samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate structure overlap between selected circuit and each bootstrap's 3rd point\n",
    "overlap_scores = []\n",
    "overlap_details = []\n",
    "\n",
    "for i, boot_structures in enumerate(bootstrap_3rd_point_structures):\n",
    "    # Calculate Jaccard similarity (intersection over union)\n",
    "    intersection = selected_circuit_structures.intersection(boot_structures)\n",
    "    union = selected_circuit_structures.union(boot_structures)\n",
    "    jaccard = len(intersection) / len(union) if len(union) > 0 else 0\n",
    "    \n",
    "    # Calculate overlap percentage (intersection over selected circuit size)\n",
    "    overlap_pct = len(intersection) / len(selected_circuit_structures) if len(selected_circuit_structures) > 0 else 0\n",
    "    \n",
    "    overlap_scores.append({\n",
    "        'boot_id': bootstrap_3rd_point_data[i]['boot_id'],\n",
    "        'jaccard_similarity': jaccard,\n",
    "        'overlap_percentage': overlap_pct,\n",
    "        'n_intersection': len(intersection),\n",
    "        'n_selected': len(selected_circuit_structures),\n",
    "        'n_bootstrap': len(boot_structures)\n",
    "    })\n",
    "    \n",
    "    overlap_details.append({\n",
    "        'boot_id': bootstrap_3rd_point_data[i]['boot_id'],\n",
    "        'intersection': intersection,\n",
    "        'only_in_selected': selected_circuit_structures - boot_structures,\n",
    "        'only_in_bootstrap': boot_structures - selected_circuit_structures\n",
    "    })\n",
    "\n",
    "overlap_df = pd.DataFrame(overlap_scores)\n",
    "print(f\"Overlap statistics:\")\n",
    "print(f\"  Mean Jaccard similarity: {overlap_df['jaccard_similarity'].mean():.4f}\")\n",
    "print(f\"  Mean overlap percentage: {overlap_df['overlap_percentage'].mean():.4f}\")\n",
    "print(f\"  Mean intersection size: {overlap_df['n_intersection'].mean():.2f}\")\n",
    "print(f\"\\nOverlap distribution:\")\n",
    "print(overlap_df[['jaccard_similarity', 'overlap_percentage', 'n_intersection']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize number of structures overlap\n",
    "fig, ax = plt.subplots(dpi=120, figsize=(8, 5))\n",
    "\n",
    "# Histogram of number of overlapping structures\n",
    "mean_intersection = overlap_df['n_intersection'].mean()\n",
    "ax.hist(overlap_df['n_intersection'], bins=30, edgecolor='black', alpha=0.7, color='#542788')\n",
    "ax.axvline(mean_intersection, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_intersection:.1f}')\n",
    "ax.set_xlabel('Number of Overlapping Structures', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "#ax.set_title('Structure Overlap: Number of Overlapping Structures', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean number of overlapping structures: {mean_intersection:.2f}\")\n",
    "print(f\"Min: {overlap_df['n_intersection'].min()}, Max: {overlap_df['n_intersection'].max()}\")\n",
    "print(f\"Median: {overlap_df['n_intersection'].median():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize overlap distribution\n",
    "fig, axes = plt.subplots(1, 2, dpi=120, figsize=(12, 5))\n",
    "\n",
    "# Histogram of Jaccard similarity\n",
    "axes[0].hist(overlap_df['jaccard_similarity'], bins=30, edgecolor='black', alpha=0.7, color='#542788')\n",
    "axes[0].axvline(overlap_df['jaccard_similarity'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {overlap_df[\"jaccard_similarity\"].mean():.3f}')\n",
    "axes[0].set_xlabel('Jaccard Similarity', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Structure Overlap: Jaccard Similarity', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of overlap percentage\n",
    "axes[1].hist(overlap_df['overlap_percentage'], bins=30, edgecolor='black', alpha=0.7, color='#542788')\n",
    "axes[1].axvline(overlap_df['overlap_percentage'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {overlap_df[\"overlap_percentage\"].mean():.3f}')\n",
    "axes[1].set_xlabel('Overlap Percentage', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Structure Overlap: Percentage of Selected Circuit', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 2: Top 20 structures by bias in main circuit\n",
    "# Get top 20 structures from the SELECTED CIRCUIT, sorted by bias value\n",
    "selected_circuit_structures_list = list(STRSPeak[-3])\n",
    "# Get bias values for structures in the selected circuit\n",
    "selected_circuit_bias = [(struct, Spark_ASD_STR_Bias.loc[struct, 'EFFECT']) for struct in selected_circuit_structures_list]\n",
    "# Sort by bias descending\n",
    "selected_circuit_bias_sorted = sorted(selected_circuit_bias, key=lambda x: x[1], reverse=True)\n",
    "# Get top 20 structures from selected circuit by bias\n",
    "top20_structures_by_bias = [struct for struct, bias in selected_circuit_bias_sorted[:20]]\n",
    "top20_structures_by_bias_set = set(top20_structures_by_bias)\n",
    "\n",
    "print(f\"Top 20 structures by bias in the selected circuit:\")\n",
    "for i, (struct, bias) in enumerate(selected_circuit_bias_sorted[:20], 1):\n",
    "    print(f\"  {i}. {struct} (bias: {bias:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many bootstrap circuits include each of the top 20 structures\n",
    "top20_presence = {struct: [] for struct in top20_structures_by_bias_set}\n",
    "\n",
    "for boot_structures in bootstrap_3rd_point_structures:\n",
    "    for struct in top20_structures_by_bias_set:\n",
    "        top20_presence[struct].append(1 if struct in boot_structures else 0)\n",
    "\n",
    "# Calculate frequency for each structure\n",
    "top20_frequency = {}\n",
    "for struct in top20_structures_by_bias_set:\n",
    "    presence_array = np.array(top20_presence[struct])\n",
    "    frequency = presence_array.mean()\n",
    "    top20_frequency[struct] = frequency\n",
    "    print(f\"{struct}: {frequency*100:.1f}% ({presence_array.sum()}/{len(presence_array)} bootstrap circuits)\")\n",
    "\n",
    "# Overall: how many bootstrap circuits include ALL top 20 structures?\n",
    "n_bootstraps_with_all_top20 = 0\n",
    "for boot_structures in bootstrap_3rd_point_structures:\n",
    "    if top20_structures_by_bias_set.issubset(boot_structures):\n",
    "        n_bootstraps_with_all_top20 += 1\n",
    "\n",
    "pct_with_all_top20 = n_bootstraps_with_all_top20 / len(bootstrap_3rd_point_structures) * 100\n",
    "print(f\"\\nBootstrap circuits that include ALL top 20 structures: {n_bootstraps_with_all_top20}/{len(bootstrap_3rd_point_structures)} ({pct_with_all_top20:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraction of Bootstrap Circuits with All Top 10 Structures Together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what fraction of bootstrap circuits contain ALL top 10 structures together\n",
    "n_bootstraps_with_all_top10_together = 0\n",
    "bootstraps_with_all_top10 = []\n",
    "bootstraps_missing_some_top10 = []\n",
    "\n",
    "for i, boot_structures in enumerate(bootstrap_3rd_point_structures):\n",
    "    if top10_structures_by_bias_set.issubset(boot_structures):\n",
    "        n_bootstraps_with_all_top10_together += 1\n",
    "        bootstraps_with_all_top10.append(bootstrap_3rd_point_data[i]['boot_id'])\n",
    "    else:\n",
    "        missing = top10_structures_by_bias_set - boot_structures\n",
    "        bootstraps_missing_some_top10.append({\n",
    "            'boot_id': bootstrap_3rd_point_data[i]['boot_id'],\n",
    "            'missing_structures': missing,\n",
    "            'n_missing': len(missing)\n",
    "        })\n",
    "\n",
    "total_bootstraps = len(bootstrap_3rd_point_structures)\n",
    "fraction_with_all_top10 = n_bootstraps_with_all_top10_together / total_bootstraps\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FRACTION OF BOOTSTRAP CIRCUITS WITH ALL TOP 10 STRUCTURES TOGETHER\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTop 10 structures (by bias) in selected circuit:\")\n",
    "for i, struct in enumerate(top10_structures_by_bias, 1):\n",
    "    print(f\"  {i}. {struct}\")\n",
    "\n",
    "print(f\"\\n Results:\")\n",
    "print(f\"  Bootstrap circuits with ALL top 10 structures: {n_bootstraps_with_all_top10_together}/{total_bootstraps}\")\n",
    "print(f\"  Fraction: {fraction_with_all_top10:.4f} ({fraction_with_all_top10*100:.2f}%)\")\n",
    "print(f\"  Bootstrap circuits missing at least one top 10 structure: {total_bootstraps - n_bootstraps_with_all_top10_together}/{total_bootstraps}\")\n",
    "\n",
    "# Show which structures are most commonly missing\n",
    "if bootstraps_missing_some_top10:\n",
    "    missing_counts = {struct: 0 for struct in top10_structures_by_bias_set}\n",
    "    for entry in bootstraps_missing_some_top10:\n",
    "        for struct in entry['missing_structures']:\n",
    "            if struct in missing_counts:\n",
    "                missing_counts[struct] += 1\n",
    "    \n",
    "    print(f\"\\n Most commonly missing structures:\")\n",
    "    missing_sorted = sorted(missing_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    for struct, count in missing_sorted:\n",
    "        if count > 0:\n",
    "            pct_missing = count / total_bootstraps * 100\n",
    "            print(f\"  - {struct}: missing in {count}/{total_bootstraps} ({pct_missing:.1f}%) bootstrap circuits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fraction of bootstrap circuits with all top 10 structures\n",
    "fig, ax = plt.subplots(dpi=120, figsize=(8, 6))\n",
    "\n",
    "# Create pie chart\n",
    "labels = ['Has all top 10', 'Missing some top 10']\n",
    "sizes = [n_bootstraps_with_all_top10_together, total_bootstraps - n_bootstraps_with_all_top10_together]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "explode = (0.05, 0)  # explode the first slice\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=90, textprops={'fontsize': 12})\n",
    "\n",
    "# Add count labels\n",
    "for i, (wedge, autotext) in enumerate(zip(wedges, autotexts)):\n",
    "    autotext.set_text(f'{sizes[i]}/{total_bootstraps}\\n({autotext.get_text()})')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(11)\n",
    "\n",
    "ax.set_title(f'Fraction of Bootstrap Circuits with All Top 10 Structures\\n(Total: {total_bootstraps} bootstrap circuits)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also create a bar chart showing the breakdown\n",
    "fig, ax = plt.subplots(dpi=120, figsize=(10, 6))\n",
    "\n",
    "categories = ['Has all top 10\\nstructures', 'Missing some top 10\\nstructures']\n",
    "counts = [n_bootstraps_with_all_top10_together, total_bootstraps - n_bootstraps_with_all_top10_together]\n",
    "bar_colors = ['#2ecc71', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(categories, counts, color=bar_colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{count}\\n({count/total_bootstraps*100:.1f}%)',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Number of Bootstrap Circuits', fontsize=12)\n",
    "ax.set_title('Bootstrap Circuits: Presence of All Top 10 Structures Together', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, max(counts) * 1.15)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 90% of bootstrap circuits include the top 10 structures\n",
    "# Count how many of the top 10 structures appear in at least 90% of bootstrap circuits\n",
    "structures_in_90pct = []\n",
    "for struct in top10_structures_by_bias_set:\n",
    "    frequency = top10_frequency[struct]\n",
    "    if frequency >= 0.90:\n",
    "        structures_in_90pct.append(struct)\n",
    "        print(f\" {struct}: {frequency*100:.1f}% (meets 90% threshold)\")\n",
    "    else:\n",
    "        print(f\" {struct}: {frequency*100:.1f}% (below 90% threshold)\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Structures appearing in 90% of bootstrap circuits: {len(structures_in_90pct)}/10\")\n",
    "print(f\"  Structures appearing in <90% of bootstrap circuits: {10 - len(structures_in_90pct)}/10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced visualization of top 20 structure frequency in bootstrap circuits\n",
    "\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "fig, ax = plt.subplots(dpi=150, figsize=(11, 7))\n",
    "\n",
    "# Use the top20_structures_by_bias that was calculated from the selected circuit (from previous cell)\n",
    "# Make sure top20_structures_by_bias and top20_frequency are available from previous cells\n",
    "structures_list = top20_structures_by_bias  # Keep original order (sorted by bias)\n",
    "# Use top20_frequency which should be calculated in a previous cell\n",
    "frequencies = [top20_frequency.get(s, 0) * 100 for s in structures_list]\n",
    "\n",
    "# Prepare display labels: replace underscores with spaces\n",
    "structures_list_display = [s.replace(\"_\", \" \") for s in structures_list]\n",
    "\n",
    "# Define nice color palette for 20 values (using \"crest\" for background consistency)\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "base_cmap = sns.color_palette(\"crest\", 20).as_hex()\n",
    "color_map = []\n",
    "for f in frequencies:\n",
    "    if f >= 90:\n",
    "        color_map.append(sns.color_palette(\"dark:#17B978\", 15).as_hex()[8])  # green tone\n",
    "    elif f >= 75:\n",
    "        color_map.append(sns.color_palette(\"dark:#FFC300\", 15).as_hex()[8])  # warm yellow/orange\n",
    "    else:\n",
    "        color_map.append(sns.color_palette(\"dark:#FF5733\", 15).as_hex()[8])  # orange/red\n",
    "\n",
    "bars = ax.barh(range(len(structures_list)), frequencies, color=color_map, alpha=0.87, \n",
    "               edgecolor='k', linewidth=1.3, height=0.67,\n",
    "               zorder=10)\n",
    "\n",
    "# Add value labels on the bars, with shadow\n",
    "for i, (bar, freq) in enumerate(zip(bars, frequencies)):\n",
    "    ax.text(freq + 1, bar.get_y() + bar.get_height() / 2, f'{freq:.1f}%',\n",
    "            va='center', ha='left', fontsize=11, weight='bold', color=color_map[i],\n",
    "            path_effects=[pe.withStroke(linewidth=2.7, foreground=\"white\")])\n",
    "\n",
    "# Enhance y-axis\n",
    "ax.set_yticks(range(len(structures_list)))\n",
    "ax.set_yticklabels(structures_list_display, fontsize=11, fontfamily='monospace')\n",
    "ax.invert_yaxis()  # highest bias at top\n",
    "\n",
    "# Titles and axis\n",
    "ax.set_xlabel('Frequency in Bootstrap Circuits (%)', fontsize=13, labelpad=13)\n",
    "#ax.set_title('Top 20 Structures (by Bias):\\nPresence Across Bootstrap Circuits', \n",
    "#             fontsize=17, weight='bold', pad=18)\n",
    "ax.set_xlim(0, 105)\n",
    "\n",
    "# Remove box frame on top/right and prettify spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(1.1)\n",
    "ax.spines['bottom'].set_linewidth(1.1)\n",
    "\n",
    "# Grid and layout\n",
    "ax.grid(True, alpha=0.18, axis='x', linestyle='-', zorder=1, color='#888C')\n",
    "plt.tight_layout(rect=[0, 0, 0.88, 1])  # add right margin for legend, if desired\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics table\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Structure': structures_list,\n",
    "    'Bias_Value': [Spark_ASD_STR_Bias.loc[s, 'EFFECT'] for s in structures_list],\n",
    "    'Frequency_Percent': frequencies,\n",
    "    'In_Selected_Circuit': [s in selected_circuit_structures for s in structures_list],\n",
    "    'Meets_90pct_Threshold': [f >= 90 for f in frequencies]\n",
    "})\n",
    "\n",
    "# Already sorted by bias (descending) from the list creation\n",
    "print(\"Summary Statistics:\")\n",
    "print(summary_stats.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot presence across bootstrap for ALL structures in the selected circuit\n",
    "# Calculate frequency for each structure in the selected circuit\n",
    "all_structures_presence = {struct: [] for struct in selected_circuit_structures}\n",
    "\n",
    "for boot_structures in bootstrap_3rd_point_structures:\n",
    "    for struct in selected_circuit_structures:\n",
    "        all_structures_presence[struct].append(1 if struct in boot_structures else 0)\n",
    "\n",
    "# Calculate frequency for each structure\n",
    "all_structures_frequency = {}\n",
    "all_structures_bias = {}\n",
    "for struct in selected_circuit_structures:\n",
    "    presence_array = np.array(all_structures_presence[struct])\n",
    "    frequency = presence_array.mean()\n",
    "    all_structures_frequency[struct] = frequency\n",
    "    all_structures_bias[struct] = Spark_ASD_STR_Bias.loc[struct, 'EFFECT']\n",
    "\n",
    "# Sort structures by strongest bias (descending) for plotting (strongest = largest EFFECT)\n",
    "all_structures_sorted = sorted(selected_circuit_structures, \n",
    "                               key=lambda x: all_structures_bias[x], \n",
    "                               reverse=True)\n",
    "all_frequencies = [all_structures_frequency[s] * 100 for s in all_structures_sorted]\n",
    "all_bias_values = [all_structures_bias[s] for s in all_structures_sorted]\n",
    "\n",
    "# Prepare yticks to match strongest bias (top) to weakest bias (bottom, highest negative or lowest positive)\n",
    "fig, ax = plt.subplots(dpi=120, figsize=(14, 8))\n",
    "\n",
    "# Color code by frequency: green >=90%, orange >=75%, red <75%\n",
    "colors = ['green' if f >= 90 else 'orange' if f >= 75 else 'red' for f in all_frequencies]\n",
    "bars = ax.barh(range(len(all_structures_sorted)), all_frequencies, \n",
    "               color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "# Add 90% threshold line\n",
    "ax.axvline(90, color='red', linestyle='--', linewidth=2, label='90% threshold', zorder=0)\n",
    "ax.axvline(75, color='orange', linestyle='--', linewidth=1.5, alpha=0.5, label='75% threshold', zorder=0)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, freq) in enumerate(zip(bars, all_frequencies)):\n",
    "    ax.text(freq + 1, i, f'{freq:.1f}%', va='center', fontsize=8)\n",
    "\n",
    "# Set strongest bias on top (reverse yticks order)\n",
    "ax.set_yticks(range(len(all_structures_sorted)))\n",
    "ax.set_yticklabels(all_structures_sorted, fontsize=8)\n",
    "ax.invert_yaxis()  # This puts the strongest biased at the top\n",
    "\n",
    "ax.set_xlabel('Frequency in Bootstrap Circuits (%)', fontsize=12)\n",
    "ax.set_title('All Selected Circuit Structures: Frequency in Bootstrap Circuits', fontsize=14)\n",
    "ax.set_xlim(0, 105)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "n_structures_90pct = sum(1 for f in all_frequencies if f >= 90)\n",
    "n_structures_75pct = sum(1 for f in all_frequencies if f >= 75)\n",
    "print(f\"\\nSummary for all {len(all_structures_sorted)} structures in selected circuit:\")\n",
    "print(f\"  Structures appearing in 90% of bootstrap circuits: {n_structures_90pct}/{len(all_structures_sorted)} ({n_structures_90pct/len(all_structures_sorted)*100:.1f}%)\")\n",
    "print(f\"  Structures appearing in 75% of bootstrap circuits: {n_structures_75pct}/{len(all_structures_sorted)} ({n_structures_75pct/len(all_structures_sorted)*100:.1f}%)\")\n",
    "print(f\"  Structures appearing in <75% of bootstrap circuits: {len(all_structures_sorted)-n_structures_75pct}/{len(all_structures_sorted)} ({(len(all_structures_sorted)-n_structures_75pct)/len(all_structures_sorted)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gencic)",
   "language": "python",
   "name": "gencic"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
