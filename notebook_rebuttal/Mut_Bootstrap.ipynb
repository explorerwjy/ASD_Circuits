{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "ProjDIR = \"/home/jw3514/Work/ASD_Circuits_CellType/\" # Change to your project directory\n",
    "sys.path.insert(1, f'{ProjDIR}/src/')\n",
    "from ASD_Circuits import *\n",
    "\n",
    "try:\n",
    "    os.chdir(f\"{ProjDIR}/notebook_rebuttal/\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not change directory - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "\n",
    "HGNC, ENSID2Entrez, GeneSymbol2Entrez, Entrez2Symbol = LoadGeneINFO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "with open(\"../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "expr_matrix_path = config[\"analysis_types\"][\"STR_ISH\"][\"expr_matrix\"]\n",
    "STR_BiasMat = pd.read_parquet(f\"../{expr_matrix_path}\")\n",
    "Anno = STR2Region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/home/jw3514/Work/data/DDD/41586_2020_2832_MOESM4_ESM.xlsx\")\n",
    "df = df.sort_values(\"denovoWEST_p_full\")\n",
    "hc_df = df[df[\"denovoWEST_p_full\"]<=0.05/18762]\n",
    "entrez_ids = [int(GeneSymbol2Entrez.get(x, -1)) for x in hc_df[\"symbol\"].values]\n",
    "hc_df[\"EntrezID\"] = entrez_ids\n",
    "hc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_df[\"AutismMerged_LoF\"] = (\n",
    "    df.loc[hc_df.index, \"frameshift_variant\"].fillna(0)\n",
    "    + df.loc[hc_df.index, \"splice_acceptor_variant\"].fillna(0)\n",
    "    + df.loc[hc_df.index, \"splice_donor_variant\"].fillna(0)\n",
    "    + df.loc[hc_df.index, \"stop_gained\"].fillna(0)\n",
    "    + df.loc[hc_df.index, \"stop_lost\"].fillna(0)\n",
    ").astype(int).clip(lower=0)\n",
    "\n",
    "hc_df[\"AutismMerged_Dmis_REVEL0.5\"] = df.loc[hc_df.index, \"missense_variant\"].fillna(0).astype(int).clip(lower=0)\n",
    "\n",
    "hc_df = hc_df[[\"EntrezID\", \"symbol\", \"AutismMerged_LoF\", \"AutismMerged_Dmis_REVEL0.5\"]]\n",
    "hc_df = hc_df.set_index(\"EntrezID\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Exclude ASD genes from hc_df before bootstrap\n",
    "ASD_GW = Fil2Dict(ProjDIR+\"dat/Genetics/GeneWeights_DN/Spark_Meta_EWS.GeneWeight.DN.gw\")\n",
    "ASD_GENES = list(ASD_GW.keys())\n",
    "print(f\"Total genes in hc_df before excluding ASD: {len(hc_df)}\")\n",
    "print(f\"Number of ASD genes to exclude: {len(ASD_GENES)}\")\n",
    "\n",
    "# Filter out ASD genes\n",
    "hc_df = hc_df[~hc_df[\"EntrezID\"].isin(ASD_GENES)]\n",
    "print(f\"Total genes in hc_df after excluding ASD: {len(hc_df)}\")\n",
    "print(f\"Excluded {len(ASD_GENES)} ASD genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDD_hc_GW = Aggregate_Gene_Weights_NDD(hc_df, out=\"../dat/GeneWeights/DDD.hc.gw.csv\")\n",
    "# NDD_top61_DF = hc_df.head(61)\n",
    "# DDD_top61_GW = Aggregate_Gene_Weights_NDD(NDD_top61_DF, out=\"../dat/GeneWeights/DDD.top61.gw.csv\")\n",
    "#Dict2Fil(DDD_top61_GW, \"../dat/GeneWeights/DDD.top61.gw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_gene_mutations(\n",
    "    df,\n",
    "    n_boot=10,\n",
    "    weighted=True,\n",
    "    lof_col=\"AutismMerged_LoF\",\n",
    "    dmis_col=\"AutismMerged_Dmis_REVEL0.5\",\n",
    "    rng=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Bootstrap mutation counts at the mutation level, preserving gene identity\n",
    "    and total mutation load. Supports weighted (mutation-rate) or uniform resampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe with gene-level LOF and Dmis mutation counts.\n",
    "    n_boot : int, optional\n",
    "        Number of bootstrap replicates (default = 10).\n",
    "    weighted : bool, optional\n",
    "        If True, mutations are resampled with probability proportional to observed counts.\n",
    "        If False, each gene has equal probability of receiving any mutation.\n",
    "    lof_col, dmis_col : str\n",
    "        Column names for LOF and Dmis counts.\n",
    "    rng : np.random.Generator, optional\n",
    "        Numpy random generator for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boot_DFs : list of pd.DataFrame\n",
    "        List of bootstrapped dataframes with resampled mutation counts and 'bootstrap_iter' column.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "    n = len(df)\n",
    "    boot_DFs = []\n",
    "\n",
    "    # Ensure integer non-negative mutation counts\n",
    "    # lof = (df[\"frameshift_variant\"] + df[\"splice_acceptor_variant\"] + df[\"splice_donor_variant\"] + df[\"stop_gained\"] + df[\"stop_lost\"]).astype(int).clip(lower=0)\n",
    "    # dmis = df[\"missense_variant\"].astype(int).clip(lower=0) \n",
    "\n",
    "    lof = df[lof_col].astype(int).clip(lower=0)\n",
    "    dmis = df[dmis_col].astype(int).clip(lower=0)\n",
    "\n",
    "    total_lof = lof.sum()\n",
    "    total_dmis = dmis.sum()\n",
    "\n",
    "    # Probability vectors for mutation assignment\n",
    "    if weighted:\n",
    "        # Weighted by observed mutation burden per gene\n",
    "        p_lof = lof / total_lof if total_lof > 0 else np.ones(n) / n\n",
    "        p_dmis = dmis / total_dmis if total_dmis > 0 else np.ones(n) / n\n",
    "    else:\n",
    "        # Uniform: every gene equally likely\n",
    "        p_lof = np.ones(n) / n\n",
    "        p_dmis = np.ones(n) / n\n",
    "\n",
    "    for i in range(1, n_boot + 1):\n",
    "        # Draw total_lof mutation events, assign to genes\n",
    "        new_lof_counts = np.bincount(\n",
    "            rng.choice(n, size=total_lof, replace=True, p=p_lof),\n",
    "            minlength=n\n",
    "        )\n",
    "        new_dmis_counts = np.bincount(\n",
    "            rng.choice(n, size=total_dmis, replace=True, p=p_dmis),\n",
    "            minlength=n\n",
    "        )\n",
    "\n",
    "        # Create bootstrap replicate\n",
    "        df_boot = df.copy().reset_index(drop=True)\n",
    "        df_boot[lof_col] = new_lof_counts\n",
    "        df_boot[dmis_col] = new_dmis_counts\n",
    "        df_boot[\"bootstrap_iter\"] = i\n",
    "        df_boot[\"bootstrap_type\"] = \"weighted\" if weighted else \"uniform\"\n",
    "        boot_DFs.append(df_boot)\n",
    "\n",
    "    return boot_DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_DFs_weights = bootstrap_gene_mutations(hc_df, 1000, weighted=True, lof_col=\"AutismMerged_LoF\", dmis_col=\"AutismMerged_Dmis_REVEL0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_DFs_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Aggregate_Gene_Weights_NDD2(MutFil, usepLI=False, Bmis=False, out=None):\n",
    "    gene2MutN = {}\n",
    "    for i, row in MutFil.iterrows():\n",
    "        try:\n",
    "            g = int(row[\"EntrezID\"])\n",
    "        except:\n",
    "            print(g, \"Error converting Entrez ID\")\n",
    "\n",
    "        nLGD = row[\"AutismMerged_LoF\"] \n",
    "        nMis = row[\"AutismMerged_Dmis_REVEL0.5\"] \n",
    "\n",
    "        gene2MutN[g] = nLGD * 0.347 + nMis * 0.194\n",
    "    if out != None:\n",
    "        writer = csv.writer(open(out, 'wt'))\n",
    "        for k,v in sorted(gene2MutN.items(), key=lambda x:x[1], reverse=True):\n",
    "           writer.writerow([k,v]) \n",
    "    return gene2MutN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing as mp\n",
    "\n",
    "def process_bootstrap_iter(args):\n",
    "    \"\"\"Worker function to process a single bootstrap iteration\"\"\"\n",
    "    i, DF, save_dir, str_bias_mat = args\n",
    "    boot_gw = Aggregate_Gene_Weights_NDD2(DF)\n",
    "    boot_bias = MouseSTR_AvgZ_Weighted(str_bias_mat, boot_gw)\n",
    "    boot_bias.to_csv(os.path.join(save_dir, f\"DDD_ExomeWide.GeneWeight.boot{i}.csv\"))\n",
    "    return i, boot_bias\n",
    "\n",
    "save_dir = \"../results/Bootstrap_bias/DDD_ExomeWide/Weighted_Resampling\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Prepare arguments for parallel processing\n",
    "n_workers = mp.cpu_count()  # Use all available CPU cores\n",
    "args_list = [(i, DF, save_dir, STR_BiasMat) for i, DF in enumerate(boot_DFs_weights)]\n",
    "\n",
    "# Process in parallel\n",
    "boot_bias_list_weights = [None] * len(boot_DFs_weights)  # Pre-allocate list to maintain order\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "    # Submit all tasks\n",
    "    future_to_idx = {executor.submit(process_bootstrap_iter, args): args[0] for args in args_list}\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    for future in as_completed(future_to_idx):\n",
    "        i, boot_bias = future.result()\n",
    "        boot_bias_list_weights[i] = boot_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOEUF25 Bootstrap Analysis\n",
    "\n",
    "# Load gnomad4 constraint data and define LOEUF25 gene set\n",
    "gnomad4 = pd.read_csv(\"/home/jw3514/Work/data/gnomad/gnomad.v4.0.constraint_metrics.tsv\", sep=\"\\t\")\n",
    "search_text = 'ENST'\n",
    "gnomad4 = gnomad4[(gnomad4[\"transcript\"].str.contains(search_text))]\n",
    "gnomad4 = gnomad4[gnomad4[\"mane_select\"]==True]\n",
    "\n",
    "# Convert gene symbols to Entrez IDs\n",
    "for i, row in gnomad4.iterrows():\n",
    "    symbol = row[\"gene\"]\n",
    "    gnomad4.loc[i, \"Entrez\"] = int(GeneSymbol2Entrez.get(symbol, 0))\n",
    "\n",
    "# Take subset where lof.oe_ci.upper is in the bottom 25% (most constrained)\n",
    "bottom_25_percent_threshold = gnomad4[\"lof.oe_ci.upper\"].quantile(0.25)\n",
    "gnomad4_bottom25 = gnomad4[gnomad4[\"lof.oe_ci.upper\"] <= bottom_25_percent_threshold]\n",
    "columns_to_keep_g4 = [\"Entrez\", \"gene\", \"lof.pLI\", \"lof.z_score\", \"lof.oe_ci.upper\"]\n",
    "gnomad4_bottom25 = gnomad4_bottom25[columns_to_keep_g4]\n",
    "gnomad4_bottom25 = gnomad4_bottom25.sort_values(by=\"lof.oe_ci.upper\", ascending=True)\n",
    "\n",
    "# Make sure Entrez is int and exclude rows with Entrez = 0\n",
    "gnomad4_bottom25[\"Entrez\"] = gnomad4_bottom25[\"Entrez\"].astype(int)\n",
    "gnomad4_bottom25 = gnomad4_bottom25[gnomad4_bottom25[\"Entrez\"] != 0]\n",
    "\n",
    "# Get LOEUF25 gene list (Entrez IDs)\n",
    "LOEUF25_genes = gnomad4_bottom25[\"Entrez\"].unique().tolist()\n",
    "print(f\"LOEUF25 gene set: {len(LOEUF25_genes)} genes\")\n",
    "print(f\"Bottom 25% threshold: {bottom_25_percent_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_genes_from_set(gene_set, n_boot=1000, n_genes=None, rng=None):\n",
    "    \"\"\"\n",
    "    Bootstrap sample genes from a given gene set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gene_set : list\n",
    "        List of Entrez gene IDs to sample from\n",
    "    n_boot : int\n",
    "        Number of bootstrap replicates\n",
    "    n_genes : int, optional\n",
    "        Number of genes to sample per bootstrap. If None, uses length of gene_set\n",
    "    rng : np.random.Generator, optional\n",
    "        Numpy random generator for reproducibility\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    boot_gene_sets : list of lists\n",
    "        List of bootstrap gene sets, each containing sampled Entrez IDs\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "    \n",
    "    if n_genes is None:\n",
    "        n_genes = len(gene_set)\n",
    "    \n",
    "    gene_set_array = np.array(gene_set)\n",
    "    boot_gene_sets = []\n",
    "    \n",
    "    for i in range(1, n_boot + 1):\n",
    "        # Sample n_genes with replacement from gene_set\n",
    "        boot_genes = rng.choice(gene_set_array, size=n_genes, replace=True)\n",
    "        boot_gene_sets.append(boot_genes.tolist())\n",
    "    \n",
    "    return boot_gene_sets\n",
    "\n",
    "# Bootstrap genes from LOEUF25 gene set\n",
    "print(f\"Bootstrapping {len(LOEUF25_genes)} genes from LOEUF25 gene set...\")\n",
    "LOEUF25_boot_gene_sets = bootstrap_genes_from_set(LOEUF25_genes, n_boot=1000, rng=np.random.default_rng(42))\n",
    "print(f\"Created {len(LOEUF25_boot_gene_sets)} bootstrap replicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "# Process LOEUF25 bootstrap iterations in parallel\n",
    "def process_LOEUF25_bootstrap_iter(args):\n",
    "    \"\"\"Worker function to process a single LOEUF25 bootstrap iteration\"\"\"\n",
    "    i, boot_genes, save_dir, str_bias_mat = args\n",
    "    # Create gene weights dictionary (equal weights of 1)\n",
    "    boot_gw = {gene: 1.0 for gene in boot_genes}\n",
    "    boot_bias = MouseSTR_AvgZ_Weighted(str_bias_mat, boot_gw)\n",
    "    boot_bias.to_csv(os.path.join(save_dir, f\"LOEUF25.GeneWeight.boot{i}.csv\"))\n",
    "    return i, boot_bias\n",
    "\n",
    "save_dir_LOEUF25 = \"../results/Bootstrap_bias/LOEUF25/Weighted_Resampling\"\n",
    "os.makedirs(save_dir_LOEUF25, exist_ok=True)\n",
    "\n",
    "# Prepare arguments for parallel processing\n",
    "n_workers = mp.cpu_count()\n",
    "args_list_LOEUF25 = [(i, boot_genes, save_dir_LOEUF25, STR_BiasMat) \n",
    "                     for i, boot_genes in enumerate(LOEUF25_boot_gene_sets)]\n",
    "\n",
    "# Process in parallel\n",
    "print(f\"Using {n_workers} workers to compute LOEUF25 bootstrap bias...\")\n",
    "LOEUF25_boot_bias_list = [None] * len(LOEUF25_boot_gene_sets)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "    future_to_idx = {executor.submit(process_LOEUF25_bootstrap_iter, args): args[0] \n",
    "                     for args in args_list_LOEUF25}\n",
    "    \n",
    "    completed = 0\n",
    "    for future in as_completed(future_to_idx):\n",
    "        i, boot_bias = future.result()\n",
    "        LOEUF25_boot_bias_list[i] = boot_bias\n",
    "        completed += 1\n",
    "        if completed % 100 == 0:\n",
    "            print(f\"Completed {completed}/{len(LOEUF25_boot_gene_sets)} LOEUF25 bootstrap iterations\")\n",
    "\n",
    "print(f\"Completed all {len(LOEUF25_boot_bias_list)} LOEUF25 bootstrap iterations\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "gencic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
