{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "ProjDIR = \"/home/jw3514/Work/ASD_Circuits_CellType/\" # Change to your project directory\n",
    "sys.path.insert(1, f'{ProjDIR}/src/')\n",
    "from ASD_Circuits import *\n",
    "import scipy.io as sio\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "try:\n",
    "    os.chdir(f\"{ProjDIR}/notebooks_mouse_str/\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not change directory - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "\n",
    "HGNC, ENSID2Entrez, GeneSymbol2Entrez, Entrez2Symbol = LoadGeneINFO()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Mouse fMRI data validation from 16 mouse model figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMRI = pd.read_excel(\"/home/jw3514/Work/FuncConnectome/ASD_Mouse/Clusters_Images/Clusters_Values.xlsx\", index_col=\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMRI.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Correlation between 4 Clusters, and top STR in common\n",
    "# Compute Spearman and Pearson correlation between Cluster1-4\n",
    "cluster_cols = ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']\n",
    "cluster_data = FMRI[cluster_cols]\n",
    "\n",
    "# Calculate Spearman and Pearson correlation matrices\n",
    "spearman_corr = cluster_data.corr(method='spearman')\n",
    "pearson_corr = cluster_data.corr(method='pearson')\n",
    "\n",
    "# Import matplotlib with explicit backend setting to avoid backend_bases error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create subplots for both correlation matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Spearman correlation heatmap\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, ax=ax1)\n",
    "ax1.set_title('Spearman Correlation between Clusters 1-4')\n",
    "\n",
    "# Pearson correlation heatmap\n",
    "sns.heatmap(pearson_corr, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, ax=ax2)\n",
    "ax2.set_title('Pearson Correlation between Clusters 1-4')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the correlation matrices\n",
    "print(\"Spearman Correlation Matrix:\")\n",
    "print(spearman_corr.round(3))\n",
    "print(\"\\nPearson Correlation Matrix:\")\n",
    "print(pearson_corr.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC = pd.read_excel(\"/home/jw3514/Work/ASD_Circuits_CellType/results/SupTabs.v57.xlsx\", sheet_name=\"Table-S1- Structure Bias\", index_col=0)\n",
    "# Need Annotate Name \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABA_Ontology = pd.read_csv(\"/home/jw3514/Work/ASD_Circuits/dat/Other/ontology.csv\", index_col = \"KEY\")\n",
    "ABA_Ontology.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _str, row in GENCIC.iterrows():\n",
    "    if _str in ABA_Ontology.index:\n",
    "        GENCIC.loc[_str, \"acronym\"] = ABA_Ontology.loc[_str, \"acronym\"]\n",
    "    else:\n",
    "        print(f\"{_str} not in ABA_Ontology\")\n",
    "GENCIC[\"Structure\"] = GENCIC.index\n",
    "GENCIC = GENCIC.set_index(\"acronym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "for cluster in ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']:\n",
    "    # Get common acronyms between GENCIC and FMRI data\n",
    "    common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "    \n",
    "    if len(common_acronyms) > 0:\n",
    "        # Extract values for common acronyms\n",
    "        gencic_bias = GENCIC.loc[common_acronyms, 'Bias']\n",
    "        fmri_cluster = FMRI.loc[common_acronyms, cluster]\n",
    "        \n",
    "        # Calculate Spearman correlation\n",
    "        spearman_correlation, spearman_p_value = spearmanr(gencic_bias, fmri_cluster)\n",
    "        \n",
    "        # Calculate Pearson correlation\n",
    "        pearson_correlation, pearson_p_value = pearsonr(gencic_bias, fmri_cluster)\n",
    "        \n",
    "        print(f\"{cluster}:\")\n",
    "        print(f\"  Number of common regions: {len(common_acronyms)}\")\n",
    "        print(f\"  Spearman correlation: {spearman_correlation:.4f} (p = {spearman_p_value:.4f})\")\n",
    "        print(f\"  Pearson correlation: {pearson_correlation:.4f} (p = {pearson_p_value:.4f})\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{cluster}: No common acronyms found between GENCIC and FMRI data\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "\n",
    "topN = 50\n",
    "\n",
    "for cluster in ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']:\n",
    "    # Get common acronyms between GENCIC and FMRI data\n",
    "    common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "    \n",
    "    if len(common_acronyms) > 0:\n",
    "        # Get top N structures from GENCIC (highest Bias values)\n",
    "        gencic_topN = GENCIC.loc[common_acronyms].nlargest(topN, 'Bias').index\n",
    "        \n",
    "        # Get top N structures from fMRI cluster (highest values)\n",
    "        fmri_topN_largest = FMRI.loc[common_acronyms].nlargest(topN, cluster).index\n",
    "        \n",
    "        # Get top N structures from fMRI cluster (lowest values)\n",
    "        fmri_topN_smallest = FMRI.loc[common_acronyms].nsmallest(topN, cluster).index\n",
    "        \n",
    "        # Calculate overlap between GENCIC top N and fMRI top N (largest)\n",
    "        overlap_largest = len(set(gencic_topN).intersection(set(fmri_topN_largest)))\n",
    "        \n",
    "        # Calculate overlap between GENCIC top N and fMRI top N (smallest)\n",
    "        overlap_smallest = len(set(gencic_topN).intersection(set(fmri_topN_smallest)))\n",
    "        \n",
    "        # Calculate p-values using hypergeometric test\n",
    "        # For largest values\n",
    "        # Population size: total common regions\n",
    "        # Successes in population: fMRI top N largest\n",
    "        # Sample size: GENCIC top N\n",
    "        # Observed successes: overlap_largest\n",
    "        pval_largest = hypergeom.sf(overlap_largest - 1, len(common_acronyms), topN, topN)\n",
    "        \n",
    "        # For smallest values\n",
    "        pval_smallest = hypergeom.sf(overlap_smallest - 1, len(common_acronyms), topN, topN)\n",
    "        \n",
    "        print(f\"{cluster}:\")\n",
    "        print(f\"  Number of common regions: {len(common_acronyms)}\")\n",
    "        print(f\"  GENCIC top {topN} overlap with fMRI top {topN} (largest): {overlap_largest} (p = {pval_largest:.4f})\")\n",
    "        print(f\"  GENCIC top {topN} overlap with fMRI top {topN} (smallest): {overlap_smallest} (p = {pval_smallest:.4f})\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{cluster}: No common acronyms found between GENCIC and FMRI data\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add average and count columns to FMRI dataframe\n",
    "FMRI['Average_Clusters'] = FMRI[['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']].mean(axis=1)\n",
    "FMRI.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4', 'Average_Clusters']:\n",
    "    # Get common acronyms between GENCIC and FMRI data\n",
    "    common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "    \n",
    "    if len(common_acronyms) > 0:\n",
    "        # Extract values for common acronyms\n",
    "        gencic_bias = GENCIC.loc[common_acronyms, 'Bias']\n",
    "        fmri_cluster = FMRI.loc[common_acronyms, cluster]\n",
    "        \n",
    "        # Calculate Spearman correlation\n",
    "        correlation, p_value = spearmanr(gencic_bias, fmri_cluster)\n",
    "        \n",
    "        print(f\"{cluster}:\")\n",
    "        print(f\"  Number of common regions: {len(common_acronyms)}\")\n",
    "        print(f\"  Spearman correlation: {correlation:.4f}\")\n",
    "        print(f\"  P-value: {p_value:.8f}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{cluster}: No common acronyms found between GENCIC and FMRI data\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get common acronyms between GENCIC and FMRI data\n",
    "common_acronyms = GENCIC.index.intersection(FMRI.index)\n",
    "\n",
    "if len(common_acronyms) > 0:\n",
    "    # Extract values for common acronyms\n",
    "    gencic_bias = GENCIC.loc[common_acronyms, 'Bias']\n",
    "    fmri_average_clusters = FMRI.loc[common_acronyms, 'Average_Clusters']\n",
    "    \n",
    "    # Calculate Spearman correlation\n",
    "    spearman_correlation, spearman_p_value = spearmanr(gencic_bias, fmri_average_clusters)\n",
    "    \n",
    "    # Calculate Pearson correlation\n",
    "    pearson_correlation, pearson_p_value = pearsonr(gencic_bias, fmri_average_clusters)\n",
    "    \n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(gencic_bias, fmri_average_clusters, alpha=0.6, s=50)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(gencic_bias, fmri_average_clusters, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(gencic_bias, p(gencic_bias), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('GENCIC Bias')\n",
    "    plt.ylabel('fMRI Average Clusters')\n",
    "    plt.title(f'GENCIC Bias vs fMRI Average Clusters\\nSpearman r = {spearman_correlation:.4f}, p = {spearman_p_value:.4f}\\nPearson r = {pearson_correlation:.4f}, p = {pearson_p_value:.4f}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Number of common regions: {len(common_acronyms)}\")\n",
    "    print(f\"Spearman correlation: {spearman_correlation:.4f}\")\n",
    "    print(f\"Spearman P-value: {spearman_p_value:.8f}\")\n",
    "    print(f\"Pearson correlation: {pearson_correlation:.4f}\")\n",
    "    print(f\"Pearson P-value: {pearson_p_value:.8f}\")\n",
    "else:\n",
    "    print(\"No common acronyms found between GENCIC and FMRI data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cut = 0\n",
    "FMRI['Count_Below_Threshold'] = (FMRI[['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']] < Cut).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new 'Area' column based on SubArea if valid, otherwise MacroArea\n",
    "FMRI['Area'] = FMRI['SubArea'].where(FMRI['SubArea'].notna() & (FMRI['SubArea'] != ''), FMRI['MacroArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMRI[FMRI[\"Count_Below_Threshold\"]>=3].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Count_Below_Threshold at MacroArea level\n",
    "macro_area_aggregation = FMRI.groupby('Area')['Count_Below_Threshold'].agg(['mean', 'std', 'count']).reset_index()\n",
    "\n",
    "# Calculate total counts for each cluster below threshold by MacroArea\n",
    "cluster_counts = FMRI.groupby('Area')[['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']].apply(lambda x: (x < Cut).sum()).reset_index()\n",
    "\n",
    "# Create a stacked bar plot showing total counts for each cluster\n",
    "plt.figure(figsize=(12, 6))\n",
    "width = 0.6\n",
    "x = range(len(cluster_counts))\n",
    "\n",
    "# Define colors for each cluster\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Blue, Orange, Green, Red\n",
    "\n",
    "# Create stacked bars\n",
    "bottom = [0] * len(cluster_counts)\n",
    "for i, cluster in enumerate(['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']):\n",
    "    plt.bar(x, cluster_counts[cluster], width, bottom=bottom, \n",
    "            label=cluster, color=colors[i], alpha=0.8)\n",
    "    bottom = [b + c for b, c in zip(bottom, cluster_counts[cluster])]\n",
    "\n",
    "plt.xlabel('MaArearoArea')\n",
    "plt.ylabel('Total Count Below Threshold')\n",
    "plt.title('Total Count Below Threshold by Area (Colored by 4 Clusters)')\n",
    "plt.xticks(x, cluster_counts['Area'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the aggregation table\n",
    "print(\"Count_Below_Threshold aggregated by Area:\")\n",
    "print(macro_area_aggregation)\n",
    "print(\"\\nTotal counts for each cluster below threshold by Area:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_gt = 3\n",
    "test_set = FMRI[FMRI[\"Count_Below_Threshold\"]>=Number_gt]\n",
    "test_set_STRs = test_set.index.tolist()\n",
    "GENCIC_STRs = GENCIC[GENCIC[\"Circuits.32\"]==1].index.tolist()\n",
    "\n",
    "# Calculate overlap between test_set_STRs and GENCIC_STRs\n",
    "overlap_STRs = set(test_set_STRs).intersection(set(GENCIC_STRs))\n",
    "overlap_count = len(overlap_STRs)\n",
    "\n",
    "# Get the sizes of each dataset\n",
    "fMRI_size = len(FMRI.index)  # 163 regions\n",
    "GENCIC_size = len(GENCIC.index)  # 213 regions\n",
    "\n",
    "test_set_count = len(test_set_STRs)\n",
    "GENCIC_count = len(GENCIC_STRs)\n",
    "\n",
    "# For hypergeometric test, we need to determine the correct population\n",
    "# Since we're testing overlap between subsets from different populations,\n",
    "# we use the intersection of both datasets as our universe\n",
    "common_regions = set(FMRI.index).intersection(set(GENCIC.index))\n",
    "universe_size = len(common_regions)\n",
    "\n",
    "# Adjust counts to only include regions in the common universe\n",
    "test_set_in_universe = set(test_set_STRs).intersection(common_regions)\n",
    "GENCIC_in_universe = set(GENCIC_STRs).intersection(common_regions)\n",
    "test_set_count_adj = len(test_set_in_universe)\n",
    "GENCIC_count_adj = len(GENCIC_in_universe)\n",
    "\n",
    "from scipy.stats import hypergeom\n",
    "# P-value is probability of getting overlap_count or more overlaps by chance\n",
    "# hypergeom.sf(k-1, N, K, n) gives P(X >= k)\n",
    "# N = universe_size, K = GENCIC_count_adj, n = test_set_count_adj, k = overlap_count\n",
    "p_value = hypergeom.sf(overlap_count - 1, universe_size, GENCIC_count_adj, test_set_count_adj)\n",
    "\n",
    "print(f\"fMRI dataset size: {fMRI_size} regions\")\n",
    "print(f\"GENCIC dataset size: {GENCIC_size} regions\")\n",
    "print(f\"Common regions (universe): {universe_size} regions\")\n",
    "print(f\"Test set (Count_Below_Threshold >= {Number_gt}): {test_set_count} regions ({test_set_count_adj} in universe)\")\n",
    "print(f\"GENCIC Circuits.46 = 1: {GENCIC_count} regions ({GENCIC_count_adj} in universe)\")\n",
    "print(f\"Overlap: {overlap_count} regions\")\n",
    "print(f\"Overlap regions: {list(overlap_STRs)}\")\n",
    "print(f\"Hypergeometric test p-value: {p_value:.6f}\")\n",
    "\n",
    "# Calculate expected overlap under null hypothesis\n",
    "expected_overlap = (test_set_count_adj * GENCIC_count_adj) / universe_size\n",
    "print(f\"Expected overlap under null hypothesis: {expected_overlap:.2f}\")\n",
    "\n",
    "# Calculate overlap statistics\n",
    "overlap_percentage_test = (overlap_count / test_set_count_adj) * 100 if test_set_count_adj > 0 else 0\n",
    "overlap_percentage_GENCIC = (overlap_count / GENCIC_count_adj) * 100 if GENCIC_count_adj > 0 else 0\n",
    "\n",
    "print(f\"Overlap as % of fMRI set: {overlap_percentage_test:.2f}%\")\n",
    "print(f\"Overlap as % of GENCIC set: {overlap_percentage_GENCIC:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 67\n",
    "set2_size = 32\n",
    "observed_overlap = 14\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"Std intersection length: {results['std_intersection']:.2f}\")\n",
    "print(f\"Min intersection length: {results['min_intersection']}\")\n",
    "print(f\"Max intersection length: {results['max_intersection']}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "print(f\"Number of permutations with overlap >= {results['observed_overlap']}: {results['n_significant']}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_gt = 3\n",
    "test_set = FMRI[FMRI[\"Count_Below_Threshold\"]>=Number_gt]\n",
    "test_set_STRs = test_set.index.tolist()\n",
    "GENCIC_STRs = GENCIC[GENCIC[\"Circuits.46\"]==1].index.tolist()\n",
    "\n",
    "# Calculate overlap between test_set_STRs and GENCIC_STRs\n",
    "overlap_STRs = set(test_set_STRs).intersection(set(GENCIC_STRs))\n",
    "overlap_count = len(overlap_STRs)\n",
    "\n",
    "# Get the sizes of each dataset\n",
    "fMRI_size = len(FMRI.index)  # 163 regions\n",
    "GENCIC_size = len(GENCIC.index)  # 213 regions\n",
    "\n",
    "test_set_count = len(test_set_STRs)\n",
    "GENCIC_count = len(GENCIC_STRs)\n",
    "\n",
    "\n",
    "common_regions = set(FMRI.index).intersection(set(GENCIC.index))\n",
    "universe_size = len(common_regions)\n",
    "\n",
    "# Adjust counts to only include regions in the common universe\n",
    "test_set_in_universe = set(test_set_STRs).intersection(common_regions)\n",
    "GENCIC_in_universe = set(GENCIC_STRs).intersection(common_regions)\n",
    "test_set_count_adj = len(test_set_in_universe)\n",
    "GENCIC_count_adj = len(GENCIC_in_universe)\n",
    "\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "p_value = hypergeom.sf(overlap_count - 1, universe_size, GENCIC_count_adj, test_set_count_adj)\n",
    "\n",
    "print(f\"fMRI dataset size: {fMRI_size} regions\")\n",
    "print(f\"GENCIC dataset size: {GENCIC_size} regions\")\n",
    "print(f\"Test set (Count_Below_Threshold >= {Number_gt}): {test_set_count} regions ({test_set_count_adj} in universe)\")\n",
    "print(f\"GENCIC Circuits.46 = 1: {GENCIC_count} regions ({GENCIC_count_adj} in universe)\")\n",
    "print(f\"Overlap: {overlap_count} regions\")\n",
    "print(f\"Overlap regions: {list(overlap_STRs)}\")\n",
    "\n",
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 67\n",
    "set2_size = 46\n",
    "observed_overlap = 21\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% cell 25 code\n",
    "\n",
    "# Set threshold for analysis\n",
    "Number_gt = 3\n",
    "\n",
    "# Define test sets\n",
    "Region2Exclude = \"Thalamus\"\n",
    "FMRI_filt = FMRI[FMRI[\"MacroArea\"] != Region2Exclude]\n",
    "GENCIC_filt = GENCIC[GENCIC[\"REGION\"] != Region2Exclude]\n",
    "test_set = FMRI_filt[FMRI_filt[\"Count_Below_Threshold\"] >= Number_gt]\n",
    "test_set_STRs = test_set.index.tolist()\n",
    "GENCIC_STRs = GENCIC_filt[GENCIC_filt[\"Circuits.46\"] == 1].index.tolist()\n",
    "\n",
    "# Calculate overlap between test_set_STRs and GENCIC_STRs\n",
    "overlap_STRs = set(test_set_STRs).intersection(set(GENCIC_STRs))\n",
    "overlap_count = len(overlap_STRs)\n",
    "\n",
    "# Get dataset sizes\n",
    "fMRI_size = len(FMRI.index)  # 163 regions\n",
    "GENCIC_size = len(GENCIC.index)  # 213 regions\n",
    "test_set_count = len(test_set_STRs)\n",
    "GENCIC_count = len(GENCIC_STRs)\n",
    "\n",
    "# Define common universe and adjust counts\n",
    "common_regions = set(FMRI.index).intersection(set(GENCIC.index))\n",
    "universe_size = len(common_regions)\n",
    "\n",
    "test_set_in_universe = set(test_set_STRs).intersection(common_regions)\n",
    "GENCIC_in_universe = set(GENCIC_STRs).intersection(common_regions)\n",
    "test_set_count_adj = len(test_set_in_universe)\n",
    "GENCIC_count_adj = len(GENCIC_in_universe)\n",
    "\n",
    "# Calculate hypergeometric p-value\n",
    "from scipy.stats import hypergeom\n",
    "p_value = hypergeom.sf(overlap_count - 1, universe_size, GENCIC_count_adj, test_set_count_adj)\n",
    "\n",
    "# Print results\n",
    "print(f\"fMRI dataset size: {fMRI_size} regions\")\n",
    "print(f\"GENCIC dataset size: {GENCIC_size} regions\")\n",
    "print(f\"Test set (Count_Below_Threshold >= {Number_gt}): {test_set_count} regions ({test_set_count_adj} in universe)\")\n",
    "print(f\"GENCIC Circuits.46 = 1: {GENCIC_count} regions ({GENCIC_count_adj} in universe)\")\n",
    "print(f\"Overlap: {overlap_count} regions\")\n",
    "print(f\"Overlap regions: {list(overlap_STRs)}\")\n",
    "\n",
    "# Run permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 53\n",
    "set2_size = 38\n",
    "observed_overlap = 19\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_overlap(set1_range, set2_range, set1_size, set2_size, observed_overlap, n_permutations=10000):\n",
    "    \"\"\"\n",
    "    Perform a permutation test to assess the significance of overlap between two sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    set1_range : array-like\n",
    "        Range of possible values for set 1 (e.g., np.arange(1, 164))\n",
    "    set2_range : array-like\n",
    "        Range of possible values for set 2 (e.g., np.arange(1, 214))\n",
    "    set1_size : int\n",
    "        Size of set 1 sample\n",
    "    set2_size : int\n",
    "        Size of set 2 sample\n",
    "    observed_overlap : int\n",
    "        The observed overlap to test against\n",
    "    n_permutations : int, default=10000\n",
    "        Number of permutations to perform\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing test results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate all random samples at once\n",
    "    set1_samples = np.array([np.random.choice(set1_range, size=set1_size, replace=False) for _ in range(n_permutations)])\n",
    "    set2_samples = np.array([np.random.choice(set2_range, size=set2_size, replace=False) for _ in range(n_permutations)])\n",
    "\n",
    "    # Vectorized intersection calculation\n",
    "    intersections = np.array([len(np.intersect1d(set1_samples[i], set2_samples[i])) for i in range(n_permutations)])\n",
    "\n",
    "    # Calculate p-value for overlap >= observed_overlap\n",
    "    p_value = np.sum(intersections >= observed_overlap) / len(intersections)\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'intersections': intersections,\n",
    "        'mean_intersection': np.mean(intersections),\n",
    "        'std_intersection': np.std(intersections),\n",
    "        'min_intersection': np.min(intersections),\n",
    "        'max_intersection': np.max(intersections),\n",
    "        'observed_overlap': observed_overlap,\n",
    "        'p_value': p_value,\n",
    "        'n_significant': np.sum(intersections >= observed_overlap),\n",
    "        'n_permutations': n_permutations\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_permutation_results(results):\n",
    "    \"\"\"\n",
    "    Plot the results of a permutation test.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results dictionary from permutation_test_overlap function\n",
    "    \"\"\"\n",
    "    intersections = results['intersections']\n",
    "    observed_overlap = results['observed_overlap']\n",
    "    mean_intersection = results['mean_intersection']\n",
    "    n_permutations = results['n_permutations']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(intersections, bins=range(min(intersections), max(intersections)+2), \n",
    "             alpha=0.7, edgecolor='black', density=True)\n",
    "    plt.axvline(observed_overlap, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Observed overlap = {observed_overlap}')\n",
    "    plt.axvline(mean_intersection, color='blue', linestyle='--', linewidth=2, \n",
    "               label=f'Mean = {mean_intersection:.1f}')\n",
    "    plt.xlabel('Intersection Length')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title(f'Distribution of Intersections from {n_permutations} Permutations')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 67\n",
    "set2_size = 46\n",
    "observed_overlap = 21\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"Std intersection length: {results['std_intersection']:.2f}\")\n",
    "print(f\"Min intersection length: {results['min_intersection']}\")\n",
    "print(f\"Max intersection length: {results['max_intersection']}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "print(f\"Number of permutations with overlap >= {results['observed_overlap']}: {results['n_significant']}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 214)\n",
    "set1_size = 67\n",
    "set2_size = 46\n",
    "observed_overlap = 21\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"Std intersection length: {results['std_intersection']:.2f}\")\n",
    "print(f\"Min intersection length: {results['min_intersection']}\")\n",
    "print(f\"Max intersection length: {results['max_intersection']}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "print(f\"Number of permutations with overlap >= {results['observed_overlap']}: {results['n_significant']}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_permutation_results(results)\n",
    "\n",
    "# Create simple Venn diagram visualization using matplotlib\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Draw two overlapping circles\n",
    "circle1 = patches.Circle((0.35, 0.5), 0.3, alpha=0.5, color='blue', label='Set 1')\n",
    "circle2 = patches.Circle((0.65, 0.5), 0.3, alpha=0.5, color='red', label='Set 2')\n",
    "\n",
    "ax.add_patch(circle1)\n",
    "ax.add_patch(circle2)\n",
    "\n",
    "# Add text labels for each region\n",
    "ax.text(0.2, 0.5, f'{set1_size - observed_overlap}', fontsize=14, ha='center', va='center')\n",
    "ax.text(0.8, 0.5, f'{set2_size - observed_overlap}', fontsize=14, ha='center', va='center')\n",
    "ax.text(0.5, 0.5, f'{observed_overlap}', fontsize=14, ha='center', va='center', weight='bold')\n",
    "\n",
    "# Add set labels\n",
    "ax.text(0.2, 0.2, 'Set 1', fontsize=12, ha='center', va='center', weight='bold')\n",
    "ax.text(0.8, 0.2, 'Set 2', fontsize=12, ha='center', va='center', weight='bold')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title(f'Venn Diagram of Set Overlap\\nObserved Overlap: {observed_overlap}', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the permutation test\n",
    "SET1 = np.arange(1, 164)\n",
    "SET2 = np.arange(1, 164)\n",
    "set1_size = 67\n",
    "set2_size = 43\n",
    "observed_overlap = 21\n",
    "\n",
    "results = permutation_test_overlap(SET1, SET2, set1_size, set2_size, observed_overlap, n_permutations=10000)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean intersection length: {results['mean_intersection']:.2f}\")\n",
    "print(f\"Std intersection length: {results['std_intersection']:.2f}\")\n",
    "print(f\"Min intersection length: {results['min_intersection']}\")\n",
    "print(f\"Max intersection length: {results['max_intersection']}\")\n",
    "print(f\"P-value for overlap >= {results['observed_overlap']}: {results['p_value']:.6f}\")\n",
    "print(f\"Number of permutations with overlap >= {results['observed_overlap']}: {results['n_significant']}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_permutation_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK Let test if each individual cluster is overlap with Test set. \n",
    "for cluster in ['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']:\n",
    "    #_sub_test_set = FMRI.sort_values(by=cluster, ascending=False).head(46).index.values\n",
    "    _sub_test_set = FMRI.sort_values(by=cluster, ascending=False).tail(46).index.values\n",
    "    # Test overlap between _sub_test_set and test_set_STRs\n",
    "    _sub_overlap = set(_sub_test_set).intersection(set(test_set_STRs))\n",
    "    _sub_overlap_count = len(_sub_overlap)\n",
    "    \n",
    "    _sub_test_count = len(_sub_test_set)\n",
    "    _test_set_count = len(test_set_STRs)\n",
    "    _pool_size = 163  # total regions in the pool\n",
    "    \n",
    "    _sub_p_value = hypergeom.sf(_sub_overlap_count - 1, _pool_size, _test_set_count, _sub_test_count)\n",
    "\n",
    "    SET1 = np.arange(1, 164)\n",
    "    SET2 = np.arange(1, 164)\n",
    "    set1_size = 67\n",
    "    set2_size = 46\n",
    "    observed_overlap = _sub_overlap_count\n",
    "    perm_p_value = permutation_test_overlap(SET1, SET2, set1_size, set2_size, _sub_overlap_count, n_permutations=10000)\n",
    "    \n",
    "    print(f\"\\n{cluster} Analysis:\")\n",
    "    print(f\"Cluster regions: {_sub_test_count}\")\n",
    "    print(f\"Test set regions: {_test_set_count}\")\n",
    "    print(f\"Overlap: {_sub_overlap_count} regions\")\n",
    "    #print(f\"Overlap regions: {list(_sub_overlap)}\")\n",
    "    #print(f\"Hypergeometric p-value: {_sub_p_value:.6f}\")\n",
    "    print(f\"Permutation p-value: {perm_p_value['p_value']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another way. Under and Over connectivity above certain threshold. \n",
    "Cut = 0.5\n",
    "FMRI['Count_Below_Threshold_v2'] = (FMRI[['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4']].abs() > Cut).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_gt = 2\n",
    "test_set = FMRI[FMRI[\"Count_Below_Threshold_v2\"]>=Number_gt]\n",
    "test_set_STRs = test_set.index.tolist()\n",
    "GENCIC_STRs = GENCIC[GENCIC[\"Circuits.46\"]==1].index.tolist()\n",
    "\n",
    "# Calculate overlap between test_set_STRs and GENCIC_STRs\n",
    "overlap_STRs = set(test_set_STRs).intersection(set(GENCIC_STRs))\n",
    "overlap_count = len(overlap_STRs)\n",
    "\n",
    "\n",
    "# First, let's get the union of all regions from both datasets to define our universe\n",
    "all_fMRI_regions = set(FMRI.index)\n",
    "all_GENCIC_regions = set(GENCIC.index)\n",
    "universe_regions = all_fMRI_regions.union(all_GENCIC_regions)\n",
    "universe_size = len(universe_regions)\n",
    "\n",
    "test_set_count = len(test_set_STRs)\n",
    "GENCIC_count = len(GENCIC_STRs)\n",
    "\n",
    "from scipy.stats import hypergeom\n",
    "p_value = hypergeom.sf(overlap_count - 1, universe_size, GENCIC_count, test_set_count)\n",
    "\n",
    "print(f\"Universe size (union of both datasets): {universe_size} regions\")\n",
    "print(f\"Test set (Count_Below_Threshold >= {Number_gt}): {test_set_count} regions\")\n",
    "print(f\"GENCIC Circuits.46 = 1: {GENCIC_count} regions\")\n",
    "print(f\"Overlap: {overlap_count} regions\")\n",
    "print(f\"Overlap regions: {list(overlap_STRs)}\")\n",
    "\n",
    "\n",
    "# Calculate expected overlap under null hypothesis\n",
    "expected_overlap = (test_set_count * GENCIC_count) / universe_size\n",
    "print(f\"Expected overlap under null hypothesis: {expected_overlap:.2f}\")\n",
    "\n",
    "# Calculate overlap statistics\n",
    "overlap_percentage_test = (overlap_count / test_set_count) * 100 if test_set_count > 0 else 0\n",
    "overlap_percentage_GENCIC = (overlap_count / GENCIC_count) * 100 if GENCIC_count > 0 else 0\n",
    "\n",
    "print(f\"Overlap as % of fMRI set: {overlap_percentage_test:.2f}%\")\n",
    "print(f\"Overlap as % of GENCIC set: {overlap_percentage_GENCIC:.2f}%\")\n",
    "print(f\"Hypergeometric test p-value: {p_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate FMRI dataframe with GENCIC Bias and Circuits.46 membership\n",
    "FMRI_annotated = FMRI.copy()\n",
    "\n",
    "# Add GENCIC Bias column\n",
    "FMRI_annotated['GENCIC_Bias'] = FMRI_annotated.index.map(GENCIC['Bias'])\n",
    "FMRI_annotated['GENCIC_Circuits_46'] = FMRI_annotated.index.map(GENCIC['Circuits.46'])\n",
    "FMRI_annotated['FullName'] = FMRI_annotated.index.map(GENCIC['Structure'])\n",
    "\n",
    "# Fill NaN values with 0 for regions not in GENCIC\n",
    "FMRI_annotated['GENCIC_Bias'] = FMRI_annotated['GENCIC_Bias'].fillna(0)\n",
    "FMRI_annotated['GENCIC_Circuits_46'] = FMRI_annotated['GENCIC_Circuits_46'].fillna(0)\n",
    "\n",
    "FMRI_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMRI_annotated.to_csv('/home/jw3514/Work/FuncConnectome/ASD_Mouse/Clusters_Images/FMRI_annotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "# Mouse Model fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDIR = \"/home/jw3514/Work/FuncConnectome/ASD_Mouse/OneDrive_1_7-31-2025/\"\n",
    "data_csf = sio.loadmat(DataDIR + \"global_connectivity_allsubjs_CSF.mat\")\n",
    "data_gsr = sio.loadmat(DataDIR + \"global_connectivity_allsubjs_GSR.mat\")\n",
    "\n",
    "parcel_indices = pd.read_csv(DataDIR + \"parcel_indices_424.csv\")\n",
    "parcel_labels = pd.read_csv(DataDIR + \"parc_labels_424_LR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_csf = data_csf['global_connectivity_allsubjs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_csf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class MouseGlobalConnectivity:\n",
    "    def __init__(self, mat_file, parcel_idx_file, parcel_label_file):\n",
    "        self.mat_file = Path(mat_file)\n",
    "        self.mouse_models = ['shank3b', 'chd8', 'cntnap2', 'mecp2']\n",
    "        self.genotypes = ['mutant', 'wt']\n",
    "\n",
    "        # Load parcel metadata\n",
    "        self.parcel_indices = pd.read_csv(parcel_idx_file, header=None, names=['index'])  # 1-based indices\n",
    "        self.parcel_labels = pd.read_csv(parcel_label_file)  # has 'name' column\n",
    "\n",
    "        # Map indices to names (adjust 1-based to 0-based indexing)\n",
    "        idx_zero_based = self.parcel_indices['index'].values - 1\n",
    "        self.parcel_names = self.parcel_labels.iloc[idx_zero_based]['name'].tolist()\n",
    "\n",
    "        # Load MATLAB data\n",
    "        self.data = self._load_mat()\n",
    "\n",
    "    def _load_mat(self):\n",
    "        \"\"\"Load MATLAB .mat file (v7.2 or older)\"\"\"\n",
    "        mat = sio.loadmat(self.mat_file, squeeze_me=True)\n",
    "        return {k: v for k, v in mat.items() if not k.startswith('__')}\n",
    "\n",
    "    def get_connectivity(self, mouse_model, genotype):\n",
    "        \"\"\"Return connectivity matrix for a given mouse model and genotype\"\"\"\n",
    "        if mouse_model not in self.mouse_models:\n",
    "            raise ValueError(f\"Unknown mouse model: {mouse_model}\")\n",
    "        if genotype not in self.genotypes:\n",
    "            raise ValueError(f\"Genotype must be one of {self.genotypes}\")\n",
    "\n",
    "        arr = self.data['global_connectivity_allsubjs']  # 4Ã—2 array of matrices\n",
    "        row = self.mouse_models.index(mouse_model)\n",
    "        col = self.genotypes.index(genotype)\n",
    "\n",
    "        mat = arr[row, col]\n",
    "        return np.array(mat)\n",
    "\n",
    "    def _merge_hemispheres(self, df, strategy=\"average\"):\n",
    "        \"\"\"Merge left/right hemisphere parcels. If only one side exists, keep as is.\"\"\"\n",
    "        base_names = df.index.str.replace(r'_(L|R)$', '', regex=True)\n",
    "\n",
    "        if strategy == \"average\":\n",
    "            # For each base name, average L/R if both exist, else just keep the one present\n",
    "            df = df.copy()\n",
    "            df['__base__'] = base_names\n",
    "            merged = []\n",
    "            for base, group in df.groupby('__base__'):\n",
    "                if len(group) == 2:\n",
    "                    merged_row = group.drop(columns='__base__').mean()\n",
    "                else:\n",
    "                    merged_row = group.drop(columns='__base__').iloc[0]\n",
    "                merged.append((base, merged_row))\n",
    "            merged_df = pd.DataFrame([row for _, row in merged], index=[base for base, _ in merged])\n",
    "            return merged_df\n",
    "\n",
    "        elif strategy == \"concat\":\n",
    "            # For each base name, concat L and R columns if both exist, else just keep the one present\n",
    "            left_mask = df.index.str.endswith('_L')\n",
    "            right_mask = df.index.str.endswith('_R')\n",
    "            left_df = df[left_mask].copy()\n",
    "            right_df = df[right_mask].copy()\n",
    "\n",
    "            left_df.index = left_df.index.str.replace(r'_L$', '', regex=True)\n",
    "            right_df.index = right_df.index.str.replace(r'_R$', '', regex=True)\n",
    "\n",
    "            left_df.columns = [f\"{c}_L\" for c in left_df.columns]\n",
    "            right_df.columns = [f\"{c}_R\" for c in right_df.columns]\n",
    "\n",
    "            # Find all base names\n",
    "            all_bases = set(left_df.index) | set(right_df.index)\n",
    "            concat_rows = []\n",
    "            concat_index = []\n",
    "            for base in sorted(all_bases):\n",
    "                left_row = left_df.loc[base] if base in left_df.index else None\n",
    "                right_row = right_df.loc[base] if base in right_df.index else None\n",
    "                if left_row is not None and right_row is not None:\n",
    "                    row = pd.concat([left_row, right_row])\n",
    "                elif left_row is not None:\n",
    "                    row = left_row\n",
    "                elif right_row is not None:\n",
    "                    row = right_row\n",
    "                else:\n",
    "                    continue  # Should not happen\n",
    "                concat_rows.append(row)\n",
    "                concat_index.append(base)\n",
    "            expanded = pd.DataFrame(concat_rows, index=concat_index)\n",
    "            expanded = expanded.sort_index()\n",
    "            return expanded\n",
    "\n",
    "        elif strategy is None:\n",
    "            return df\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"merge strategy must be 'average', 'concat', or None\")\n",
    "\n",
    "    def get_dataframe(self, mouse_model, genotype, merge=None):\n",
    "        \"\"\"\n",
    "        Return DataFrame with parcel names and connectivity values.\n",
    "        merge: None, 'average', or 'concat'\n",
    "        \"\"\"\n",
    "        mat = self.get_connectivity(mouse_model, genotype)\n",
    "        df = pd.DataFrame(\n",
    "            mat,\n",
    "            index=self.parcel_names,\n",
    "            columns=[f\"subj_{i+1}\" for i in range(mat.shape[1])]\n",
    "        )\n",
    "        df.index.name = 'parcel_name'\n",
    "\n",
    "        if merge is not None:\n",
    "            df = self._merge_hemispheres(df, strategy=merge)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "def connectivity_test(data, method, gene):\n",
    "    mut_df = data[method][gene][\"mutant\"]\n",
    "    wt_df = data[method][gene][\"wt\"]\n",
    "    results = []\n",
    "    for i, _str in enumerate(mut_df.index.values):\n",
    "        mut_conn = mut_df.iloc[i, :]\n",
    "        wt_conn = wt_df.iloc[i, :]\n",
    "        # Exclude invalid values (NaN, inf, -inf)\n",
    "        mut_conn_valid = mut_conn[~np.isnan(mut_conn) & np.isfinite(mut_conn)]\n",
    "        wt_conn_valid = wt_conn[~np.isnan(wt_conn) & np.isfinite(wt_conn)]\n",
    "        mut_conn_mean = mut_conn_valid.mean()\n",
    "        wt_conn_mean = wt_conn_valid.mean()\n",
    "        mut_conn_std = mut_conn_valid.std()\n",
    "        wt_conn_std = wt_conn_valid.std()\n",
    "        # Only perform test if both groups have at least one valid value\n",
    "        if len(mut_conn_valid) > 0 and len(wt_conn_valid) > 0:\n",
    "            stat, p = mannwhitneyu(mut_conn_valid, wt_conn_valid, alternative='two-sided')\n",
    "        else:\n",
    "            p = np.nan\n",
    "        results.append({\n",
    "            'parcel_name': _str,\n",
    "            'mut_mean': mut_conn_mean,\n",
    "            'wt_mean': wt_conn_mean,\n",
    "            'conn_diff': mut_conn_mean - wt_conn_mean,\n",
    "            'mut_std': mut_conn_std,\n",
    "            'wt_std': wt_conn_std,\n",
    "            'mwu_p': p\n",
    "        })\n",
    "    results_df = pd.DataFrame(results).set_index('parcel_name')\n",
    "    results_df = results_df.sort_values(by='mwu_p')\n",
    "    return results_df\n",
    "\n",
    "def collapse_hemispheres(df, strategy='mean'):\n",
    "    if strategy == 'mean':\n",
    "        # Strip _L / _R suffix from parcel names\n",
    "        collapsed = df.copy()\n",
    "        collapsed.index = collapsed.index.str.replace(r'_(L|R)$', '', regex=True)\n",
    "        # Group by the new parcel name and take the mean across L and R\n",
    "        collapsed = collapsed.groupby(collapsed.index).mean()\n",
    "        return collapsed\n",
    "    elif strategy == 'concat':\n",
    "        # Strip _L / _R suffix from parcel names\n",
    "        collapsed = df.copy()\n",
    "        collapsed.index = collapsed.index.str.replace(r'_(L|R)$', '', regex=True)\n",
    "        # Group by the new parcel name and take the mean across L and R\n",
    "        collapsed = collapsed.groupby(collapsed.index).mean()\n",
    "        return collapsed\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid strategy: {strategy}\")\n",
    "        \n",
    "def print_data_treeview(data, indent=0):\n",
    "    for preproc in data:\n",
    "        print(\"  \" * indent + f\"{preproc}/\")\n",
    "        for gene in data[preproc]:\n",
    "            print(\"  \" * (indent + 1) + f\"{gene}/\")\n",
    "            for group in data[preproc][gene]:\n",
    "                print(\"  \" * (indent + 2) + f\"{group}: DataFrame shape {data[preproc][gene][group].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned up data structure: use nested dicts for easy access\n",
    "# Structure: data[preproc][gene][group] = dataframe\n",
    "\n",
    "data = {}\n",
    "for preproc, loader in {\n",
    "    \"CSF\": MouseGlobalConnectivity(\n",
    "        mat_file=DataDIR + \"global_connectivity_allsubjs_CSF.mat\",\n",
    "        parcel_idx_file=DataDIR + \"parcel_indices_424.csv\",\n",
    "        parcel_label_file=DataDIR + \"parc_labels_424_LR.csv\"\n",
    "    ),\n",
    "    \"GSR\": MouseGlobalConnectivity(\n",
    "        mat_file=DataDIR + \"global_connectivity_allsubjs_GSR.mat\",\n",
    "        parcel_idx_file=DataDIR + \"parcel_indices_424.csv\",\n",
    "        parcel_label_file=DataDIR + \"parc_labels_424_LR.csv\"\n",
    "    )\n",
    "}.items():\n",
    "    data[preproc] = {}\n",
    "    for gene in [\"shank3b\", \"cntnap2\", \"chd8\", \"mecp2\"]:\n",
    "        data[preproc][gene] = {}\n",
    "        for group in [\"mutant\", \"wt\"]:\n",
    "            data[preproc][gene][group] = loader.get_dataframe(gene, group, merge=None)\n",
    "print_data_treeview(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LR_merge = {}\n",
    "for preproc, loader in {\n",
    "    \"CSF\": MouseGlobalConnectivity(\n",
    "        mat_file=DataDIR + \"global_connectivity_allsubjs_CSF.mat\",\n",
    "        parcel_idx_file=DataDIR + \"parcel_indices_424.csv\",\n",
    "        parcel_label_file=DataDIR + \"parc_labels_424_LR.csv\"\n",
    "    ),\n",
    "    \"GSR\": MouseGlobalConnectivity(\n",
    "        mat_file=DataDIR + \"global_connectivity_allsubjs_GSR.mat\",\n",
    "        parcel_idx_file=DataDIR + \"parcel_indices_424.csv\",\n",
    "        parcel_label_file=DataDIR + \"parc_labels_424_LR.csv\"\n",
    "    )\n",
    "}.items():\n",
    "    data_LR_merge[preproc] = {}\n",
    "    for gene in [\"shank3b\", \"cntnap2\", \"chd8\", \"mecp2\"]:\n",
    "        data_LR_merge[preproc][gene] = {}\n",
    "        for group in [\"mutant\", \"wt\"]:\n",
    "            data_LR_merge[preproc][gene][group] = loader.get_dataframe(gene, group, merge=\"average\")\n",
    "print_data_treeview(data_LR_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shank3b_mut.head(5)\n",
    "data[\"CSF\"][\"shank3b\"][\"mutant\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSF_shank3b_res = connectivity_test(data, \"CSF\", \"shank3b\")\n",
    "CSF_chd8_res = connectivity_test(data, \"CSF\", \"chd8\")\n",
    "CSF_cntnap2_res = connectivity_test(data, \"CSF\", \"cntnap2\")\n",
    "CSF_mecp2_res = connectivity_test(data, \"CSF\", \"mecp2\")\n",
    "\n",
    "GSR_shank3b_res = connectivity_test(data, \"GSR\", \"shank3b\")\n",
    "GSR_chd8_res = connectivity_test(data, \"GSR\", \"chd8\")\n",
    "GSR_cntnap2_res = connectivity_test(data, \"GSR\", \"cntnap2\")\n",
    "GSR_mecp2_res = connectivity_test(data, \"GSR\", \"mecp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSF_shank3b_res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def compare_lr_correlations(results_df, plot=True, title=None):\n",
    "    \"\"\"\n",
    "    Compare left vs right hemisphere correlation for conn_diff and mwu_p,\n",
    "    and make scatter plots of L vs R for both conn_diff and -log10(mwu_p).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_df : pd.DataFrame\n",
    "        Must have index with `_L` and `_R` suffixes and columns 'conn_diff' and 'mwu_p'.\n",
    "    plot : bool\n",
    "        If True, show scatter plots.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Spearman correlations for conn_diff and mwu_p.\n",
    "    \"\"\"\n",
    "    # Make sure we only use parcels with both L and R\n",
    "    base_names = results_df.index.str.replace(r'_(L|R)$', '', regex=True)\n",
    "    results_df = results_df.assign(base=base_names)\n",
    "    \n",
    "    left_df = results_df[results_df.index.str.endswith('_L')].copy()\n",
    "    right_df = results_df[results_df.index.str.endswith('_R')].copy()\n",
    "    \n",
    "    # Align on base name\n",
    "    left_df.index = left_df['base']\n",
    "    right_df.index = right_df['base']\n",
    "    \n",
    "    # Intersect bases to be safe\n",
    "    common = left_df.index.intersection(right_df.index)\n",
    "    left_df = left_df.loc[common]\n",
    "    right_df = right_df.loc[common]\n",
    "    \n",
    "    # Spearman correlations\n",
    "    rho_conn, p_conn = spearmanr(left_df['conn_diff'], right_df['conn_diff'])\n",
    "    rho_pval, p_pval = spearmanr(left_df['mwu_p'], right_df['mwu_p'])\n",
    "    \n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        \n",
    "        # Scatter for conn_diff\n",
    "        axs[0].scatter(left_df['conn_diff'], right_df['conn_diff'], alpha=0.7)\n",
    "        axs[0].set_xlabel('Left conn_diff')\n",
    "        axs[0].set_ylabel('Right conn_diff')\n",
    "        axs[0].set_title(f'conn_diff L vs R\\nSpearman r={rho_conn:.2f}, p={p_conn:.2g}')\n",
    "        axs[0].axline((0, 0), slope=1, color='gray', linestyle='--', linewidth=1)\n",
    "        \n",
    "        # Scatter for -log10(mwu_p)\n",
    "        left_logp = -np.log10(left_df['mwu_p'].clip(lower=1e-20))\n",
    "        right_logp = -np.log10(right_df['mwu_p'].clip(lower=1e-20))\n",
    "        axs[1].scatter(left_logp, right_logp, alpha=0.7)\n",
    "        axs[1].set_xlabel('-log10(mwu_p) Left')\n",
    "        axs[1].set_ylabel('-log10(mwu_p) Right')\n",
    "        axs[1].set_title(f'-log10(mwu_p) L vs R\\nSpearman r={rho_pval:.2f}, p={p_pval:.2g}')\n",
    "        axs[1].axline((0, 0), slope=1, color='gray', linestyle='--', linewidth=1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if title is not None:\n",
    "            fig.suptitle(title)\n",
    "            plt.subplots_adjust(top=0.85)\n",
    "        plt.show()\n",
    "    \n",
    "    res = {\n",
    "        \"n_pairs\": len(common),\n",
    "        \"conn_diff_spearman_rho\": rho_conn,\n",
    "        \"conn_diff_pval\": p_conn,\n",
    "        \"mwu_p_spearman_rho\": rho_pval,\n",
    "        \"mwu_p_pval\": p_pval\n",
    "    }\n",
    "    return pd.DataFrame([res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res_df, name in zip([CSF_shank3b_res, GSR_shank3b_res, CSF_chd8_res, GSR_chd8_res, CSF_cntnap2_res, GSR_cntnap2_res, CSF_mecp2_res, GSR_mecp2_res], [\"CSF Shank3b\", \"GSR Shank3b\", \"CSF Chd8\", \"GSR Chd8\", \"CSF Cntnap2\", \"GSR Cntnap2\", \"CSF Mepc2\", \"GSR Mepc2\"]) :\n",
    "    lr_corr = compare_lr_correlations(res_df, title=name)\n",
    "#print(lr_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSF_merge_shank3b_res = connectivity_test(data_LR_merge, \"CSF\", \"shank3b\")\n",
    "CSF_merge_chd8_res = connectivity_test(data_LR_merge, \"CSF\", \"chd8\")\n",
    "CSF_merge_cntnap2_res = connectivity_test(data_LR_merge, \"CSF\", \"cntnap2\")\n",
    "CSF_merge_mecp2_res = connectivity_test(data_LR_merge, \"CSF\", \"mecp2\")\n",
    "\n",
    "GSR_merge_shank3b_res = connectivity_test(data_LR_merge, \"GSR\", \"shank3b\")\n",
    "GSR_merge_chd8_res = connectivity_test(data_LR_merge, \"GSR\", \"chd8\")\n",
    "GSR_merge_cntnap2_res = connectivity_test(data_LR_merge, \"GSR\", \"cntnap2\")\n",
    "GSR_merge_mecp2_res = connectivity_test(data_LR_merge, \"GSR\", \"mecp2\")\n",
    "\n",
    "merge_res_dict = {\n",
    "    \"CSF_merge\": {\n",
    "        \"shank3b\": CSF_merge_shank3b_res,\n",
    "        \"chd8\": CSF_merge_chd8_res,\n",
    "        \"cntnap2\": CSF_merge_cntnap2_res,\n",
    "        \"mecp2\": CSF_merge_mecp2_res\n",
    "    },\n",
    "    \"GSR_merge\": {\n",
    "        \"shank3b\": GSR_merge_shank3b_res,\n",
    "        \"chd8\": GSR_merge_chd8_res,\n",
    "        \"cntnap2\": GSR_merge_cntnap2_res,\n",
    "        \"mecp2\": GSR_merge_mecp2_res\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_res_dict[\"CSF_merge\"][\"shank3b\"].sort_values(by=\"conn_diff\").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_res_dict[\"CSF_merge\"][\"chd8\"].sort_values(by=\"conn_diff\").tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_spearman(merge_results_dict, stat_type=\"conn_diff\", merge_key=\"CSF_merge\"):\n",
    "    \"\"\"\n",
    "    Compare models pairwise by Spearman correlation of MWU p-values using the new merge_res_dict structure.\n",
    "\n",
    "    merge_results_dict: dict\n",
    "        Outer keys = merge type (e.g., \"CSF_merge\", \"GSR_merge\")\n",
    "        Inner keys = model name (str)\n",
    "        Inner values = results DataFrame (must have 'conn_diff' column and same index)\n",
    "    stat_type: str\n",
    "        The column to use for correlation (default \"conn_diff\")\n",
    "    merge_key: str\n",
    "        Which merge type to use from merge_results_dict (default \"CSF_merge\")\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of pairwise Spearman correlation coefficients.\n",
    "    \"\"\"\n",
    "    # Use the specified merge_key to get the inner dict of models\n",
    "    results_dict = merge_results_dict[merge_key]\n",
    "    models = list(results_dict.keys())\n",
    "    corr_df = pd.DataFrame(index=models, columns=models, dtype=float)\n",
    "\n",
    "    for m1, m2 in combinations(models, 2):\n",
    "        # Align by parcel_name index\n",
    "        s1 = results_dict[m1][stat_type]\n",
    "        s2 = results_dict[m2][stat_type]\n",
    "        aligned = pd.concat([s1, s2], axis=1, join='inner').dropna()\n",
    "\n",
    "        rho, _ = spearmanr(aligned.iloc[:, 0], aligned.iloc[:, 1])\n",
    "\n",
    "        corr_df.loc[m1, m2] = rho\n",
    "        corr_df.loc[m2, m1] = rho\n",
    "\n",
    "    # Fill diagonal\n",
    "    for m in models:\n",
    "        corr_df.loc[m, m] = 1.0\n",
    "\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_table = compare_models_spearman(merge_res_dict, merge_key=\"CSF_merge\")\n",
    "sns.heatmap(rho_table.astype(float), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Spearman correlation of MWU p-values across models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_table = compare_models_spearman(merge_res_dict, merge_key=\"GSR_merge\")\n",
    "sns.heatmap(rho_table.astype(float), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Spearman correlation of MWU p-values across models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_topN_overlap(results_dict, N=50, merge_key=None):\n",
    "    \"\"\"\n",
    "    Compare models by % overlap of top-N parcels (lowest MWU p-values).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_dict : dict\n",
    "        If merge_key is None:\n",
    "            Keys = model name (str)\n",
    "            Values = results DataFrame (must have 'mwu_p' column)\n",
    "        If merge_key is not None:\n",
    "            Outer keys = merge type (e.g., \"CSF_merge\", \"GSR_merge\")\n",
    "            Inner keys = model name (str)\n",
    "            Inner values = results DataFrame (must have 'mwu_p' column)\n",
    "    N : int\n",
    "        Number of top parcels to compare.\n",
    "    merge_key : str or None\n",
    "        If not None, use this key to select the inner dict from results_dict.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Pairwise % overlap of top-N parcels.\n",
    "    \"\"\"\n",
    "    # Handle merge_res_dict format if merge_key is provided\n",
    "    if merge_key is not None:\n",
    "        results_dict = results_dict[merge_key]\n",
    "\n",
    "    models = list(results_dict.keys())\n",
    "    overlap_df = pd.DataFrame(index=models, columns=models, dtype=float)\n",
    "\n",
    "    # Precompute top-N sets for each model\n",
    "    top_sets = {}\n",
    "    for model, df in results_dict.items():\n",
    "        top_sets[model] = set(df.sort_values('mwu_p').head(N).index)\n",
    "\n",
    "    for m1, m2 in combinations(models, 2):\n",
    "        overlap_count = len(top_sets[m1] & top_sets[m2])\n",
    "        overlap_pct = overlap_count / N\n",
    "        overlap_df.loc[m1, m2] = overlap_pct\n",
    "        overlap_df.loc[m2, m1] = overlap_pct\n",
    "\n",
    "    # Fill diagonal with 1.0\n",
    "    for m in models:\n",
    "        overlap_df.loc[m, m] = 1.0\n",
    "\n",
    "    return overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models_topN_overlap(merge_res_dict, merge_key=\"CSF_merge\", N=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models_topN_overlap(merge_res_dict, merge_key=\"GSR_merge\", N=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC = pd.read_excel(\"/home/jw3514/Work/ASD_Circuits_CellType/results/SupTabs.v57.xlsx\", sheet_name=\"Table-S1- Structure Bias\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "CommonSTRs = merge_res_dict[\"CSF_merge\"][\"shank3b\"].index.intersection(GENCIC.index)\n",
    "GENCIC_intersect = GENCIC.loc[CommonSTRs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate conn_diff and mwu_p for each mouse model and each method to GENCIC DataFrame\n",
    "\n",
    "# Define the methods and mouse models to annotate\n",
    "methods = [\"CSF_merge\", \"GSR_merge\"]\n",
    "mouse_models = list(merge_res_dict[\"CSF_merge\"].keys())\n",
    "\n",
    "for method in methods:\n",
    "    for model in mouse_models:\n",
    "        # Prepare column names for conn_diff and mwu_p\n",
    "        conn_col = f\"{model}_{method}_conn_diff\"\n",
    "        pval_col = f\"{model}_{method}_mwu_p\"\n",
    "        # Initialize columns if not present\n",
    "        if conn_col not in GENCIC_intersect.columns:\n",
    "            GENCIC_intersect[conn_col] = pd.NA\n",
    "        if pval_col not in GENCIC_intersect.columns:\n",
    "            GENCIC_intersect[pval_col] = pd.NA\n",
    "        # Get the result DataFrame for this model/method\n",
    "        res_df = merge_res_dict[method][model]\n",
    "        for STR in GENCIC_intersect.index:\n",
    "            if STR in res_df.index:\n",
    "                GENCIC_intersect.at[STR, conn_col] = res_df.at[STR, \"conn_diff\"] if \"conn_diff\" in res_df.columns else pd.NA\n",
    "                GENCIC_intersect.at[STR, pval_col] = res_df.at[STR, \"mwu_p\"] if \"mwu_p\" in res_df.columns else pd.NA\n",
    "            else:\n",
    "                GENCIC_intersect.at[STR, conn_col] = pd.NA\n",
    "                GENCIC_intersect.at[STR, pval_col] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC_intersect.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENCIC_intersect.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mousemodels = [\"shank3b\", \"chd8\", \"cntnap2\", \"mecp2\"]\n",
    "methods = [\"CSF_merge\", \"GSR_merge\"]\n",
    "\n",
    "fig, axes = plt.subplots(len(mousemodels), len(methods), figsize=(10, 16), dpi=150, sharex=True, sharey=False)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "for i, mousemodel in enumerate(mousemodels):\n",
    "    for j, method in enumerate(methods):\n",
    "        ax = axes[i, j]\n",
    "        x = GENCIC_intersect[\"Bias\"]\n",
    "        y = GENCIC_intersect[f\"{mousemodel}_{method}_conn_diff\"]\n",
    "        valid = x.notna() & y.notna()\n",
    "        if valid.sum() > 1:\n",
    "            corr, p = spearmanr(x[valid], y[valid])\n",
    "            ax.scatter(x[valid], y[valid], alpha=0.7, s=20)\n",
    "            ax.set_title(f\"{mousemodel} - {method}\")\n",
    "            ax.annotate(f\"r={corr:.2f}\\np={p:.2g}\", xy=(0.05, 0.85), xycoords=\"axes fraction\", fontsize=10,\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"gray\", alpha=0.7))\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"Not enough data\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "            ax.set_title(f\"{mousemodel} - {method}\")\n",
    "        if i == len(mousemodels) - 1:\n",
    "            ax.set_xlabel(\"GENCIC Bias\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"Conn Diff\")\n",
    "plt.suptitle(\"GENCIC Bias vs Mouse Model Conn Diff\\n(Spearman r and p shown)\", fontsize=16, y=0.92)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Collect all relevant columns for pairwise correlation\n",
    "cols = [\"Bias\"]\n",
    "for mousemodel in [\"shank3b\", \"chd8\", \"cntnap2\", \"mecp2\"]:\n",
    "    for method in [\"CSF_merge\", \"GSR_merge\"]:\n",
    "        col = f\"{mousemodel}_{method}_conn_diff\"\n",
    "        if col in GENCIC_intersect.columns:\n",
    "            cols.append(col)\n",
    "\n",
    "# Subset and drop rows with all-NA\n",
    "df_corr = GENCIC_intersect[cols].copy()\n",
    "df_corr = df_corr.dropna(how=\"all\", subset=cols)\n",
    "\n",
    "# Compute pairwise Spearman correlation\n",
    "corr_matrix = df_corr.corr(method=\"spearman\")\n",
    "\n",
    "# Cluster the correlation matrix and show clustered heatmap\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute linkage for rows and columns\n",
    "linkage_rows = linkage(corr_matrix, method='average')\n",
    "linkage_cols = linkage(corr_matrix.T, method='average')\n",
    "\n",
    "# Get the order of rows and columns after clustering\n",
    "row_order = leaves_list(linkage_rows)\n",
    "col_order = leaves_list(linkage_cols)\n",
    "\n",
    "# Reorder the correlation matrix\n",
    "corr_matrix_clustered = corr_matrix.iloc[row_order, col_order]\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "sns.heatmap(\n",
    "    corr_matrix_clustered, annot=True, cmap=\"vlag\", center=0,\n",
    "    linewidths=0.5, cbar_kws={\"label\": \"Spearman r\"}\n",
    ")\n",
    "plt.title(\"Clustered Spearman Correlation: GENCIC Bias & Mouse Model Conn Diff\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top HypoConnected vs GENCIC Bias \n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "def compute_hypergeometric_pvalue(N_total, N_set1, N_set2, N_common):\n",
    "    \"\"\"\n",
    "    Compute the p-value for observing at least N_common overlap between two sets\n",
    "    of size N_set1 and N_set2 drawn from a population of size N_total.\n",
    "    \"\"\"\n",
    "    # P(X >= N_common)\n",
    "    # sf is \"survival function\" = 1 - cdf, so sf(N_common-1) = P(X >= N_common)\n",
    "    pval = hypergeom.sf(N_common-1, N_total, N_set1, N_set2)\n",
    "    return pval\n",
    "\n",
    "GENCIC_STRs = GENCIC_intersect[GENCIC_intersect[\"Circuits.46\"] == 1].index.values\n",
    "N_total_STR = 211\n",
    "N_GENCIC = len(GENCIC_STRs)\n",
    "N_top = 44\n",
    "N_bottom = 44\n",
    "\n",
    "for mousemodel in [\"shank3b\", \"chd8\", \"cntnap2\", \"mecp2\"]:\n",
    "    for method in [\"CSF_merge\", \"GSR_merge\"]:\n",
    "        col = f\"{mousemodel}_{method}_conn_diff\"\n",
    "        col = GENCIC_intersect[col].sort_values(ascending=False)\n",
    "        top46 = col.head(N_top)\n",
    "        bottom44 = col.tail(N_bottom)\n",
    "        Common_hyper = set(GENCIC_STRs).intersection(set(top46.index))\n",
    "        Common_hypo = set(GENCIC_STRs).intersection(set(bottom44.index))\n",
    "        pval_hyper = compute_hypergeometric_pvalue(N_total_STR, N_GENCIC, N_top, len(Common_hyper))\n",
    "        pval_hypo = compute_hypergeometric_pvalue(N_total_STR, N_GENCIC, N_bottom, len(Common_hypo))\n",
    "        print(f\"{mousemodel} {method} | Hyper: {len(Common_hyper)} (p={pval_hyper:.4g}), Hypo: {len(Common_hypo)} (p={pval_hypo:.4g})\")\n",
    "        #print(Common_hyper)\n",
    "        #print(Common_hypo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gencic)",
   "language": "python",
   "name": "gencic"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
