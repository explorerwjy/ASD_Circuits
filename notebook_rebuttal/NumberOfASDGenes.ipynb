{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "ProjDIR = \"/home/jw3514/Work/ASD_Circuits_CellType/\" # Change to your project directory\n",
    "sys.path.insert(1, f'{ProjDIR}/src/')\n",
    "from ASD_Circuits import *\n",
    "\n",
    "try:\n",
    "    os.chdir(f\"{ProjDIR}/notebook_rebuttal/\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not change directory - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "\n",
    "\n",
    "HGNC, ENSID2Entrez, GeneSymbol2Entrez, Entrez2Symbol = LoadGeneINFO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "with open(\"../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "expr_matrix_path = config[\"analysis_types\"][\"STR_ISH\"][\"expr_matrix\"]\n",
    "STR_BiasMat = pd.read_parquet(f\"../{expr_matrix_path}\")\n",
    "Anno = STR2Region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_structure_bias_correlation(df_a, df_b, label_a='Dataset A', label_b='Dataset B', title=None):\n",
    "    \"\"\"\n",
    "    Create comparison plot between two structure bias datasets\n",
    "\n",
    "    Parameters:\n",
    "    df_a: DataFrame with EFFECT column for first dataset\n",
    "    df_b: DataFrame with EFFECT column for second dataset\n",
    "    label_a: Label for x-axis (first dataset)\n",
    "    label_b: Label for y-axis (second dataset)\n",
    "    title: Custom title for the plot (ignored, no title drawn)\n",
    "\n",
    "    Returns:\n",
    "    correlation: Pearson correlation coefficient\n",
    "    \"\"\"\n",
    "    from scipy.stats import pearsonr\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(1, 1, dpi=120, figsize=(5, 4), facecolor='none')\n",
    "\n",
    "    fig.patch.set_alpha(0)\n",
    "    ax.patch.set_alpha(0)\n",
    "\n",
    "    # Merge the datasets on structure names for comparison\n",
    "    merged_data = pd.merge(df_a[['EFFECT']], df_b[['EFFECT']], \n",
    "                          left_index=True, right_index=True, suffixes=('_A', '_B'))\n",
    "\n",
    "    # Create scatter plot\n",
    "    ax.scatter(merged_data['EFFECT_A'], merged_data['EFFECT_B'], \n",
    "              alpha=1, s=20, c='#1f77b4', edgecolors='black', linewidth=0.5)\n",
    "\n",
    "    # Add diagonal line for reference\n",
    "    min_val = min(merged_data['EFFECT_A'].min(), merged_data['EFFECT_B'].min())\n",
    "    max_val = max(merged_data['EFFECT_A'].max(), merged_data['EFFECT_B'].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2, label='y=x')\n",
    "\n",
    "    # Calculate correlation and p-value\n",
    "    correlation, pval = pearsonr(merged_data['EFFECT_A'], merged_data['EFFECT_B'])\n",
    "\n",
    "    # Set labels (no title)\n",
    "    ax.set_xlabel(f'{label_a}', fontsize=14)\n",
    "    ax.set_ylabel(f'{label_b}', fontsize=14)\n",
    "\n",
    "    # Format p-value display according to instructions\n",
    "    if pval < 1e-10:\n",
    "        p_disp = f\"p <{1e-10:.0e}\"\n",
    "    else:\n",
    "        p_disp = f\"p ={pval:.2g}\"\n",
    "\n",
    "    # Put correlation and p-value inside plot as annotation\n",
    "    ax.annotate(f'r = {correlation:.3f}\\n{p_disp}',\n",
    "                xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                ha='left', va='top', fontsize=15,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"w\", ec=\"gray\", alpha=0.8))\n",
    "\n",
    "    # Add grid\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "    # Make axes equal for better comparison\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    #print(f\"Correlation between {label_a} and {label_b} structure bias: {correlation:.4f}\")\n",
    "    #print(f\"Number of structures compared: {len(merged_data)}\")\n",
    "\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_ASD_STR_Bias = pd.read_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.FDR.csv\", index_col=0)\n",
    "Spark_ASD_STR_Bias[\"Region\"] = [Anno.get(ct_idx, \"Unknown\") for ct_idx in Spark_ASD_STR_Bias.index.values]\n",
    "\n",
    "Spark_ASD_159_STR_Bias = pd.read_csv(\"/home/jw3514/Work/ASD_Circuits_CellType/results/STR_ISH/ASD_SPARK_159_bias_addP_sibling.csv\", index_col=0)\n",
    "Spark_ASD_159_STR_Bias[\"Region\"] = [Anno.get(ct_idx, \"Unknown\") for ct_idx in Spark_ASD_159_STR_Bias.index.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Saterstorm et al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/jw3514/Work/ASD_Circuits_CellType/dat/Genetics/ASC-102Genes.xlsx\"\n",
    "ASC_102_DF_Autosomal = pd.read_excel(file_path, sheet_name=\"Autosomal\", skiprows=0)\n",
    "ASC_102_DF_Xlinked = pd.read_excel(file_path, sheet_name=\"ChrX\", skiprows=0)\n",
    "ASC_102_DF = pd.read_excel(file_path, sheet_name=\"102_ASD\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASC_102_DF = ASC_102_DF[[\"gene\", \"entrez_id\", \"dn.ptv\", \"dn.misa\", \"dn.misb\", \"qval_dnccPTV\"]]\n",
    "ASC_102_DF = ASC_102_DF[ASC_102_DF[\"entrez_id\"].notna()].copy()\n",
    "ASC_102_DF[\"entrez_id\"] = ASC_102_DF[\"entrez_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gamma columns from Autosomal or Xlinked dataframes\n",
    "# Combine the gamma columns from both dataframes (genes are either autosomal or X-linked)\n",
    "gamma_cols = [\"gamma_dn.ptv\", \"gamma_dn.misa\", \"gamma_dn.misb\"]\n",
    "gamma_df_auto = ASC_102_DF_Autosomal[[\"gene\"] + gamma_cols].copy()\n",
    "#gamma_df_x = ASC_102_DF_Xlinked[[\"gene\"] + gamma_cols].copy()\n",
    "\n",
    "# Concatenate both dataframes (genes appear in only one)\n",
    "#gamma_df_combined = pd.concat([gamma_df_auto, gamma_df_x], ignore_index=True)\n",
    "\n",
    "# Merge with ASC_102_DF to add gamma columns\n",
    "ASC_102_DF = ASC_102_DF.merge(\n",
    "    gamma_df_auto,\n",
    "    on=\"gene\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASC_102_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fu et al. 2022 USE BF for each mutation type as weight\n",
    "def GeneWeights_ASC_102(ASC_102_DF):\n",
    "    gene2MutN = {}\n",
    "    for i, row in ASC_102_DF.iterrows():\n",
    "        symbol = row[\"gene\"]\n",
    "        try:\n",
    "            g = GeneSymbol2Entrez[symbol]\n",
    "            entrez = row[\"entrez_id\"]\n",
    "            PR_LGD = ASC_102_DF.loc[i, \"gamma_dn.ptv\"]\n",
    "            PR_MisA = ASC_102_DF.loc[i, \"gamma_dn.misa\"]\n",
    "            PR_MisB = ASC_102_DF.loc[i, \"gamma_dn.misb\"]\n",
    "            if entrez not in gene2MutN:\n",
    "                gene2MutN[entrez] = 0\n",
    "            gene2MutN[entrez] += (\n",
    "                row[\"dn.ptv\"] * PR_LGD +\n",
    "                row[\"dn.misb\"] * PR_MisB +\n",
    "                row[\"dn.misa\"] * PR_MisA\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping gene {symbol} due to error: {e}\")\n",
    "    return gene2MutN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "GW_ASC_102 = GeneWeights_ASC_102(ASC_102_DF)\n",
    "Dict2Fil(GW_ASC_102, ProjDIR+\"/dat/Genetics/GeneWeights/GW_ASC_102.gw\")\n",
    "ASC_102_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW_ASC_102)\n",
    "ASC_102_STR_Bias[\"Region\"] = [Anno.get(ct_idx, \"Unknown\") for ct_idx in ASC_102_STR_Bias.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_structure_bias_correlation(Spark_ASD_STR_Bias, ASC_102_STR_Bias, label_a='Mutation Bias \\nZhou et al. 61 ASD genes', label_b='Mutation Bias \\nSatterstorm et al. 102 ASD genes', title='Structure Bias Comparison: Spark vs ASC_102')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Fu et al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/jw3514/Work/ASD_Circuits_CellType/dat/Genetics/Fu_et_al_2022.xlsx\"\n",
    "fu_DF_SSCASC = pd.read_excel(file_path, sheet_name=\"Supplementary Table 5\", skiprows=0)\n",
    "fu_DF_SPARK = pd.read_excel(file_path, sheet_name=\"Supplementary Table 6\", skiprows=0)\n",
    "fu_DF_TADA_PR = pd.read_excel(file_path, sheet_name=\"Supplementary Table 8\", skiprows=0)\n",
    "fu_DF_Pval = pd.read_excel(file_path, sheet_name=\"Supplementary Table 11\", skiprows=0)\n",
    "\n",
    "fu_DF_SSCASC = fu_DF_SSCASC[fu_DF_SSCASC[\"gene_id\"].notna()]\n",
    "fu_DF_SPARK = fu_DF_SPARK[fu_DF_SPARK[\"gene_id\"].notna()]\n",
    "fu_DF_Pval = fu_DF_Pval[fu_DF_Pval[\"gene_id\"].notna()]\n",
    "fu_DF_TADA_PR = fu_DF_TADA_PR[fu_DF_TADA_PR[\"gene_id\"].notna()]\n",
    "fu_DF_TADA_PR.set_index(\"gene_gencodeV33\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fu_ASD_72 = fu_DF_Pval[fu_DF_Pval[\"ASD72\"]==1]\n",
    "Fu_ASD_185 = fu_DF_Pval[fu_DF_Pval[\"ASD185\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fu et al. 2022 USE BF for each mutation type as weight\n",
    "def GeneWeights_Fu2022(DF_Filt, DF_PR, mut_DFs):\n",
    "    gene2MutN = {}\n",
    "    for DF in mut_DFs:\n",
    "        DF = DF[DF[\"gene_gencodeV33\"].isin(DF_Filt[\"gene_gencodeV33\"])]\n",
    "        \n",
    "        for i, row in DF.iterrows():\n",
    "            symbol = row[\"gene_gencodeV33\"]\n",
    "            try:\n",
    "                g = GeneSymbol2Entrez[symbol]\n",
    "                PR_LGD = DF_PR.loc[symbol, \"prior.dn.ptv\"]\n",
    "                PR_MisA = DF_PR.loc[symbol, \"prior.dn.misa\"]\n",
    "                PR_MisB = DF_PR.loc[symbol, \"prior.dn.misb\"]\n",
    "                if g not in gene2MutN:\n",
    "                    gene2MutN[g] = 0\n",
    "                gene2MutN[g] += (\n",
    "                    row[\"dn.ptv\"] * PR_LGD +\n",
    "                    row[\"dn.misb\"] * PR_MisB +\n",
    "                    row[\"dn.misa\"] * PR_MisA\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping gene {symbol} due to error: {e}\")\n",
    "    return gene2MutN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "GW_Fu_ASD_72 = GeneWeights_Fu2022(Fu_ASD_72, fu_DF_TADA_PR, [fu_DF_SSCASC, fu_DF_SPARK])\n",
    "GW_Fu_ASD_185 = GeneWeights_Fu2022(Fu_ASD_185, fu_DF_TADA_PR, [fu_DF_SSCASC, fu_DF_SPARK])\n",
    "Dict2Fil(GW_Fu_ASD_72, ProjDIR+\"/dat/Genetics/GeneWeights/GW_Fu_ASD_72.gw\")\n",
    "Dict2Fil(GW_Fu_ASD_185, ProjDIR+\"/dat/Genetics/GeneWeights/GW_Fu_ASD_185.gw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fu_ASD_72_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW_Fu_ASD_72)\n",
    "Fu_ASD_72_STR_Bias[\"Region\"] = [Anno.get(ct_idx, \"Unknown\") for ct_idx in Fu_ASD_72_STR_Bias.index.values]\n",
    "\n",
    "Fu_ASD_185_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW_Fu_ASD_185)\n",
    "Fu_ASD_185_STR_Bias[\"Region\"] = [Anno.get(ct_idx, \"Unknown\") for ct_idx in Fu_ASD_185_STR_Bias.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fu_ASD_72_STR_Bias.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fu_ASD_185_STR_Bias.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_structure_bias_correlation(Spark_ASD_STR_Bias, Spark_ASD_159_STR_Bias, label_a='Mutation Bias \\nZhou et al. 61 ASD genes', label_b='Mutation Bias \\nZhou et al. 159 ASD genes', title='Structure Bias Comparison: Spark vs Fu_ASD_72')\n",
    "plot_structure_bias_correlation(Spark_ASD_STR_Bias, Fu_ASD_72_STR_Bias, label_a='Mutation Bias \\nZhou et al. 61 ASD genes', label_b='Mutation Bias \\nFu et al. 72 ASD genes', title='Structure Bias Comparison: Spark vs Fu_ASD_72')\n",
    "plot_structure_bias_correlation(Spark_ASD_STR_Bias, Fu_ASD_185_STR_Bias, label_a='Mutation Bias \\nZhou et al. 61 ASD genes', label_b='Mutation Bias \\nFu et al. 185 ASD genes', title='Structure Bias Comparison: Spark vs Fu_ASD_185')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Neuron_den_norm_bias = pd.read_csv(\"../dat/Unionize_bias/ASD.neuron.density.norm.bias.csv\", \n",
    "                                      index_col=\"STR\")\n",
    "ASD_Glia_norm_bias = pd.read_csv(\"../dat/Unionize_bias/ASD.neuro2glia.norm.bias.csv\", \n",
    "                                      index_col=\"STR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_structure_bias_correlation(Spark_ASD_STR_Bias, ASD_Neuron_den_norm_bias, label_a='Mutation Bias \\nZhou et al. 61 ASD genes', label_b='Neuronal Density Normalized Bias\\nZhou et al. 61 ASD genes', title='Structure Bias Comparison: Spark vs Fu_ASD_72')\n",
    "plot_structure_bias_correlation(Spark_ASD_STR_Bias, ASD_Glia_norm_bias, label_a='Mutation Bias \\nZhou et al. 61 ASD genes', label_b='Neuro-to-Glia Ratio Normalized Bias\\nZhou et al. 61 ASD genes', title='Structure Bias Comparison: Spark vs Fu_ASD_185')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Male = pd.read_csv(\"../dat/Unionize_bias/ASD.Male.ALL.bias.csv\", \n",
    "                                      index_col=\"STR\")\n",
    "ASD_Female = pd.read_csv(\"../dat/Unionize_bias/ASD.Female.ALL.bias.csv\", \n",
    "                                      index_col=\"STR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_structure_bias_correlation(ASD_Male, ASD_Female, label_a='Male Mutation Bias\\nZhou et al. 61 ASD genes', label_b='Female Mutation Bias\\nZhou et al. 61 ASD genes', title='Structure Bias Comparison: Spark vs Fu_ASD_72')\n",
    "#plot_structure_bias_correlation(Spark_ASD_STR_Bias, ASD_Female, label_a='Mutation Bias \\nZhou et al. 61 ASD genes', label_b='Neuro-to-Glia Ratio Normalized Bias\\nZhou et al. 61 ASD genes', title='Structure Bias Comparison: Spark vs Fu_ASD_185')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoreMatDir=\"/home/jw3514/Work/ASD_Circuits/dat/allen-mouse-conn/ScoreingMat_jw_v3/\"\n",
    "IpsiInfoMat=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.csv\", index_col=0)\n",
    "IpsiInfoMatShort_v1=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.Short.3900.csv\", index_col=0)\n",
    "IpsiInfoMatLong_v1=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.Long.3900.csv\", index_col=0)\n",
    "\n",
    "DIR = \"/home/jw3514/Work/ASD_Circuits/scripts/RankScores/\"\n",
    "Cont_Distance = np.load(\"{}/RankScore.Ipsi.Cont.npy\".format(DIR))\n",
    "Cont_DistanceShort = np.load(\"{}/RankScore.Ipsi.Short.3900.Cont.npy\".format(DIR))\n",
    "Cont_DistanceLong = np.load(\"{}/RankScore.Ipsi.Long.3900.Cont.npy\".format(DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_circuit_scores_for_profiles(\n",
    "    profile_bias_dict,\n",
    "    topNs,\n",
    "    info_mats_dict,\n",
    "    scoring_func=ScoreCircuit_SI_Joint,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute circuit scores for multiple profiles and connection types.\n",
    "\n",
    "    Args:\n",
    "        profile_bias_dict: dict of {profile_name: STR_Bias DataFrame}\n",
    "        topNs: list of top N structure ranks to scan\n",
    "        info_mats_dict: dict of {conn_type: info_mat pandas DataFrame}\n",
    "        scoring_func: function (top_str_list, info_mat) => score\n",
    "\n",
    "    Returns:\n",
    "        results: dict of {profile_name: {conn_type: np.array of scores}}\n",
    "    \"\"\"\n",
    "    results = {profile_name: {conn_type: [] for conn_type in info_mats_dict}\n",
    "               for profile_name in profile_bias_dict}\n",
    "    for profile_name, bias_df in profile_bias_dict.items():\n",
    "        str_ranks = bias_df.sort_values(\"EFFECT\", ascending=False).index.values\n",
    "        for topN in topNs:\n",
    "            top_strs = str_ranks[:topN]\n",
    "            for conn_type, info_mat in info_mats_dict.items():\n",
    "                score = scoring_func(top_strs, info_mat)\n",
    "                results[profile_name][conn_type].append(score)\n",
    "    # Convert lists to np.arrays for easier plotting\n",
    "    for profile_name in results:\n",
    "        for conn_type in results[profile_name]:\n",
    "            results[profile_name][conn_type] = np.array(results[profile_name][conn_type])\n",
    "    return results\n",
    "\n",
    "def plot_circuit_connectivity_scores_multi(\n",
    "    topNs,\n",
    "    circuit_scores_results,\n",
    "    cont_distance_dict,\n",
    "    profile_plot_kwargs=None,\n",
    "    show_siblings=True,\n",
    "    profile_labels=None,\n",
    "    xlim=(0, 121)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot circuit connectivity scores for multiple profiles and connection types.\n",
    "    - circuit_scores_results: output of compute_circuit_scores_for_profiles\n",
    "    - cont_distance_dict: {conn_type: np.array [n_iter, len(topNs)]}\n",
    "    - profile_plot_kwargs: {profile_name: {kwargs for plt.plot}}\n",
    "    - profile_labels: {profile_name: label string}\n",
    "    \"\"\"\n",
    "    conn_types = list(cont_distance_dict.keys())\n",
    "    n_conn = len(conn_types)\n",
    "    fig, axes = plt.subplots(n_conn, 1, dpi=480, figsize=(7, 4*n_conn))\n",
    "\n",
    "    if n_conn == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    BarLen = 34.1\n",
    "\n",
    "    colors = [\"blue\", \"red\", \"purple\", \"orange\", \"green\", \"black\", \"brown\"]\n",
    "    if profile_plot_kwargs is None:\n",
    "        profile_plot_kwargs = {}\n",
    "    if profile_labels is None:\n",
    "        profile_labels = {}\n",
    "\n",
    "    for i, conn_type in enumerate(conn_types):\n",
    "        ax = axes[i]\n",
    "        cont = (np.median if not conn_type.lower().startswith(\"long\") else np.nanmean)(cont_distance_dict[conn_type], axis=0)\n",
    "        # Plot scores for all profiles\n",
    "        for idx, (profile_name, prof_scores) in enumerate(circuit_scores_results.items()):\n",
    "            scores = prof_scores[conn_type]\n",
    "            label = profile_labels.get(profile_name, profile_name)\n",
    "            plot_args = profile_plot_kwargs.get(profile_name, {})\n",
    "            if not plot_args:\n",
    "                # Generate plot styles dynamically\n",
    "                plot_args = dict(\n",
    "                    color=colors[idx % len(colors)],\n",
    "                    marker=[\"o\", \"s\", \"^\", \"d\", \"x\", \"v\"][idx % 6],\n",
    "                    markersize=5 if idx == 0 else 3,\n",
    "                    lw=1,\n",
    "                    ls='dashed' if idx == 0 else '-',\n",
    "                    label=label\n",
    "                )\n",
    "            ax.plot(topNs, scores, **plot_args)\n",
    "\n",
    "        # Plot Sibling controls\n",
    "        if show_siblings:\n",
    "            #if \"nan\" in str(type(cont_distance_dict[conn_type])):\n",
    "            lower = np.nanpercentile(cont_distance_dict[conn_type], 50-BarLen, axis=0)\n",
    "            upper = np.nanpercentile(cont_distance_dict[conn_type], 50+BarLen, axis=0)\n",
    "            #else:\n",
    "            #    lower = np.percentile(cont_distance_dict[conn_type], 50-BarLen, axis=0)\n",
    "            #    upper = np.percentile(cont_distance_dict[conn_type], 50+BarLen, axis=0)\n",
    "            ax.errorbar(\n",
    "                topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "                yerr=(cont - lower, np.abs(upper - cont)),\n",
    "                ls=\"dashed\", label=\"Siblings\"\n",
    "            )\n",
    "\n",
    "        ax.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "        ax.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "        ax.legend(fontsize=13)\n",
    "        ax.set_xlim(*xlim)\n",
    "        ax.grid(True)\n",
    "        ax.set_title(f'Connection Type: {conn_type}', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# -- USAGE EXAMPLE/INSTANTIATION --\n",
    "\n",
    "topNs = list(range(200, 5, -1))\n",
    "\n",
    "# Define profiles to use (easily reusable/extendable!)\n",
    "profiles = {\n",
    "    \"Fu_ASD_185\": Fu_ASD_185_STR_Bias,\n",
    "    \"Fu_ASD_72\": Fu_ASD_72_STR_Bias,\n",
    "    \"Spark 61\": Spark_ASD_STR_Bias,\n",
    "    \"Spark 159\": Spark_ASD_159_STR_Bias,\n",
    "    # \"Spark\": Spark_ASD_STR_Bias, # add more as needed\n",
    "}\n",
    "info_mats = {\n",
    "    \"Standard\": IpsiInfoMat,\n",
    "    \"Short\": IpsiInfoMatShort_v1,\n",
    "    \"Long\": IpsiInfoMatLong_v1,\n",
    "}\n",
    "cont_distance_dict = {\n",
    "    \"Standard\": Cont_Distance,\n",
    "    \"Short\": Cont_DistanceShort,\n",
    "    \"Long\": Cont_DistanceLong,\n",
    "}\n",
    "\n",
    "# Compute all\n",
    "circuit_scores = compute_circuit_scores_for_profiles(\n",
    "    profiles, topNs, info_mats\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig = plot_circuit_connectivity_scores_multi(\n",
    "    topNs,\n",
    "    circuit_scores,\n",
    "    cont_distance_dict,\n",
    "    profile_labels={\n",
    "        \"Fu_ASD_185\": \"185 genes (Fu_ASD_185)\",\n",
    "        \"Fu_ASD_72\": \"72 genes (Fu_ASD_72)\",\n",
    "    },\n",
    "    xlim=(0, 121)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# Try Spark Genelist with different number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark_Denovo_Stage1 = pd.read_excel(\"../dat/Genetics/41588_2022_1148_MOESM4_ESM.xlsx\",\n",
    "#                            skiprows=2, sheet_name=\"Table S6\")\n",
    "# Spark_Denovo_Stage1 = Spark_Denovo_Stage1[Spark_Denovo_Stage1[\n",
    "#     \"pDenovoWEST\"]!=\".\"]\n",
    "# Spark_Denovo_Stage1.shape\n",
    "\n",
    "Spark_Denovo_Stage1 = pd.read_excel(\"~/Work/SPARK2020/TabS_DenovoWEST_Stage1.xlsx\",\n",
    "                           skiprows=1, sheet_name=\"AllGenes\")\n",
    "Spark_Denovo_Stage1 = Spark_Denovo_Stage1[Spark_Denovo_Stage1[\"pDenovoWEST\"]!=\".\"]\n",
    "Spark_Denovo_Stage1.shape                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_Denovo_Stage1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_Bias_DF_list = []\n",
    "Spark_Bias_DF_list_Unif = []\n",
    "TopN_list = np.concatenate([np.arange(200, 2000, 100), np.arange(2000, 5000, 500)])  # Combine arrays properly\n",
    "\n",
    "for topN in TopN_list:\n",
    "    # This gets topN genes, but excludes the top 61 (i.e. gets genes ranked 62 to topN, like in ASC cell 21)\n",
    "    SPARK_ASD_topN = Spark_Denovo_Stage1.head(topN).iloc[61:]\n",
    "    GW_Unif, GW = SPARK_Gene_Weights(SPARK_ASD_topN)\n",
    "    SPARK_ASD_topN_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW)\n",
    "    SPARK_ASD_topN_STR_Bias_Unif = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW_Unif)\n",
    "    Spark_Bias_DF_list.append(SPARK_ASD_topN_STR_Bias)\n",
    "    Spark_Bias_DF_list_Unif.append(SPARK_ASD_topN_STR_Bias_Unif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_Bias_DF_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "def plot_correlation_profile_together(\n",
    "    TopN_list, \n",
    "    DF_list1, \n",
    "    DF_list2, \n",
    "    reference_df,\n",
    "    label1=\"Weighted\", \n",
    "    label2=\"Uniform\",\n",
    "    title=\"Correlation with Reference vs TopN\",\n",
    "    ylabel=\"Spearman r with Reference\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the correlation (Spearman r) of each DataFrame in the lists with the reference DataFrame over TopN_list.\n",
    "    Ensures that the structure (index) between each df and reference_df are matched before calculation.\n",
    "    \"\"\"\n",
    "    ref_effect = reference_df['EFFECT']\n",
    "    ref_index = reference_df.index\n",
    "\n",
    "    cors1 = []\n",
    "    for df in DF_list1:\n",
    "        # Align indices before comparing\n",
    "        df_matched = df.loc[df.index.intersection(ref_index)].copy()\n",
    "        ref_matched = ref_effect.loc[df_matched.index]\n",
    "        cors1.append(spearmanr(df_matched['EFFECT'], ref_matched).correlation)\n",
    "\n",
    "    cors2 = []\n",
    "    for df in DF_list2:\n",
    "        df_matched = df.loc[df.index.intersection(ref_index)].copy()\n",
    "        ref_matched = ref_effect.loc[df_matched.index]\n",
    "        cors2.append(spearmanr(df_matched['EFFECT'], ref_matched).correlation)\n",
    "    \n",
    "    plt.figure(figsize=(8, 5.5))\n",
    "    sns.set(style=\"whitegrid\", font_scale=1.25)\n",
    "    sns.lineplot(x=TopN_list, y=cors1, marker='o', linewidth=2.5, label=label1, color='royalblue')\n",
    "    sns.lineplot(x=TopN_list, y=cors2, marker='s', linewidth=2.5, label=label2, color='orange')\n",
    "    plt.xlabel(\"Number of Top ASD Genes (Excluding Top 61)\", fontsize=14)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    plt.title(title, fontsize=16, weight='bold')\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot correlation with reference (Spark_ASD_STR_Bias)\n",
    "plot_correlation_profile_together(\n",
    "    TopN_list,\n",
    "    Spark_Bias_DF_list,\n",
    "    Spark_Bias_DF_list_Unif,\n",
    "    reference_df=Spark_ASD_STR_Bias,\n",
    "    label1=\"Weighted\",\n",
    "    label2=\"Uniform\",\n",
    "    title=\"SPARK: Correlation (Spearman) with Top 61 Gene Structure Bias\",\n",
    "    ylabel=\"Spearman r with Top 61 Gene Structure Bias\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# Try ASC genelist with different number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fu_DF_Pval = fu_DF_Pval.sort_values(by=\"p_TADA_ASD\", ascending=True)\n",
    "fu_DF_Pval.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias_DF_list = []\n",
    "for topN in TopN_list:\n",
    "    # This gets topN genes, but excludes the top 72 (i.e. gets genes ranked 73 to topN)\n",
    "    Fu_ASD_topN = fu_DF_Pval.head(topN).iloc[72:]\n",
    "    GW_Fu_ASD_topN = GeneWeights_Fu2022(Fu_ASD_topN, fu_DF_TADA_PR, [fu_DF_SSCASC, fu_DF_SPARK])\n",
    "    Fu_ASD_topN_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW_Fu_ASD_topN)\n",
    "    Bias_DF_list.append(Fu_ASD_topN_STR_Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_correlation_vs_topn(TopN_list, Bias_DF_list, Fu_ASD_72_STR_Bias, reference_label=\"Top 72 (ASC)\", title=\"Correlation vs TopN_list (ASC)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test SCZ\n",
    "SCZ_GeneDF = pd.read_csv(\"/home/jw3514/Work/CellType_Psy/CellTypeBias_VIP/dat/SCZ.ALLGENE.MutCountModified.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Aggregate_Gene_Weights_SCZ_Daly(MutFil, allen_mouse_genes, usepLI=False, Bmis=False, out=None, mode=\"MC\", \n",
    "                                  lgd_weight=0.33, mis3_weight=0.27, mis2_weight=0.12):\n",
    "    print(\"New\")\n",
    "    assert mode in [\"OR\", \"MC\", \"ORMC\"]\n",
    "    print(mode)\n",
    "    gene2MutN = {}\n",
    "    for i, row in MutFil.iterrows():\n",
    "        try:\n",
    "            g = int(i)\n",
    "            if g not in allen_mouse_genes:\n",
    "                print(g, \"not in Expression dataset\")\n",
    "                continue\n",
    "        except:\n",
    "            print(g, \"Error converting Entrez ID\")\n",
    "        if usepLI:\n",
    "            try:\n",
    "                pLI = float(row[\"pLI\"])\n",
    "            except:\n",
    "                print(g, \"don't have pLI score on file, set to 0\")\n",
    "                pLI = 0.0\n",
    "            if pLI >= 0.5:\n",
    "                gene2MutN[g] = row[\"nLGD\"] * 0.26 + row[\"nMis3\"] * 0.25 + row[\"nMis2\"] * 0.06  \n",
    "            else:\n",
    "                gene2MutN[g] = row[\"nLGD\"] * 0.01 + row[\"nMis3\"] * 0.01 + row[\"nMis2\"] * 0 \n",
    "        else:\n",
    "            if mode == \"OR\":\n",
    "                gene2MutN[g] = row[\"LGD_OR\"] * lgd_weight + row[\"Mis3_OR\"] * mis3_weight + row[\"Mis2_OR\"] * mis2_weight\n",
    "            elif mode == \"MC\":\n",
    "                gene2MutN[g] = row[\"nLGD\"] * lgd_weight + row[\"nMis3\"] * mis3_weight + row[\"nMis2\"] * mis2_weight\n",
    "    if out != None:\n",
    "        writer = csv.writer(open(out, 'wt'))\n",
    "        for k,v in sorted(gene2MutN.items(), key=lambda x:x[1], reverse=True):\n",
    "           writer.writerow([k,v]) \n",
    "    return gene2MutN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "TopGeneToTeset = 100\n",
    "TopN_list2 = np.concatenate([np.arange(200, 1600, 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCZ_61GW = Aggregate_Gene_Weights_SCZ_Daly(SCZ_GeneDF.head(TopGeneToTeset), STR_BiasMat.index.values, mode=\"MC\", mis2_weight=0)\n",
    "SCZ_61_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, SCZ_61GW)\n",
    "SCZ_61_Bias.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCZ_Bias_DF_list = []\n",
    "for topN in TopN_list2:\n",
    "    # This gets topN genes, but excludes the top 72 (i.e. gets genes ranked 73 to topN)\n",
    "    SCZ_topN = SCZ_GeneDF.head(topN).iloc[TopGeneToTeset:]\n",
    "    GW_SCZ_topN = Aggregate_Gene_Weights_SCZ_Daly(SCZ_topN, STR_BiasMat.index.values, mode=\"MC\", usepLI=True, mis2_weight=0)\n",
    "    SCZ_topN_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW_SCZ_topN)\n",
    "    SCZ_Bias_DF_list.append(SCZ_topN_Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_Bias_DF_list = []\n",
    "for topN in TopN_list2:\n",
    "    # This gets topN genes, but excludes the top 61 (i.e. gets genes ranked 62 to topN, like in ASC cell 21)\n",
    "    SPARK_ASD_topN = Spark_Denovo_Stage1.head(topN).iloc[TopGeneToTeset:]\n",
    "    GW_Unif, GW = SPARK_Gene_Weights(SPARK_ASD_topN)\n",
    "    SPARK_ASD_topN_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW)\n",
    "    SPARK_ASD_topN_STR_Bias_Unif = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW_Unif)\n",
    "    Spark_Bias_DF_list.append(SPARK_ASD_topN_STR_Bias)\n",
    "    Spark_Bias_DF_list_Unif.append(SPARK_ASD_topN_STR_Bias_Unif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_ASD_topN = Spark_Denovo_Stage1.head(TopGeneToTeset)\n",
    "GW_Unif, GW = SPARK_Gene_Weights(SPARK_ASD_topN)\n",
    "SPARK_ASD_topN_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, GW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ASD Spark vs SCZ\n",
    "reference_df = SPARK_ASD_topN_STR_Bias   \n",
    "ref_effect = reference_df['EFFECT']\n",
    "ref_index = reference_df.index\n",
    "\n",
    "spearman_cors1 = []\n",
    "pearson_cors1 = []\n",
    "for df in Spark_Bias_DF_list:\n",
    "    # Align indices before comparing\n",
    "    df_matched = df.loc[df.index.intersection(ref_index)].copy()\n",
    "    ref_matched = ref_effect.loc[df_matched.index]\n",
    "    spearman_cors1.append(spearmanr(df_matched['EFFECT'], ref_matched).correlation)\n",
    "    pearson_cors1.append(pearsonr(df_matched['EFFECT'], ref_matched)[0])\n",
    "\n",
    "reference_df = SCZ_61_Bias   \n",
    "ref_effect = reference_df['EFFECT']\n",
    "ref_index = reference_df.index\n",
    "\n",
    "spearman_cors2 = []\n",
    "pearson_cors2 = []\n",
    "for df in SCZ_Bias_DF_list:\n",
    "    df_matched = df.loc[df.index.intersection(ref_index)].copy()\n",
    "    ref_matched = ref_effect.loc[df_matched.index]\n",
    "    spearman_cors2.append(spearmanr(df_matched['EFFECT'], ref_matched).correlation)\n",
    "    pearson_cors2.append(pearsonr(df_matched['EFFECT'], ref_matched)[0])\n",
    "\n",
    "plt.figure(figsize=(8, 5.5), dpi=300)\n",
    "sns.set(style=\"whitegrid\", font_scale=1.25)\n",
    "\n",
    "# Plot both Spearman and Pearson on same figure\n",
    "sns.lineplot(x=TopN_list2, y=spearman_cors1, marker='o', linewidth=2.5, label=\"ASD (Spearman)\", color='royalblue')\n",
    "sns.lineplot(x=TopN_list2, y=pearson_cors1, marker='o', linewidth=2.5, label=\"ASD (Pearson)\", color='darkblue', linestyle='--')\n",
    "\n",
    "sns.lineplot(x=TopN_list2, y=spearman_cors2, marker='s', linewidth=2.5, label=\"SCZ (Spearman)\", color='orange')\n",
    "sns.lineplot(x=TopN_list2, y=pearson_cors2, marker='s', linewidth=2.5, label=\"SCZ (Pearson)\", color='darkorange', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Number of Genes (Excluding Top 100 Genes)\", fontsize=14)\n",
    "plt.ylabel(\"StructureBias Correlation \\nwith Top 100 Genes\", fontsize=14)\n",
    "#plt.title(\"Spearman and Pearson Correlations with Reference Gene Sets\", fontsize=16, weight='bold')\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "# Top 20 Plus longtail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topN = 500 \n",
    "# SPARK_ASD_topN = Spark_Denovo_Stage1.head(topN).iloc[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_ASD_topN = Spark_Denovo_Stage1.head(20)\n",
    "GW_Unif, top_20_GW = SPARK_Gene_Weights(SPARK_ASD_topN)\n",
    "Dict2Fil(top_20_GW, ProjDIR+\"/dat/Genetics/GeneWeights/Spark_top20.gw\")\n",
    "SPARK_ASD_topN_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, top_20_GW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "Bias_DF_list = []\n",
    "save_dir = \"../results/Bootstrap_bias/Spark_top20_Random40/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "random_seed = 42  # Set a seed for reproducibility\n",
    "for i in range(1000):\n",
    "    # This gets topN genes, but excludes the top 72 (i.e. gets genes ranked 73 to topN)\n",
    "    Random_longtail_ASD_topN = Spark_Denovo_Stage1.head(500).iloc[20:].sample(n=41, random_state=random_seed + i)\n",
    "    _, GW_ASD_tmp = SPARK_Gene_Weights(Random_longtail_ASD_topN)\n",
    "    combined_dict = {**top_20_GW, **GW_ASD_tmp}\n",
    "    ASD_topN_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, combined_dict)\n",
    "\n",
    "    Bias_DF_list.append(ASD_topN_STR_Bias)\n",
    "\n",
    "    csv_path = os.path.join(save_dir, f\"bias_df_{i}.csv\")\n",
    "    ASD_topN_STR_Bias.to_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_topN_STR_Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark_ASD_STR_Bias\n",
    "# SPARK_ASD_topN_STR_Bias\n",
    "# Bias_DF_list\n",
    "\n",
    "# Compare structure correlation between Spark_ASD_STR_Bias and SPARK_ASD_topN_STR_Bias\n",
    "# Ensure structure indices are aligned\n",
    "print(\"Comparing Spark_ASD_STR_Bias vs SPARK_ASD_topN_STR_Bias\")\n",
    "print(f\"Spark_ASD_STR_Bias structures: {len(Spark_ASD_STR_Bias)}\")\n",
    "print(f\"SPARK_ASD_topN_STR_Bias structures: {len(SPARK_ASD_topN_STR_Bias)}\")\n",
    "\n",
    "# Find common structures\n",
    "common_structures = Spark_ASD_STR_Bias.index.intersection(SPARK_ASD_topN_STR_Bias.index)\n",
    "print(f\"Common structures: {len(common_structures)}\")\n",
    "\n",
    "# Plot correlation with aligned indices\n",
    "plot_structure_bias_correlation(\n",
    "    Spark_ASD_STR_Bias.loc[common_structures], \n",
    "    SPARK_ASD_topN_STR_Bias.loc[common_structures], \n",
    "    label_a='Mutation Bias\\nZhou et al. 61 ASD genes', \n",
    "    label_b='Mutation Bias\\nTop 20 ASD genes', \n",
    "    title='Structure Bias Comparison: Spark_ASD_STR_Bias vs SPARK_ASD_topN_STR_Bias'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SPARK_ASD_topN_STR_Bias with each sampling from Bias_DF_list\n",
    "# Ensure structure indices are aligned for correct bias correlation\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import numpy as np\n",
    "\n",
    "# Get common structures between SPARK_ASD_topN_STR_Bias and all DataFrames in Bias_DF_list\n",
    "ref_index = SPARK_ASD_topN_STR_Bias.index\n",
    "ref_effect = SPARK_ASD_topN_STR_Bias['EFFECT']\n",
    "\n",
    "# Compute correlations for each bootstrap sample\n",
    "pearson_cors = []\n",
    "spearman_cors = []\n",
    "\n",
    "print(f\"Reference (SPARK_ASD_topN_STR_Bias) has {len(ref_index)} structures\")\n",
    "print(f\"Computing correlations with {len(Bias_DF_list)} bootstrap samples...\")\n",
    "\n",
    "for i, df in enumerate(Bias_DF_list):\n",
    "    # Align indices - find common structures\n",
    "    common_idx = ref_index.intersection(df.index)\n",
    "    \n",
    "    if len(common_idx) == 0:\n",
    "        print(f\"Warning: No common structures found for bootstrap sample {i}\")\n",
    "        pearson_cors.append(np.nan)\n",
    "        spearman_cors.append(np.nan)\n",
    "        continue\n",
    "    \n",
    "    # Extract aligned EFFECT values\n",
    "    ref_aligned = ref_effect.loc[common_idx]\n",
    "    df_aligned = df.loc[common_idx, 'EFFECT']\n",
    "    \n",
    "    # Compute correlations\n",
    "    pearson_r, pearson_p = pearsonr(ref_aligned, df_aligned)\n",
    "    spearman_r, spearman_p = spearmanr(ref_aligned, df_aligned)\n",
    "    \n",
    "    pearson_cors.append(pearson_r)\n",
    "    spearman_cors.append(spearman_r)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(Bias_DF_list)} samples\")\n",
    "\n",
    "pearson_cors = np.array(pearson_cors)\n",
    "spearman_cors = np.array(spearman_cors)\n",
    "\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(f\"Pearson correlation - Mean: {np.nanmean(pearson_cors):.4f}, Std: {np.nanstd(pearson_cors):.4f}\")\n",
    "print(f\"Spearman correlation - Mean: {np.nanmean(spearman_cors):.4f}, Std: {np.nanstd(spearman_cors):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation distribution and print 95% CIs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate 95% confidence intervals for the correlations (ignoring NaNs)\n",
    "def correlation_CI(data, alpha=0.05):\n",
    "    data = data[~np.isnan(data)]\n",
    "    lower = np.percentile(data, 100 * (alpha / 2))\n",
    "    upper = np.percentile(data, 100 * (1 - alpha / 2))\n",
    "    return lower, upper\n",
    "\n",
    "pearson_ci_lower, pearson_ci_upper = correlation_CI(pearson_cors)\n",
    "spearman_ci_lower, spearman_ci_upper = correlation_CI(spearman_cors)\n",
    "\n",
    "print(f\"Pearson correlation 95% CI: [{pearson_ci_lower:.4f}, {pearson_ci_upper:.4f}]\")\n",
    "print(f\"Spearman correlation 95% CI: [{spearman_ci_lower:.4f}, {spearman_ci_upper:.4f}]\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), dpi=120)\n",
    "\n",
    "# Pearson correlation histogram\n",
    "axes[0].hist(pearson_cors, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0].axvline(np.nanmean(pearson_cors), color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: {np.nanmean(pearson_cors):.4f}')\n",
    "axes[0].axvline(pearson_ci_lower, color='green', linestyle=':', linewidth=2, label=f'95% CI: [{pearson_ci_lower:.2f}, {pearson_ci_upper:.2f}]')\n",
    "axes[0].axvline(pearson_ci_upper, color='green', linestyle=':', linewidth=2)\n",
    "axes[0].set_xlabel('Pearson Correlation', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Pearson Correlations\\nSPARK_ASD_topN_STR_Bias vs Bootstrap Samples', fontsize=13)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Spearman correlation histogram\n",
    "axes[1].hist(spearman_cors, bins=50, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[1].axvline(np.nanmean(spearman_cors), color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: {np.nanmean(spearman_cors):.4f}')\n",
    "axes[1].axvline(spearman_ci_lower, color='green', linestyle=':', linewidth=2, label=f'95% CI: [{spearman_ci_lower:.2f}, {spearman_ci_upper:.2f}]')\n",
    "axes[1].axvline(spearman_ci_upper, color='green', linestyle=':', linewidth=2)\n",
    "axes[1].set_xlabel('Spearman Correlation', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Distribution of Spearman Correlations\\nSPARK_ASD_topN_STR_Bias vs Bootstrap Samples', fontsize=13)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots for a few example bootstrap samples to visualize alignment\n",
    "# Select a few representative samples\n",
    "sample_indices = [0, 100, 500, 999]  # First, middle, and last samples\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12), dpi=120)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, sample_idx in enumerate(sample_indices):\n",
    "    if sample_idx >= len(Bias_DF_list):\n",
    "        continue\n",
    "    \n",
    "    df_sample = Bias_DF_list[sample_idx]\n",
    "    \n",
    "    # Align indices\n",
    "    common_idx = ref_index.intersection(df_sample.index)\n",
    "    ref_aligned = ref_effect.loc[common_idx]\n",
    "    sample_aligned = df_sample.loc[common_idx, 'EFFECT']\n",
    "    \n",
    "    # Compute correlation\n",
    "    pearson_r, pearson_p = pearsonr(ref_aligned, sample_aligned)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    ax.scatter(ref_aligned, sample_aligned, alpha=0.6, s=30, edgecolors='black', linewidth=0.3)\n",
    "    \n",
    "    # Add diagonal line\n",
    "    min_val = min(ref_aligned.min(), sample_aligned.min())\n",
    "    max_val = max(ref_aligned.max(), sample_aligned.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=1.5)\n",
    "    \n",
    "    # Format p-value\n",
    "    if pearson_p < 1e-10:\n",
    "        p_disp = f\"p <{1e-10:.0e}\"\n",
    "    else:\n",
    "        p_disp = f\"p ={pearson_p:.2g}\"\n",
    "    \n",
    "    ax.annotate(f'r = {pearson_r:.3f}\\n{p_disp}',\n",
    "                xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                ha='left', va='top', fontsize=11,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"w\", ec=\"gray\", alpha=0.8))\n",
    "    \n",
    "    ax.set_xlabel('SPARK_ASD_topN_STR_Bias (EFFECT)', fontsize=11)\n",
    "    ax.set_ylabel(f'Bootstrap Sample {sample_idx} (EFFECT)', fontsize=11)\n",
    "    ax.set_title(f'Bootstrap Sample {sample_idx}\\n{len(common_idx)} common structures', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gencic)",
   "language": "python",
   "name": "gencic"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
