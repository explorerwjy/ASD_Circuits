{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jw3514/Work/ASD_Circuits/src')\n",
    "from ASD_Circuits import *\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "InfoMat = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/InfoMat.Ipsi.csv\", index_col=0)\n",
    "adj_mat = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/WeightMat.Ipsi.csv\", index_col=0)\n",
    "\n",
    "InfoMat_short = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/InfoMat.Ipsi.short.csv\", index_col=0)\n",
    "\n",
    "InfoMat_long = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/InfoMat.Ipsi.long.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "code_folding": [
     57,
     82
    ]
   },
   "outputs": [],
   "source": [
    "def normtoUnit(x, xmin, xmax):\n",
    "    return (x-xmin)/(xmax-xmin)\n",
    "\n",
    "def searchFil(text, DIR):\n",
    "    #print(text)\n",
    "    RES = []\n",
    "    for file in os.listdir(DIR):\n",
    "        if text in file:\n",
    "            RES.append(file)\n",
    "    return RES\n",
    "\n",
    "def LoadSA3(fname, DIR, adj_mat, topL=100):\n",
    "    fin = open(DIR+fname, 'rt')\n",
    "    max_score, max_bias, max_STRs = 0, 0, []\n",
    "    for i, l in enumerate(fin):\n",
    "        if i > topL:\n",
    "            break\n",
    "        l = l.strip().split()\n",
    "        bias = float(l[1])\n",
    "        STRs = l[2].split(\",\")\n",
    "        score = ScoreCircuit_NEdges(STRs, adj_mat)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_bias = bias\n",
    "            max_STRs = STRs\n",
    "    return max_score, max_bias, max_STRs\n",
    "\n",
    "def GetData2(params, size, DIR, adj_mat):\n",
    "    SCORES, CutBias, RealBias, STRS = [],[],[],[]\n",
    "    for i, row in params.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        score, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat)\n",
    "        score = ScoreCircuit_NEdges(STRs, adj_mat)\n",
    "        if score == 0:\n",
    "            continue\n",
    "        SCORES.append(score)\n",
    "        CutBias.append(row[\"bias\"])\n",
    "        RealBias.append(real_minbias)\n",
    "        STRS.append(STRs)\n",
    "    return SCORES, CutBias, RealBias, STRS\n",
    "\n",
    "def XXXX_cont(BiasDF, BiasDF2, biaslim_df, size, DIR, adj_mat):\n",
    "    #fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, bias), DIR)[0]\n",
    "    SCORES, CutBias, RealBias, STRS = GetData2(biaslim_df, size, DIR, adj_mat)\n",
    "    New_RealBias = []\n",
    "    for STRSET in STRS:\n",
    "        xx = BiasDF.loc[STRSET, \"EFFECT\"].mean()\n",
    "        New_RealBias.append(xx)\n",
    "    # Add top size STRs\n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_NEdges(topNSTRs, adj_mat)\n",
    "    SCORES.append(score)\n",
    "    CutBias.append(bias)\n",
    "    New_RealBias.append(bias)\n",
    "    STRS.append(topNSTRs)    \n",
    "    return SCORES, CutBias, New_RealBias, STRS\n",
    "\n",
    "def search_target_swap(size, BiasDF, NSwap, biaslim_df, adj_mat, \n",
    "                       ProbMat1, ProbMat1_short, ProbMat1_long, \n",
    "                       ProbMat2, ProbMat2_short, ProbMat2_long, DIR):\n",
    "    # TopN targets \n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_v7(topNSTRs, adj_mat, ProbMat1, ProbMat2)\n",
    "    # search along the profile\n",
    "    for i, row in biaslim_df.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        cohe, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat, ProbMat1, ProbMat2)\n",
    "        score = ScoreCircuit_v7(STRs, adj_mat, ProbMat1, ProbMat2)\n",
    "\n",
    "        bias = BiasDF.loc[STRs, \"EFFECT\"].mean()\n",
    "        NDiff = len(set(STRs).difference(topNSTRs))\n",
    "        if abs(NDiff-NSwap) < 2:\n",
    "\n",
    "            score1 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_short, ProbMat2_short)\n",
    "            score2 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_long, ProbMat2_long)\n",
    "            if score > 0.714:\n",
    "                #print(RegionDistributionsList(STRs))\n",
    "                print(score, score1, score2)\n",
    "            return bias, score, score1, score2\n",
    "    return None, None, None, None\n",
    "\n",
    "def search_target_swap2(size, BiasDF, biaslim, biaslim_df, adj_mat, \n",
    "                       ProbMat1, ProbMat1_short, ProbMat1_long, \n",
    "                       ProbMat2, ProbMat2_short, ProbMat2_long, DIR):\n",
    "    # TopN targets \n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_v7(topNSTRs, adj_mat, ProbMat1, ProbMat2)\n",
    "    # search along the profile\n",
    "    for i, row in biaslim_df.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        cohe, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat, ProbMat1, ProbMat2)\n",
    "        score = ScoreCircuit_v7(STRs, adj_mat, ProbMat1, ProbMat2)\n",
    "\n",
    "        bias = BiasDF.loc[STRs, \"EFFECT\"].mean()\n",
    "        #print(round(real_minbias,3), biaslim)\n",
    "        if round(real_minbias,3) == biaslim:\n",
    "            score1 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_short, ProbMat2_short)\n",
    "            score2 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_long, ProbMat2_long)\n",
    "            if score2 > 0.673:\n",
    "                #print()\n",
    "                print(RegionDistributionsList(STRs))\n",
    "            return bias, score, score1, score2\n",
    "    return None, None, None, None\n",
    "\n",
    "def LoadProfiles(BiasDF, BiasDF2, biaslim_df, size, DIR, adj_mat):\n",
    "    Scores, CutBias, RealBias, STRS = GetData2(biaslim_df, size, DIR, adj_mat)\n",
    "    # Add top size STRs\n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF2.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_NEdges(topNSTRs, adj_mat)\n",
    "    Scores.append(score)\n",
    "    CutBias.append(bias)\n",
    "    RealBias.append(bias)\n",
    "    STRS.append(topNSTRs)    \n",
    "    return Scores, CutBias, RealBias, STRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 46\n",
    "#biaslim_df = pd.read_csv(biaslim_dir + \"biaslim.size.{}.txt\".format(size), names=[\"size\", \"bias\"])\n",
    "ASD_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Circuits/SA/ASD_Pareto_Conn_Size46/\"\n",
    "ASD_BiasDF = pd.read_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.csv\", index_col=\"STR\")\n",
    "biaslim_df = pd.read_csv(\n",
    "    \"../dat/Circuits/SA/biaslims2/biaslim.size.46.top17.txt\", names=[\"size\", \"bias\"])\n",
    "COHESPeak, CutBiasPeak, RealBiasPeak, STRSPeak = LoadProfiles(ASD_BiasDF, ASD_BiasDF, biaslim_df, size, \n",
    "                                              ASD_DIR, adj_mat)\n",
    "ASD_DFPeak = pd.DataFrame(data={\"Cohe\":COHESPeak, \"minBias\":CutBiasPeak, \"Bias\":RealBiasPeak})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RegionDistributionsList(STRSPeak[-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "biaslim_df = pd.read_csv(\n",
    "    \"../dat/Circuits/SA/biaslims2/biaslim.size.46.top17.txt\", names=[\"size\", \"bias\"])\n",
    "\n",
    "SIB_SA_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Circuits/SA/SubSib_Score_Conn_Nov_2023/\"\n",
    "SIB_BIAS_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Unionize_bias/SubSampleSib/\"\n",
    "\n",
    "dat_score = []\n",
    "dat_bias = []\n",
    "\n",
    "for i, file in enumerate(os.listdir(SIB_SA_DIR)):\n",
    "    #try:\n",
    "    d = os.path.join(SIB_SA_DIR, file)\n",
    "    if os.path.isdir(d):\n",
    "        biasdf = SIB_BIAS_DIR + file + \".csv\"\n",
    "        Sib_BiasDF = pd.read_csv(biasdf, index_col=\"STR\")\n",
    "\n",
    "            \n",
    "        try:\n",
    "            ASD_cont_Dir = SIB_SA_DIR + file + \"/\"\n",
    "            COHES55, CutBias55, RealBias55, STRS55 = XXXX_cont(Sib_BiasDF, ASD_BiasDF, biaslim_df, size, \n",
    "                                                          ASD_cont_Dir, adj_mat)\n",
    "            dat_score.append(COHES55)\n",
    "            dat_bias.append(RealBias55)\n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_score = np.array(dat_score)\n",
    "dat_score_flat = dat_score.flatten()\n",
    "dat_bias = np.array(dat_bias)\n",
    "dat_bias_flat = dat_bias.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sib_DF55 = pd.DataFrame(data={\"SI score\":dat_score_flat, \"Bias\":dat_bias_flat})\n",
    "Sib_DF55.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = []\n",
    "for bias, score in zip(dat_bias, dat_score):\n",
    "    meanbias = np.mean(bias)\n",
    "    meanscore = np.mean(score)\n",
    "    meantotal = meanbias + meanscore\n",
    "    profiles.append([meanbias, meanscore, meantotal, bias, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_bias = sorted(profiles, key = lambda x:x[0], reverse=True)\n",
    "rank_score = sorted(profiles, key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "topbias = []\n",
    "for i in range(len(profiles)):\n",
    "    topbias.append((rank_bias[i][4], rank_bias[i][3]))\n",
    "topbias = np.array(topbias)\n",
    "topSI = []\n",
    "for i in range(len(profiles)):\n",
    "    topSI.append((rank_score[i][4], rank_score[i][3]))\n",
    "topSI = np.array(topSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "topbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample subsample sibs\n",
    "rand_indexes = np.random.randint(0, topbias.shape[0], 480)\n",
    "topbias_sub = topbias[rand_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanbias = []\n",
    "meanSI = []\n",
    "xerr = []\n",
    "yerr = []\n",
    "for i in range(topbias.shape[2]):\n",
    "    meanbias.append(topbias[:,1,i].mean())\n",
    "    meanSI.append(topbias[:,0,i].mean())\n",
    "    xerr.append(topbias[:,0,i].std())\n",
    "    yerr.append(topbias[:,1,i].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=120, figsize=(10,6))\n",
    "\n",
    "ax.plot(ASD_DFPeak[\"Cohe\"].values, ASD_DFPeak[\"Bias\"].values, marker=\".\", color=\"#542788\",  lw=3, markersize=12,\n",
    "             ls = \"--\", label=\"ASD\")\n",
    "ax.scatter(ASD_DFPeak[\"Cohe\"].values[-4], ASD_DFPeak[\"Bias\"].values[-4], marker=\"x\", s=70, color=\"red\", lw=2,\n",
    "           zorder=100, label=\"Selected Circuits\")\n",
    "\n",
    "N=5200\n",
    "#plt.plot(topbias[:N,0,:].T, topbias[:N,1,:].T, marker=\".\", color=\"grey\",\n",
    "#             ls = \"--\", alpha=0.1, label=\"subsampled siblings\")\n",
    "ax.plot(topbias_sub[:,0,:].T, topbias_sub[:,1,:].T, marker=\".\", color=\"#fee0b6\", markersize=3, lw=1,\n",
    "             ls = \"--\", alpha=0.4)\n",
    "ax.plot(topbias_sub[0,0,:].T, topbias_sub[0,1,:].T, marker=\".\", color=\"#fee0b6\", markersize=3, lw=1,\n",
    "             ls = \"--\", alpha=0.4, label=\"subsampled siblings\")\n",
    "\n",
    "ax.plot(meanSI, meanbias, marker=\".\", color=\"#b35806\", lw=3, markersize=12,\n",
    "             ls = \"--\", alpha=1, label=\"mean profile of \\nsubsampled siblings\")\n",
    "\n",
    "\n",
    "#handles, labels = plt.gca().get_legend_handles_labels()\n",
    "#labels, ids = np.unique(labels, return_index=True)\n",
    "#handles = [handles[i] for i in ids]\n",
    "#plt.legend(handles, labels, loc='best')\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.9))\n",
    "\n",
    "plt.xlabel(\"Circuit Score (Connectivity)\", fontsize=14)\n",
    "plt.ylabel(\"Average Mutation Bias\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Distance graph with conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "##### Load diatance related function and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "code_folding": [
     0,
     16,
     44
    ]
   },
   "outputs": [],
   "source": [
    "def MaskDistMat(Mat1, Mat2, cutoff, m='lt'):\n",
    "    New_Mat2 = Mat2.copy(deep=True)\n",
    "    for STR_i in Mat1.index.values:\n",
    "        for STR_j in Mat1.columns.values:\n",
    "            if m == 'gt':\n",
    "                if Mat1.loc[STR_i, STR_j] >= cutoff:\n",
    "                    New_Mat2.loc[STR_i, STR_j] = 0\n",
    "                else:\n",
    "                    New_Mat2.loc[STR_i, STR_j] = Mat2.loc[STR_i, STR_j]\n",
    "            elif m == \"lt\":\n",
    "                if Mat1.loc[STR_i, STR_j] <= cutoff:\n",
    "                    New_Mat2.loc[STR_i, STR_j] = 0\n",
    "                else:\n",
    "                    New_Mat2.loc[STR_i, STR_j] = Mat2.loc[STR_i, STR_j]\n",
    "    return New_Mat2\n",
    "\n",
    "def MaskDistMat_xx(distance_mat, Conn_mat, cutoff, cutoff2, keep='gt'):\n",
    "    Conn_mat_new = Conn_mat.copy(deep=True)\n",
    "    distance_mat_new = distance_mat.copy(deep=True)\n",
    "    for STR_i in distance_mat.index.values:\n",
    "        for STR_j in distance_mat.columns.values:\n",
    "            if keep == 'gt':\n",
    "                if distance_mat.loc[STR_i, STR_j] >= cutoff:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = Conn_mat.loc[STR_i, STR_j]\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = distance_mat.loc[STR_i, STR_j]\n",
    "                else:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = 0\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = 0\n",
    "            elif keep == \"lt\":\n",
    "                if distance_mat.loc[STR_i, STR_j] <= cutoff:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = Conn_mat.loc[STR_i, STR_j]\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = distance_mat.loc[STR_i, STR_j]\n",
    "                else:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = 0\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = 0   \n",
    "            elif keep==\"bw\":\n",
    "                if distance_mat.loc[STR_i, STR_j] >= cutoff and distance_mat.loc[STR_i, STR_j] <= cutoff2:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = Conn_mat.loc[STR_i, STR_j]\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = distance_mat.loc[STR_i, STR_j]\n",
    "                else:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = 0\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = 0   \n",
    "    return Conn_mat_new, distance_mat_new\n",
    "\n",
    "def MaskDistMat_xy(distance_mat, Conn_mat, cutoff, cutoff2, keep='gt'):\n",
    "    Conn_mat_new = Conn_mat.copy(deep=True)\n",
    "    distance_mat_new = distance_mat.copy(deep=True)\n",
    "    for STR_i in distance_mat.index.values:\n",
    "        for STR_j in distance_mat.columns.values:\n",
    "            if STR_i == STR_j:\n",
    "                Conn_mat_new.loc[STR_i, STR_j] = 0\n",
    "                distance_mat_new.loc[STR_i, STR_j] = 0\n",
    "                continue\n",
    "            if keep == 'gt':\n",
    "                if distance_mat.loc[STR_i, STR_j] >= cutoff:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = Conn_mat.loc[STR_i, STR_j]\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = distance_mat.loc[STR_i, STR_j]\n",
    "                else:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = 0\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = 0\n",
    "            elif keep == \"lt\":\n",
    "                if distance_mat.loc[STR_i, STR_j] <= cutoff:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = Conn_mat.loc[STR_i, STR_j]\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = distance_mat.loc[STR_i, STR_j]\n",
    "                else:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = 0\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = 0\n",
    "            elif keep==\"bw\":\n",
    "                if distance_mat.loc[STR_i, STR_j] >= cutoff and distance_mat.loc[STR_i, STR_j] <= cutoff2:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = Conn_mat.loc[STR_i, STR_j]\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = distance_mat.loc[STR_i, STR_j]\n",
    "                else:\n",
    "                    Conn_mat_new.loc[STR_i, STR_j] = 0\n",
    "                    distance_mat_new.loc[STR_i, STR_j] = 0\n",
    "    return Conn_mat_new, distance_mat_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/WeightMat.Ipsi.csv\", index_col=0)\n",
    "dist_mat = pd.read_csv(\"../dat/allen-mouse-conn/Dist_CartesianDistance.ipsi.csv\", index_col=0)\n",
    "dist_mat.columns = dist_mat.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cartesian_distances_w_edge = MaskDistMat(adj_mat, dist_mat, cutoff=0)\n",
    "#Distance_Cuts = [0, 1000, 2000, 3000, 4000, 5000, 100000]\n",
    "Distance_Cuts = [0, 1000, 2000, 3000, 4000, 100000]\n",
    "\n",
    "N_Connections_total = []\n",
    "N_Pairs_total = []\n",
    "Cutted_DistMat = {}\n",
    "Cutted_AdjMat = {}\n",
    "for i, cut in enumerate(Distance_Cuts[:-1]):\n",
    "    Conn_mat_new, distance_mat_new = MaskDistMat_xy(dist_mat, adj_mat, keep=\"bw\",\n",
    "                                                cutoff=Distance_Cuts[i], cutoff2=Distance_Cuts[i+1])\n",
    "    Cutted_DistMat[i] = distance_mat_new\n",
    "    Cutted_AdjMat[i] = Conn_mat_new\n",
    "    N_Connections_total.append(np.count_nonzero(Conn_mat_new))\n",
    "    N_Pairs_total.append(np.count_nonzero(distance_mat_new))\n",
    "N_Connections_total = np.array(N_Connections_total)\n",
    "N_Pairs_total = np.array(N_Pairs_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "##### Load ASD and sib data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normtoUnit(x, xmin, xmax):\n",
    "    return (x-xmin)/(xmax-xmin)\n",
    "\n",
    "def searchFil(text, DIR):\n",
    "    RES = []\n",
    "    for file in os.listdir(DIR):\n",
    "        if text in file:\n",
    "            RES.append(file)\n",
    "    return RES\n",
    "\n",
    "def LoadSA3(fname, DIR, adj_mat, topL=100):\n",
    "    fin = open(DIR+fname, 'rt')\n",
    "    max_score, max_bias, max_STRs = 0, 0, []\n",
    "    for i, l in enumerate(fin):\n",
    "        if i > topL:\n",
    "            break\n",
    "        l = l.strip().split()\n",
    "        bias = float(l[1])\n",
    "        STRs = l[2].split(\",\")\n",
    "        score = ScoreCircuit_NEdges(STRs, adj_mat)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_bias = bias\n",
    "            max_STRs = STRs\n",
    "    return max_score, max_bias, max_STRs\n",
    "\n",
    "def GetData2(params, size, DIR, adj_mat):\n",
    "    SCORES, CutBias, RealBias, STRS = [],[],[],[]\n",
    "    for i, row in params.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        score, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat)\n",
    "        score = ScoreCircuit_NEdges(topNSTRs, adj_mat)\n",
    "        if score == 0:\n",
    "            continue\n",
    "        SCORES.append(score)\n",
    "        CutBias.append(row[\"bias\"])\n",
    "        RealBias.append(real_minbias)\n",
    "        STRS.append(STRs)\n",
    "    return SCORES, CutBias, RealBias, STRS\n",
    "\n",
    "def ExtractSibSTR(bias_cut, DIR, adj_mat):\n",
    "    fil = searchFil(\"topN_121-keepN_46-minbias_{}.txt\".format(bias_cut), DIR)[0]\n",
    "    score, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat) \n",
    "    return STRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "biaslim_df = pd.read_csv(\n",
    "    \"../dat/Circuits/SA/biaslims2/biaslim.size.46.top17.txt\", names=[\"size\", \"bias\"])\n",
    "adj_mat = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/WeightMat.Ipsi.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_STR_Bias = pd.read_csv(\"../../ASD_Circuits/dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.csv\", \n",
    "                           index_col=\"STR\")\n",
    "ASD_Circuits = STRSPeak[-4]\n",
    "ASD_Connections = []\n",
    "ASD_Pairs = []\n",
    "for i,v in enumerate(Distance_Cuts[:-1]):\n",
    "    adj_mat_ = Cutted_AdjMat[i]\n",
    "    dist_mat_ = Cutted_DistMat[i]\n",
    "    adj_mat_asd = adj_mat_.loc[ASD_Circuits,ASD_Circuits]\n",
    "    dist_mat_asd = dist_mat_.loc[ASD_Circuits,ASD_Circuits]\n",
    "    Nconn = np.count_nonzero(adj_mat_asd)\n",
    "    Npair = np.count_nonzero(dist_mat_asd)\n",
    "    ASD_Connections.append(Nconn)\n",
    "    ASD_Pairs.append(Npair)\n",
    "ASD_Connections = np.array(ASD_Connections)\n",
    "ASD_Pairs = np.array(ASD_Pairs)\n",
    "print(ASD_STR_Bias.loc[ASD_Circuits, \"EFFECT\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_cut = 0.37\n",
    "Sib_Cir_STRs = []\n",
    "for i, file in enumerate(os.listdir(SIB_SA_DIR)):\n",
    "    d = os.path.join(SIB_SA_DIR, file)\n",
    "    if os.path.isdir(d):\n",
    "        try:\n",
    "            ASD_cont_Dir = SIB_SA_DIR + file + \"/\"\n",
    "            Sib_CirSTR = ExtractSibSTR(bias_cut, ASD_cont_Dir, adj_mat)\n",
    "            Sib_Cir_STRs.append(Sib_CirSTR)\n",
    "        except:\n",
    "            continue\n",
    "    #if i > 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Sib_Cir_STRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsib_connections = []\n",
    "subsib_Pairs = []\n",
    "Sim_dir = \"../dat/Unionize_bias/SubSampleSib//\"\n",
    "for i, _SibSTRs in enumerate(Sib_Cir_STRs):\n",
    "    _SIB_Connections = []\n",
    "    _SIB_Pairs = []\n",
    "    for i,v in enumerate(Distance_Cuts[:-1]):\n",
    "        adj_mat_ = Cutted_AdjMat[i]\n",
    "        dist_mat_ = Cutted_DistMat[i]\n",
    "        adj_mat_sib = adj_mat_.loc[_SibSTRs,_SibSTRs]\n",
    "        dist_mat_sib = dist_mat_.loc[_SibSTRs,_SibSTRs]\n",
    "        Nconn = np.count_nonzero(adj_mat_sib)\n",
    "        Npair = np.count_nonzero(dist_mat_sib)\n",
    "        _SIB_Connections.append(Nconn)\n",
    "        _SIB_Pairs.append(Npair)\n",
    "    subsib_connections.append(_SIB_Connections)\n",
    "    subsib_Pairs.append(_SIB_Pairs)\n",
    "subsib_connections = np.array(subsib_connections)\n",
    "subsib_Pairs = np.array(subsib_Pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsib_connections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsib_conns_mean =  np.mean(subsib_connections, axis=0)\n",
    "subsib_conns_std =  np.std(subsib_connections, axis=0)\n",
    "subsib_pairs_mean =  np.mean(subsib_Pairs, axis=0)\n",
    "subsib_pairs_std =  np.std(subsib_Pairs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for asd, sibs in zip(ASD_Connections, subsib_connections.T):\n",
    "    #print(asd, len(sibs))\n",
    "    z,p = GetPermutationP(sibs, asd)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance of connection enrichment:\n",
    "for asd, sibs in zip(ASD_Connections, subsib_connections.T):\n",
    "    #print(asd, len(sibs))\n",
    "    #z,p = GetPermutationP(sibs, asd)\n",
    "    #print(p)\n",
    "    print(np.mean(sibs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance of connection pairs:\n",
    "for asd, sibs in zip(ASD_Pairs, subsib_Pairs.T):\n",
    "    #print(asd, len(sibs))\n",
    "    z,p = GetPermutationP(sibs, asd)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance of fc:\n",
    "norm = N_Connections_total/N_Pairs_total\n",
    "for asd, sibs in zip(ASD_Connections/ASD_Pairs / norm, (subsib_connections/subsib_Pairs / norm).T):\n",
    "    #print(asd, len(sibs))\n",
    "    z,p = GetPermutationP(sibs, asd)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = 3\n",
    "CaseGroup1 = np.sum(ASD_Connections[:split_idx])/np.sum(N_Connections_total[:split_idx])\n",
    "CaseGroup2 = np.sum(ASD_Connections[split_idx:])/np.sum(N_Connections_total[split_idx:])\n",
    "CtrlGroup1 = np.sum(subsib_connections[:, :split_idx], axis=1)/np.sum(N_Connections_total[:split_idx])\n",
    "CtrlGroup2 = np.sum(subsib_connections[:, split_idx:], axis=1)/np.sum(N_Connections_total[split_idx:])\n",
    "\n",
    "# significance of fc:\n",
    "z,p = GetPermutationP(CtrlGroup1, CaseGroup1)\n",
    "print(p)\n",
    "\n",
    "z,p = GetPermutationP(CtrlGroup2, CaseGroup2)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = 3\n",
    "CaseGroup1 = np.sum(ASD_Connections[:split_idx])/np.sum(ASD_Pairs[:split_idx])/np.sum(N_Connections_total[:split_idx]/N_Pairs_total[:split_idx])\n",
    "CaseGroup2 = np.sum(ASD_Connections[split_idx:])/np.sum(ASD_Pairs[split_idx:])/np.sum(N_Connections_total[split_idx:]/N_Pairs_total[split_idx:])\n",
    "CtrlGroup1 = np.sum(subsib_connections[:, :split_idx], axis=1)/np.sum(subsib_Pairs[:, :split_idx], axis=1)/np.sum(N_Connections_total[:split_idx]/N_Pairs_total[:split_idx])\n",
    "CtrlGroup2 = np.sum(subsib_connections[:, split_idx:], axis=1)/np.sum(subsib_Pairs[:, split_idx:], axis=1)/np.sum(N_Connections_total[split_idx:]/N_Pairs_total[split_idx:])\n",
    "\n",
    "# significance of fc:\n",
    "z,p = GetPermutationP(CtrlGroup1, CaseGroup1)\n",
    "print(p)\n",
    "\n",
    "z,p = GetPermutationP(CtrlGroup2, CaseGroup2)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.ticker as mticker  \n",
    "plt.style.use('seaborn-talk')\n",
    "matplotlib.rcParams.update({'font.size': 25})\n",
    "fig, ax = plt.subplots(dpi=480, figsize=(6,6))\n",
    "\n",
    "ax.plot(np.arange(5), ASD_Connections/N_Connections_total, marker=\"o\" , color=\"blue\", label=\"ASD Circuits\")\n",
    "#ax.plot(np.arange(6) + 0.05, SIB_Connections/N_Connections_total, marker=\"o\", color=\"orange\", label=\"Sibling Circuits\")\n",
    "ax.errorbar(np.arange(5) + 0.05, \n",
    "                 subsib_conns_mean/N_Connections_total, \n",
    "                 yerr= np.nanstd(subsib_connections/N_Connections_total, axis=0), #subsib_conns_std/N_Connections_total,\n",
    "                 marker=\"o\", color=\"grey\", label=\"Siblings Circuits\",)\n",
    "\n",
    "ax.grid(True)\n",
    "ax.legend(loc=\"lower left\", fontsize=17)\n",
    "ax.set_ylabel(\"Connection Density\", fontsize=25)\n",
    "ax.set_xlabel(r\"Distance range (mm)\", fontsize=20)\n",
    "#ax.set_xticklabels([\"\", \"0-1\", \"1-2\", \"2-3\", \"3-4\", \"4-5\", r\">5\"], fontsize=20)\n",
    "ax.set_xticklabels([\"\", \"0-1\", \"1-2\", \"2-3\", \"3-4\", r\">4\"], fontsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "#ax.set_ylim(0, 0.17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=480, figsize=(6,6))\n",
    "norm = N_Connections_total/N_Pairs_total\n",
    "ax.plot(np.arange(5), ASD_Connections/ASD_Pairs / norm , marker=\"o\" , color=\"blue\", label=\"ASD Circuits\")\n",
    "#ax.plot(np.arange(6) + 0.05, SIB_Connections/SIB_Pairs / norm, marker=\"o\", color=\"orange\", label=\"Sibling Circuits\")\n",
    "ax.errorbar(np.arange(5) + 0.05, \n",
    "                 subsib_conns_mean/subsib_pairs_mean / norm, \n",
    "                 yerr= np.nanstd(subsib_connections/subsib_Pairs/norm, axis=0),\n",
    "                 marker=\"o\", color=\"grey\", label=\"Siblings Circuits\")\n",
    "\n",
    "ax.grid(True)\n",
    "ax.legend(loc=\"upper left\", fontsize=17)\n",
    "ax.set_ylabel(\"Connection Likelihood Ratio\", fontsize=25)\n",
    "ax.set_xlabel(r\"Distance range (mm)\", fontsize=20)\n",
    "#ax.set_xticklabels([\"\", \"0-1\", \"1-2\", \"2-3\", \"3-4\", \"4-5\", r\">5\"], fontsize=20)\n",
    "ax.set_xticklabels([\"\", \"0-1\", \"1-2\", \"2-3\", \"3-4\", r\">4\"], fontsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "#plt.gca().xaxis.set_major_formatter(mticker.FormatStrFormatter('%s x1000'))\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
