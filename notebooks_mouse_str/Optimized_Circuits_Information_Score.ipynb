{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jw3514/Work/ASD_Circuits/src')\n",
    "from ASD_Circuits import *\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "InfoMat = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/InfoMat.Ipsi.csv\", index_col=0)\n",
    "adj_mat = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/WeightMat.Ipsi.csv\", index_col=0)\n",
    "\n",
    "InfoMat_short = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/InfoMat.Ipsi.short.csv\", index_col=0)\n",
    "\n",
    "InfoMat_long = pd.read_csv(\"../dat/allen-mouse-conn/ScoreingMat_jw_v3/InfoMat.Ipsi.long.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "code_folding": [
     60,
     85
    ]
   },
   "outputs": [],
   "source": [
    "def normtoUnit(x, xmin, xmax):\n",
    "    return (x-xmin)/(xmax-xmin)\n",
    "\n",
    "def searchFil(text, DIR):\n",
    "    RES = []\n",
    "    for file in os.listdir(DIR):\n",
    "        if text in file:\n",
    "            RES.append(file)\n",
    "    return RES\n",
    "\n",
    "def LoadSA3(fname, DIR, InfoMat, minbias, topL=100):\n",
    "    fin = open(DIR+fname, 'rt')\n",
    "    max_score, max_bias, max_STRs = 0, 0, []\n",
    "    for i, l in enumerate(fin):\n",
    "        if i > topL:\n",
    "            break\n",
    "        l = l.strip().split()\n",
    "        bias = float(l[1])\n",
    "        if bias < minbias:\n",
    "            continue\n",
    "        STRs = l[2].split(\",\")\n",
    "        score = ScoreCircuit_SI_Joint(STRs, InfoMat)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_bias = bias\n",
    "            max_STRs = STRs\n",
    "    return max_score, max_bias, max_STRs\n",
    "\n",
    "def GetData2(params, size, DIR, adj_mat, InfoMat):\n",
    "    SCORES, CutBias, RealBias, STRS = [],[],[],[]\n",
    "    for i, row in params.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        score, real_minbias, STRs = LoadSA3(fil, DIR, InfoMat, row[\"bias\"])\n",
    "        score = ScoreCircuit_SI_Joint(STRs, InfoMat)\n",
    "        if score == 0:\n",
    "            continue\n",
    "        SCORES.append(score)\n",
    "        CutBias.append(row[\"bias\"])\n",
    "        RealBias.append(real_minbias)\n",
    "        STRS.append(STRs)\n",
    "    return SCORES, CutBias, RealBias, STRS\n",
    "\n",
    "def XXXX_cont(BiasDF, BiasDF2, biaslim_df, size, DIR, adj_mat, InfoMat):\n",
    "    #fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, bias), DIR)[0]\n",
    "    SCORES, CutBias, RealBias, STRS = GetData2(biaslim_df, size, DIR, adj_mat, InfoMat)\n",
    "    New_RealBias = []\n",
    "    for STRSET in STRS:\n",
    "        xx = BiasDF.loc[STRSET, \"EFFECT\"].mean()\n",
    "        New_RealBias.append(xx)\n",
    "    # Add top size STRs\n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_SI_Joint(topNSTRs, InfoMat)\n",
    "    SCORES.append(score)\n",
    "    CutBias.append(bias)\n",
    "    New_RealBias.append(bias)\n",
    "    STRS.append(topNSTRs)    \n",
    "    return SCORES, CutBias, New_RealBias, STRS\n",
    "\n",
    "def search_target_swap(size, BiasDF, NSwap, biaslim_df, adj_mat, \n",
    "                       ProbMat1, ProbMat1_short, ProbMat1_long, \n",
    "                       ProbMat2, ProbMat2_short, ProbMat2_long, DIR):\n",
    "    # TopN targets \n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_v7(topNSTRs, adj_mat, ProbMat1, ProbMat2)\n",
    "    # search along the profile\n",
    "    for i, row in biaslim_df.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        cohe, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat, ProbMat1, ProbMat2)\n",
    "        score = ScoreCircuit_v7(STRs, adj_mat, ProbMat1, ProbMat2)\n",
    "\n",
    "        bias = BiasDF.loc[STRs, \"EFFECT\"].mean()\n",
    "        NDiff = len(set(STRs).difference(topNSTRs))\n",
    "        if abs(NDiff-NSwap) < 2:\n",
    "\n",
    "            score1 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_short, ProbMat2_short)\n",
    "            score2 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_long, ProbMat2_long)\n",
    "            if score > 0.714:\n",
    "                #print(RegionDistributionsList(STRs))\n",
    "                print(score, score1, score2)\n",
    "            return bias, score, score1, score2\n",
    "    return None, None, None, None\n",
    "\n",
    "def search_target_swap2(size, BiasDF, biaslim, biaslim_df, adj_mat, \n",
    "                       ProbMat1, ProbMat1_short, ProbMat1_long, \n",
    "                       ProbMat2, ProbMat2_short, ProbMat2_long, DIR):\n",
    "    # TopN targets \n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_v7(topNSTRs, adj_mat, ProbMat1, ProbMat2)\n",
    "    # search along the profile\n",
    "    for i, row in biaslim_df.iterrows():\n",
    "        fil = searchFil(\"keepN_{}-minbias_{}.txt\".format(size, row[\"bias\"]), DIR)[0]\n",
    "        cohe, real_minbias, STRs = LoadSA3(fil, DIR, adj_mat, ProbMat1, ProbMat2)\n",
    "        score = ScoreCircuit_v7(STRs, adj_mat, ProbMat1, ProbMat2)\n",
    "\n",
    "        bias = BiasDF.loc[STRs, \"EFFECT\"].mean()\n",
    "        #print(round(real_minbias,3), biaslim)\n",
    "        if round(real_minbias,3) == biaslim:\n",
    "            score1 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_short, ProbMat2_short)\n",
    "            score2 = ScoreCircuit_v7(STRs, adj_mat, ProbMat1_long, ProbMat2_long)\n",
    "            if score2 > 0.673:\n",
    "                #print()\n",
    "                print(RegionDistributionsList(STRs))\n",
    "            return bias, score, score1, score2\n",
    "    return None, None, None, None\n",
    "\n",
    "def LoadProfiles(BiasDF, BiasDF2, biaslim_df, size, DIR, adj_mat, InfoMat):\n",
    "    Scores, CutBias, RealBias, STRS = GetData2(biaslim_df, size, DIR, adj_mat, InfoMat)\n",
    "    # Add top size STRs\n",
    "    topNSTRs = BiasDF.index.values[:size]\n",
    "    bias = BiasDF2.head(size)[\"EFFECT\"].mean()\n",
    "    score = ScoreCircuit_SI_Joint(topNSTRs, InfoMat)\n",
    "    Scores.append(score)\n",
    "    CutBias.append(bias)\n",
    "    RealBias.append(bias)\n",
    "    STRS.append(topNSTRs)    \n",
    "    return Scores, CutBias, RealBias, STRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Plot ASD vs Sibling Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 46\n",
    "#biaslim_df = pd.read_csv(biaslim_dir + \"biaslim.size.{}.txt\".format(size), names=[\"size\", \"bias\"])\n",
    "ASD_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Circuits/SA/ASD_Pareto_SI_v2_Size46_Nov2023/\"\n",
    "ASD_BiasDF = pd.read_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.csv\", index_col=\"STR\")\n",
    "biaslim_df = pd.read_csv(\n",
    "    \"../dat/Circuits/SA/biaslims2/biaslim.size.46.top17.txt\", names=[\"size\", \"bias\"])\n",
    "COHESPeak, CutBiasPeak, RealBiasPeak, STRSPeak = LoadProfiles(ASD_BiasDF, ASD_BiasDF, biaslim_df, size, \n",
    "                                              ASD_DIR, adj_mat, InfoMat)\n",
    "ASD_DFPeak = pd.DataFrame(data={\"Cohe\":COHESPeak, \"minBias\":CutBiasPeak, \"Bias\":RealBiasPeak})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RegionDistributionsList(STRSPeak[-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RegionDistributionsList(STRSPeak[-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=480, figsize=(5,5))\n",
    "plt.plot(ASD_DFPeak[\"Cohe\"].values, ASD_DFPeak[\"Bias\"].values, marker=\"x\", color=\"blue\",\n",
    "             ls = \"--\", label=\"ASD\")\n",
    "plt.scatter(ASD_DFPeak[\"Cohe\"].values[-3], ASD_DFPeak[\"Bias\"].values[-3], marker=\"x\", s=50, color=\"red\",\n",
    "           zorder=100, label=\"Selected Circuits\")\n",
    "#plt.plot(SIB_DF55[\"Cohe\"].values[3:], SIB_DF55[\"Bias\"].values[3:], marker=\"x\", color=\"orange\",\n",
    "#             ls = \"--\", label=\"Sibling\")\n",
    "plt.xlabel(\"Circuit Score\")\n",
    "plt.ylabel(\"Mean Structure bias\")\n",
    "plt.grid()\n",
    "plt.ylim((0.05, 0.4))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Plt with Random Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 46\n",
    "\n",
    "biaslim_df = pd.read_csv(\n",
    "    \"../dat/Circuits/SA/biaslims2/biaslim.size.46.top17.txt\", names=[\"size\", \"bias\"])\n",
    "\n",
    "\n",
    "SIB_SA_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Circuits/SA/SubSib_Score_SI_Nov27_2023/\"\n",
    "SIB_BIAS_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Unionize_bias/SubSampleSib/\"\n",
    "\n",
    "dat_score = []\n",
    "dat_bias = []\n",
    "\n",
    "for i, file in enumerate(os.listdir(SIB_SA_DIR)):\n",
    "    #try:\n",
    "    d = os.path.join(SIB_SA_DIR, file)\n",
    "    if os.path.isdir(d):\n",
    "        biasdf = SIB_BIAS_DIR + file + \".csv\"\n",
    "        Sib_BiasDF = pd.read_csv(biasdf, index_col=\"STR\")\n",
    "        try:\n",
    "            ASD_cont_Dir = SIB_SA_DIR + file + \"/\"\n",
    "            COHES55, CutBias55, RealBias55, STRS55 = XXXX_cont(Sib_BiasDF, ASD_BiasDF, biaslim_df, size, \n",
    "                                                          ASD_cont_Dir, adj_mat, InfoMat)\n",
    "            dat_score.append(COHES55)\n",
    "            dat_bias.append(RealBias55)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_score = np.array(dat_score)\n",
    "dat_score_flat = dat_score.flatten()\n",
    "dat_bias = np.array(dat_bias)\n",
    "dat_bias_flat = dat_bias.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sib_DF55 = pd.DataFrame(data={\"SI score\":dat_score_flat, \"Bias\":dat_bias_flat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sib_DF55.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = []\n",
    "for bias, score in zip(dat_bias, dat_score):\n",
    "    meanbias = np.mean(bias)\n",
    "    meanscore = np.mean(score)\n",
    "    meantotal = meanbias + meanscore\n",
    "    profiles.append([meanbias, meanscore, meantotal, bias, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_bias = sorted(profiles, key = lambda x:x[0], reverse=True)\n",
    "rank_score = sorted(profiles, key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "topbias = []\n",
    "for i in range(len(profiles)):\n",
    "    topbias.append((rank_bias[i][4], rank_bias[i][3]))\n",
    "topbias = np.array(topbias)\n",
    "topSI = []\n",
    "for i in range(len(profiles)):\n",
    "    topSI.append((rank_score[i][4], rank_score[i][3]))\n",
    "topSI = np.array(topSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "topbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "topbias[1,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving AVG\n",
    "meanbias = []\n",
    "meanSI = []\n",
    "xerr = []\n",
    "yerr = []\n",
    "for i in range(topbias.shape[2]):\n",
    "    meanbias.append(np.nanmean(topbias[:,1,i]))\n",
    "    meanSI.append(np.nanmean(topbias[:,0,i]))\n",
    "    xerr.append(topbias[:,0,i].std())\n",
    "    yerr.append(topbias[:,1,i].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "topbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample subsample sibs\n",
    "#rand_indexes = np.random.randint(0, topbias.shape[0], topbias.shape[0])\n",
    "rand_indexes = np.random.randint(0, topbias.shape[0], 1000)\n",
    "topbias_sub = topbias[rand_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save variables to numpy file\n",
    "np.savez('../dat/CircuitSearch/SA/ASD_Pareto_SI_Size46/circuit_analysis_data.sibling.SA.npz', \n",
    "         meanbias=np.array(meanbias),\n",
    "         meanSI=np.array(meanSI), \n",
    "         topbias_sub=topbias_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=480, figsize=(4.2,4))\n",
    "\n",
    "ax.plot(ASD_DFPeak[\"Cohe\"].values, ASD_DFPeak[\"Bias\"].values, marker=\".\", color=\"#542788\",  lw=2, markersize=8,\n",
    "             ls = \"-\", label=\"ASD\")\n",
    "ax.scatter(ASD_DFPeak[\"Cohe\"].values[-4], ASD_DFPeak[\"Bias\"].values[-4], marker=\"x\", s=70, color=\"red\", lw=2,\n",
    "           zorder=100)\n",
    "ax.text(ASD_DFPeak[\"Cohe\"].values[-4], 0.01 + ASD_DFPeak[\"Bias\"].values[-4], s=\"Selected\\n Circuit\")\n",
    "\n",
    "ax.plot(topbias_sub[:,0,:].T, topbias_sub[:,1,:].T, color=\"grey\", markersize=1, lw=0.5,\n",
    "             ls = \"-\", alpha=0.05)\n",
    "#ax.plot(topbias_sub[0,0,:].T, topbias_sub[0,1,:].T, color=\"grey\", markersize=1, lw=1,\n",
    "#             ls = \"-\", alpha=1, label=\"Sibling Circuit\")\n",
    "\n",
    "ax.plot(meanSI, meanbias, marker=\".\", color=\"Orange\", lw=2, markersize=8,\n",
    "             ls = \"-\", alpha=1, label=\"Average Sibling Circuit\")\n",
    "ax.plot(meanSI, meanbias, color=\"grey\", lw=2, markersize=8,\n",
    "             ls = \"-\", alpha=1, label=\"Sibling Circuit\", zorder=0)\n",
    "\n",
    "#box = ax.get_position()\n",
    "#ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "#ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.9))\n",
    "ax.legend(loc=\"lower left\", frameon=False)\n",
    "\n",
    "plt.xlabel(\"Circuit Connectivity Score\", fontsize=14)\n",
    "plt.ylabel(\"Average Mutation Bias\", fontsize=14)\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.ylim(0.05, 0.42)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "3/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "4/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean profile w error bars\n",
    "yerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120, figsize=(8,6))\n",
    "\n",
    "plt.plot(ASD_DFPeak[\"Cohe\"].values, ASD_DFPeak[\"Bias\"].values, marker=\".\", color=\"blue\",\n",
    "             ls = \"--\", label=\"ASD\")\n",
    "plt.scatter(ASD_DFPeak[\"Cohe\"].values[-4], ASD_DFPeak[\"Bias\"].values[-4], marker=\"x\", s=50, color=\"red\",\n",
    "           zorder=100, label=\"Selected Circuits\")\n",
    "\n",
    "\n",
    "plt.errorbar(meanSI, meanbias, xerr=xerr, yerr=yerr, marker=\".\", color=\"black\",\n",
    "             ls = \"--\", alpha=1, label=\"mean profile subsampled siblings\")\n",
    "\n",
    "plt.legend()\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "labels, ids = np.unique(labels, return_index=True)\n",
    "handles = [handles[i] for i in ids]\n",
    "plt.legend(handles, labels, loc='best')\n",
    "\n",
    "plt.xlabel(\"SI score\")\n",
    "plt.ylabel(\"Bias\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=Sib_DF55[\"Cohe\"], y=Sib_DF55[\"Bias\"], \n",
    "              kind='kde', color=\"grey\", space=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 46\n",
    "NSwap = 5\n",
    "Score_ASD = 0.714\n",
    "Score_ASD_Short = 0.817 #0.817 0.673\n",
    "Score_ASD_Long = 0.673\n",
    "\n",
    "biaslim_dir_cont = \"../dat/Circuits/SA/biaslims2/\"\n",
    "biaslim_df = pd.read_csv(biaslim_dir_cont + \"biaslim.size.46.top17.txt\", header=None, names=[\"size\", \"bias\"])\n",
    "biaslim_df = biaslim_df.sort_values(\"bias\", ascending=False)\n",
    "\n",
    "Biases = []\n",
    "SCORES = []\n",
    "SCORES_Short = []\n",
    "SCORES_Long = []\n",
    "SIB_SA_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Circuits/SA/Sim_ScoreInfo_Oct12//\"\n",
    "SIB_BIAS_DIR = \"/home/jw3514/Work/ASD_Circuits/dat/Unionize_bias/RandGene.61.W1/\"\n",
    "\n",
    "counts = 0\n",
    "for i, file in enumerate(os.listdir(SIB_SA_DIR)):\n",
    "    d = os.path.join(SIB_SA_DIR, file)\n",
    "    if os.path.isdir(d):\n",
    "        #print(d)\n",
    "        \n",
    "        try:\n",
    "            biasdf = SIB_BIAS_DIR + file + \".csv\"\n",
    "            Sib_BiasDF = pd.read_csv(biasdf, index_col=\"STR\")\n",
    "            ASD_cont_Dir = SIB_SA_DIR + file + \"/\"\n",
    "            bias, score, score1, score2 = search_target_swap(size, Sib_BiasDF, NSwap, biaslim_df, \\\n",
    "                    adj_mat, ProbMat1, ProbMat1_short, ProbMat1_long, \\\n",
    "                    ProbMat2, ProbMat2_short, ProbMat2_long, ASD_cont_Dir)\n",
    "            #if score2 > Score_ASD_Long:\n",
    "            #    print(\"--\" + file)\n",
    "            #print(cohe)\n",
    "            if score != None:\n",
    "                SCORES.append(score)\n",
    "                SCORES_Short.append(score1)\n",
    "                SCORES_Long.append(score2)\n",
    "                Biases.append(bias)\n",
    "            else:\n",
    "                print(file, \"Fail to find proper circuits\")\n",
    "        except:\n",
    "            print(file, \"Fail to process\")\n",
    "        \n",
    "    counts += 1\n",
    "    #if counts > 10 :\n",
    "    #    break\n",
    "#print(COHES, Score_ASD)\n",
    "print(GetPermutationP(SCORES, Score_ASD))\n",
    "print(GetPermutationP(SCORES_Short, Score_ASD_Short))\n",
    "print(GetPermutationP(SCORES_Long, Score_ASD_Long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(COHES, Score_ASD)\n",
    "print(GetPermutationP(SCORES, Score_ASD))\n",
    "print(GetPermutationP(SCORES_Short, Score_ASD_Short))\n",
    "print(GetPermutationP(SCORES_Long, Score_ASD_Long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3,dpi=120, figsize=(16,4))\n",
    "PlotPermutationP(SCORES, Score_ASD, ax1,\n",
    "                     title=\"Info Per Edge Inside Circuit\".format(), xlabel=\"Normed Score\", \n",
    "                     dist_label=\"Simulated\", bar_label=\"ASD\")\n",
    "PlotPermutationP(SCORES_Short, Score_ASD_Short, ax2,\n",
    "                     title=\"Info Per Edge Inside Circuit\".format(), xlabel=\"Normed Score\", \n",
    "                     dist_label=\"Simulated\", bar_label=\"ASD\")\n",
    "PlotPermutationP(SCORES_Long, Score_ASD_Long, ax3,\n",
    "                     title=\"Info Per Edge Inside Circuit\".format(), xlabel=\"Normed Score\", \n",
    "                     dist_label=\"Simulated\", bar_label=\"ASD\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
