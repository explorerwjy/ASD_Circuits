{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import requests\n",
    "import json\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ProjDIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(1, os.path.join(ProjDIR, \"src\"))\n",
    "from ASD_Circuits import modify_str, LoadList\n",
    "\n",
    "os.chdir(os.path.join(ProjDIR, \"notebooks_mouse_str\"))\n",
    "print(f\"Project root: {ProjDIR}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config for data paths\n",
    "with open(os.path.join(ProjDIR, \"config/config.yaml\"), \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "ISH_DIR = config[\"data_files\"][\"ish_expression_dir\"]\n",
    "print(f\"ISH expression directory: {ISH_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Download ISH Data from Allen Brain Atlas\n",
    "\n",
    "This notebook downloads and preprocesses input data for the GENCIC pipeline:\n",
    "\n",
    "1. **Allen ISH experiment metadata** — list of all mouse brain ISH experiments with gene info\n",
    "2. **Allen gene catalog** — all genes with Entrez IDs in the Allen Mouse Brain Atlas\n",
    "3. **ISH expression energy** — per-structure unionized expression for each experiment (bulk download)\n",
    "4. **Human-Mouse gene homology** — ortholog mapping from MGI/JAX\n",
    "5. **Gene mapping construction** — match human genes → mouse orthologs → Allen section IDs\n",
    "6. **Structure metadata** — 213 selected brain structures\n",
    "\n",
    "All outputs are saved to `dat/allen-mouse-exp/`.\n",
    "Data downloads are guarded by `os.path.exists()` checks to avoid re-downloading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Allen ISH Experiment Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download list of all ISH experiments with gene and plane-of-section information\n",
    "out_path = os.path.join(ProjDIR, \"dat/allen-mouse-exp/All_Mouse_Brain_ISH_experiments.csv\")\n",
    "if not os.path.exists(out_path):\n",
    "    url = (\n",
    "        \"http://api.brain-map.org/api/v2/data/query.csv?criteria=model::SectionDataSet,\"\n",
    "        \"rma::criteria,[failed$eqfalse],products[abbreviation$eq'Mouse'],\"\n",
    "        \"treatments[name$eq'ISH'],genes,plane_of_section,\"\n",
    "        \"rma::options,[tabular$eq'plane_of_sections.name+as+plane',\"\n",
    "        \"'genes.acronym+as+gene_acronym',\"\n",
    "        \"'genes.entrez_id+as+genes_entrez_id',\"\n",
    "        \"'genes.ensembl_id+as+gene_ensembl_id',\"\n",
    "        \"'genes.alias_tags+as+gene_alias_tags',\"\n",
    "        \"'data_sets.id+as+section_data_set_id'],\"\n",
    "        \"[order$eq'plane_of_sections.name,genes.acronym,data_sets.id']&\"\n",
    "        \"start_row=0&num_rows=all\"\n",
    "    )\n",
    "    print(f\"Downloading ISH experiments from:\\n{url}\")\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    print(f\"Saved to {out_path}\")\n",
    "else:\n",
    "    print(f\"Already exists: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download complete gene catalog (gene symbols, aliases, Entrez IDs)\n",
    "out_path = os.path.join(ProjDIR, \"dat/allen-mouse-exp/All_Mouse_Brain_ISH_genes.csv\")\n",
    "if not os.path.exists(out_path):\n",
    "    url = (\n",
    "        \"http://api.brain-map.org/api/v2/data/query.csv?criteria=model::Gene,\"\n",
    "        \"rma::criteria,[failed$eqfalse],products[abbreviation$eq'Mouse'],\"\n",
    "        \"[tabular$eq'acronym+as+gene_acronym',\"\n",
    "        \"'gene_aliases.name+as+gene_aliases',\"\n",
    "        \"'entrez_id+as+genes_entrez_id',\"\n",
    "        \"[order$eq'acronym']&\"\n",
    "        \"start_row=0&num_rows=all\"\n",
    "    )\n",
    "    print(f\"Downloading gene catalog from:\\n{url}\")\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    print(f\"Saved to {out_path}\")\n",
    "else:\n",
    "    print(f\"Already exists: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download gene metadata with homologene IDs\n",
    "out_path = os.path.join(ProjDIR, \"dat/allen-mouse-exp/All_Mouse_Brain_Genes.csv\")\n",
    "if not os.path.exists(out_path):\n",
    "    url = (\n",
    "        \"http://api.brain-map.org/api/v2/data/query.csv?criteria=\"\n",
    "        \"model::Gene,\"\n",
    "        \"rma::criteria,products[abbreviation$eq'Mouse'],\"\n",
    "        \"rma::options,[tabular$eq'genes.id','genes.acronym+as+gene_symbol',\"\n",
    "        \"'genes.name+as+gene_name','genes.entrez_id+as+entrez_gene_id',\"\n",
    "        \"'genes.homologene_id+as+homologene_group_id',\"\n",
    "        \"'genes.alias_tags+as+gene_alias_tags'],\"\n",
    "        \"[order$eq'genes.acronym']&num_rows=all&start_row=0\"\n",
    "    )\n",
    "    print(f\"Downloading gene metadata from:\\n{url}\")\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    print(f\"Saved to {out_path}\")\n",
    "else:\n",
    "    print(f\"Already exists: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download ISH Expression Energy (Bulk)\n",
    "\n",
    "Each ISH experiment has a `section_data_set_id`. For each, we download the\n",
    "structure-unionized expression energy from the Allen API. This produces one\n",
    "CSV per experiment in the ISH directory configured in `config/config.yaml`.\n",
    "\n",
    "**This is a large download (~26,000 files). Skip if already present.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_PATH = \"http://api.brain-map.org/api/v2/data\"\n",
    "GRAPH_ID = 1\n",
    "\n",
    "experiments_csv = os.path.join(ProjDIR, \"dat/allen-mouse-exp/All_Mouse_Brain_ISH_experiments.csv\")\n",
    "\n",
    "# Check how many are already downloaded\n",
    "existing_files = set(os.listdir(ISH_DIR)) if os.path.exists(ISH_DIR) else set()\n",
    "print(f\"ISH directory: {ISH_DIR}\")\n",
    "print(f\"Existing expression files: {len(existing_files)}\")\n",
    "\n",
    "if len(existing_files) < 25000:\n",
    "    os.makedirs(ISH_DIR, exist_ok=True)\n",
    "    experiments = pd.read_csv(experiments_csv)\n",
    "    section_ids = experiments[\"section_data_set_id\"].unique()\n",
    "    print(f\"Total unique section IDs: {len(section_ids)}\")\n",
    "\n",
    "    url_base = (\n",
    "        f\"{API_PATH}/StructureUnionize/query.csv\"\n",
    "        f\"?criteria=[section_data_set_id$eq%d]\"\n",
    "        f\",structure[graph_id$eq{GRAPH_ID}]\"\n",
    "        f\"&numRows=all\"\n",
    "    )\n",
    "    n_downloaded = 0\n",
    "    for i, section_id in enumerate(section_ids):\n",
    "        fname = f\"{section_id}.csv\"\n",
    "        if fname in existing_files:\n",
    "            continue\n",
    "        url = url_base % section_id\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        with open(os.path.join(ISH_DIR, fname), \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        n_downloaded += 1\n",
    "        if n_downloaded % 1000 == 0:\n",
    "            print(f\"  Downloaded {n_downloaded} / {len(section_ids) - len(existing_files)} remaining...\")\n",
    "    print(f\"Downloaded {n_downloaded} new files. Total: {len(existing_files) + n_downloaded}\")\n",
    "else:\n",
    "    print(f\"ISH expression data already downloaded ({len(existing_files)} files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Human-Mouse Gene Homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MGI Human-Mouse homology report\n",
    "hom_path = os.path.join(ProjDIR, \"dat/HOM_MouseHumanSequence.rpt\")\n",
    "if not os.path.exists(hom_path):\n",
    "    url = \"https://www.informatics.jax.org/downloads/reports/HOM_MouseHumanSequence.rpt\"\n",
    "    print(f\"Downloading homology data from:\\n{url}\")\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(hom_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    print(f\"Saved to {hom_path}\")\n",
    "else:\n",
    "    print(f\"Already exists: {hom_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4. Build Human-Mouse Gene Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllenMouseGenes = pd.read_csv(\n",
    "    os.path.join(ProjDIR, \"dat/allen-mouse-exp/All_Mouse_Brain_ISH_experiments.csv\")\n",
    ")\n",
    "Human2MouseHom = pd.read_csv(hom_path, delimiter=\"\\t\")\n",
    "print(f\"Allen ISH experiments: {len(AllenMouseGenes)}\")\n",
    "print(f\"Homology entries: {len(Human2MouseHom)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build bidirectional Human <-> Mouse gene mappings using homology IDs\n",
    "Homo_IDs = set(Human2MouseHom[\"DB Class Key\"].values)\n",
    "print(f\"Unique homology groups: {len(Homo_IDs)}\")\n",
    "\n",
    "Human2Mouse_Genes = {}\n",
    "Mouse2Human_Genes = {}\n",
    "\n",
    "for ID in Homo_IDs:\n",
    "    tmp_df = Human2MouseHom[Human2MouseHom[\"DB Class Key\"] == ID]\n",
    "    hum_genes, mou_genes = [], []\n",
    "    for _, row in tmp_df.iterrows():\n",
    "        TaxonID = row[\"NCBI Taxon ID\"]\n",
    "        Symbol = row[\"Symbol\"]\n",
    "        Entrez = row[\"EntrezGene ID\"]\n",
    "        if TaxonID == 9606:\n",
    "            hum_genes.append((Symbol, Entrez))\n",
    "        elif TaxonID == 10090:\n",
    "            mou_genes.append((Symbol, Entrez))\n",
    "\n",
    "    for (Symbol, Entrez) in hum_genes:\n",
    "        if Entrez not in Human2Mouse_Genes:\n",
    "            Human2Mouse_Genes[Entrez] = {\"symbol\": Symbol, \"mouseHomo\": mou_genes}\n",
    "        else:\n",
    "            Human2Mouse_Genes[Entrez][\"mouseHomo\"].extend(mou_genes)\n",
    "\n",
    "    for (Symbol, Entrez) in mou_genes:\n",
    "        if Entrez not in Mouse2Human_Genes:\n",
    "            Mouse2Human_Genes[Entrez] = {\n",
    "                \"symbol\": Symbol,\n",
    "                \"humanHomo\": hum_genes,\n",
    "                \"allen_section_data_set_id\": [],\n",
    "            }\n",
    "        else:\n",
    "            Mouse2Human_Genes[Entrez][\"humanHomo\"].extend(hum_genes)\n",
    "\n",
    "print(f\"Human genes with mouse orthologs: {len(Human2Mouse_Genes)}\")\n",
    "print(f\"Mouse genes with human orthologs: {len(Mouse2Human_Genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create symbol-keyed version for convenience\n",
    "Mouse2Human_Genes_2 = {}\n",
    "for k, v in Mouse2Human_Genes.items():\n",
    "    Mouse2Human_Genes_2[v[\"symbol\"]] = {\"Entrez\": k, \"humanHomo\": v[\"humanHomo\"]}\n",
    "\n",
    "# Save pickle files\n",
    "pk.dump(Mouse2Human_Genes_2, open(os.path.join(ProjDIR, \"dat/Mouse2Human_Symbol.pk\"), \"wb\"))\n",
    "pk.dump(Mouse2Human_Genes, open(os.path.join(ProjDIR, \"dat/Mouse2Human_Entrez.pk\"), \"wb\"))\n",
    "print(\"Saved Mouse2Human_Symbol.pk and Mouse2Human_Entrez.pk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 5. Match Allen Section IDs to Mouse Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load discontinued Entrez IDs to handle gene ID changes\n",
    "df_disc = pd.read_csv(os.path.join(ProjDIR, \"dat/gene_history.human.mouse.tsv\"), delimiter=\"\\t\")\n",
    "Discontinued_ID = dict(zip(df_disc[\"Discontinued_GeneID\"].values, df_disc[\"GeneID\"].values))\n",
    "print(f\"Discontinued gene ID mappings: {len(Discontinued_ID)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match Allen section IDs to mouse genes via Entrez ID (primary) or discontinued ID (fallback)\n",
    "Entrez_Failed_ID = []\n",
    "for _, row in AllenMouseGenes.iterrows():\n",
    "    allen_entrez = int(row[\"genes_entrez_id\"]) if str(row[\"genes_entrez_id\"]) != \"nan\" else None\n",
    "    allen_section_id = row[\"section_data_set_id\"]\n",
    "\n",
    "    potential_ID = Discontinued_ID.get(allen_entrez, -1)\n",
    "    if isinstance(potential_ID, (int, float)) and not np.isnan(potential_ID):\n",
    "        potential_ID = int(potential_ID)\n",
    "    else:\n",
    "        potential_ID = -1\n",
    "\n",
    "    if allen_entrez in Mouse2Human_Genes:\n",
    "        Mouse2Human_Genes[allen_entrez][\"allen_section_data_set_id\"].append(allen_section_id)\n",
    "    elif potential_ID in Mouse2Human_Genes:\n",
    "        Mouse2Human_Genes[potential_ID][\"allen_section_data_set_id\"].append(allen_section_id)\n",
    "    else:\n",
    "        Entrez_Failed_ID.append(allen_section_id)\n",
    "\n",
    "print(f\"Section IDs matched by Entrez: {len(AllenMouseGenes) - len(Entrez_Failed_ID)}\")\n",
    "print(f\"Section IDs unmatched: {len(Entrez_Failed_ID)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count genes still missing section IDs\n",
    "Mouse_MissSectionID = [k for k, v in Mouse2Human_Genes.items() if len(v[\"allen_section_data_set_id\"]) == 0]\n",
    "print(f\"Mouse genes with no Allen section IDs yet: {len(Mouse_MissSectionID)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second pass: match unlinked section IDs by gene symbol or alias\n",
    "Unlinked_AllenMouseGenes = AllenMouseGenes[AllenMouseGenes[\"section_data_set_id\"].isin(Entrez_Failed_ID)]\n",
    "Symbol_Failed_ID = []\n",
    "mapped_by_symbol = 0\n",
    "mapped_by_alias = 0\n",
    "\n",
    "for _, row in Unlinked_AllenMouseGenes.iterrows():\n",
    "    allen_symbol = row[\"gene_acronym\"] if str(row[\"gene_acronym\"]) != \"nan\" else None\n",
    "    allen_alias = row[\"gene_alias_tags\"].split() if str(row[\"gene_alias_tags\"]) != \"nan\" else []\n",
    "    allen_section_id = row[\"section_data_set_id\"]\n",
    "\n",
    "    found = False\n",
    "    for k in Mouse_MissSectionID:\n",
    "        symbol = Mouse2Human_Genes[k][\"symbol\"]\n",
    "        if allen_symbol and symbol.lower() == allen_symbol.lower():\n",
    "            Mouse2Human_Genes[k][\"allen_section_data_set_id\"].append(allen_section_id)\n",
    "            found = True\n",
    "            mapped_by_symbol += 1\n",
    "            break\n",
    "        else:\n",
    "            for alias in allen_alias:\n",
    "                if alias.lower() == symbol.lower():\n",
    "                    Mouse2Human_Genes[k][\"allen_section_data_set_id\"].append(allen_section_id)\n",
    "                    found = True\n",
    "                    mapped_by_alias += 1\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "    if not found:\n",
    "        Symbol_Failed_ID.append(allen_section_id)\n",
    "\n",
    "print(f\"Matched by symbol: {mapped_by_symbol}\")\n",
    "print(f\"Matched by alias: {mapped_by_alias}\")\n",
    "print(f\"Still unmatched: {len(Symbol_Failed_ID)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final count of genes still missing\n",
    "Mouse_MissSectionID = [k for k, v in Mouse2Human_Genes.items() if len(v[\"allen_section_data_set_id\"]) == 0]\n",
    "print(f\"Mouse genes with no Allen section IDs (final): {len(Mouse_MissSectionID)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 6. Save Gene Mapping and Unlinked IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = os.path.join(ProjDIR, \"dat/allen-mouse-exp/\")\n",
    "\n",
    "with open(os.path.join(DIR, \"human2mouse.0420.json\"), \"w\") as f:\n",
    "    json.dump(Human2Mouse_Genes, f)\n",
    "\n",
    "with open(os.path.join(DIR, \"mouse2sectionID.0420.json\"), \"w\") as f:\n",
    "    json.dump(Mouse2Human_Genes, f)\n",
    "\n",
    "Unlinked_final = AllenMouseGenes[AllenMouseGenes[\"section_data_set_id\"].isin(Symbol_Failed_ID)]\n",
    "Unlinked_final.to_csv(os.path.join(DIR, \"Allen_Unlinked_SectionIDs.0415.csv\"), index=False)\n",
    "\n",
    "print(f\"Saved human2mouse.0420.json ({len(Human2Mouse_Genes)} entries)\")\n",
    "print(f\"Saved mouse2sectionID.0420.json ({len(Mouse2Human_Genes)} entries)\")\n",
    "print(f\"Saved Allen_Unlinked_SectionIDs.0415.csv ({len(Unlinked_final)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 7. Structure Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_Meta = pd.read_csv(os.path.join(ProjDIR, \"dat/allen-mouse-exp/allen_brain_atlas_structures.csv\"))\n",
    "STR_Meta.dropna(inplace=True, subset=[\"atlas_id\"])\n",
    "STR_Meta[\"atlas_id\"] = STR_Meta[\"atlas_id\"].astype(int)\n",
    "STR_Meta = STR_Meta.set_index(\"atlas_id\")\n",
    "\n",
    "# Clean up structure names using modify_str\n",
    "STR_Meta[\"Name2\"] = STR_Meta[\"safe_name\"].apply(modify_str)\n",
    "\n",
    "# Filter to the 213 selected structures\n",
    "Selected_STRs = LoadList(os.path.join(ProjDIR, \"dat/allen-mouse-exp/Structures.txt\"))\n",
    "STR_Meta_2 = STR_Meta[STR_Meta[\"Name2\"].isin(Selected_STRs)].sort_values(\"Name2\")\n",
    "\n",
    "out_path = os.path.join(ProjDIR, \"dat/allen-mouse-exp/Selected_213_STRs.Meta.csv\")\n",
    "STR_Meta_2.to_csv(out_path)\n",
    "print(f\"Selected structures: {len(STR_Meta_2)} (expected 213)\")\n",
    "print(f\"Saved to {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "gencic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
