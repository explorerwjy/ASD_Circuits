{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "ProjDIR = \"/home/jw3514/Work/ASD_Circuits_CellType/\" # Change to your project directory\n",
    "sys.path.insert(1, f'{ProjDIR}/src/')\n",
    "from ASD_Circuits import *\n",
    "\n",
    "try:\n",
    "    os.chdir(f\"{ProjDIR}/notebooks_figures/\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not change directory - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "\n",
    "\n",
    "HGNC, ENSID2Entrez, GeneSymbol2Entrez, Entrez2Symbol = LoadGeneINFO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the input and output Excel file paths\n",
    "input_excel = \"Supplementary_Tables_updated_sub.xlsx\"\n",
    "output_excel = \"Supplementary_Tables_updated_sub_new.xlsx\"  # Different output file\n",
    "\n",
    "# Read in the existing supplementary Excel file (if sheet names are unknown, this will scan them)\n",
    "try:\n",
    "    with pd.ExcelFile(input_excel) as xls:\n",
    "        sheet_names = xls.sheet_names\n",
    "        existing_tables = {sheet: pd.read_excel(xls, sheet_name=sheet) for sheet in sheet_names}\n",
    "        print(f\"Successfully read {len(existing_tables)} existing tables from {input_excel}\")\n",
    "except FileNotFoundError:\n",
    "    # File does not exist yet, so start with empty tables dictionary\n",
    "    existing_tables = {}\n",
    "    print(f\"Warning: {input_excel} not found. Starting with empty tables dictionary.\")\n",
    "\n",
    "# Initialize a dictionary to store new tables you want to add\n",
    "new_tables = {}\n",
    "\n",
    "# Function to save all tables (existing + new) to a new Excel file\n",
    "def save_supplementary_tables(output_filepath, new_tables_dict, existing_tables_dict):\n",
    "    \"\"\"\n",
    "    Combine existing tables with new ones and save to a new Excel file.\n",
    "    New tables can overwrite existing sheets of the same name.\n",
    "    \"\"\"\n",
    "    # Combine existing tables with new ones (new ones can overwrite existing sheets of the same name)\n",
    "    all_tables = {**existing_tables_dict, **new_tables_dict}\n",
    "    with pd.ExcelWriter(output_filepath, engine='openpyxl', mode='w') as writer:\n",
    "        for sheet, df in all_tables.items():\n",
    "            # Truncate sheet names to 31 characters to avoid Excel warnings\n",
    "            sheet_name = sheet[:31] if len(sheet) > 31 else sheet\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    print(f\"Successfully saved {len(all_tables)} tables to {output_filepath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Supplementary Table 6: Neurotransmitter genes included in validation analysis.\n",
    "# TableS6 = pd.read_csv(\"NeuralSystem.csv\", index_col=0)\n",
    "# TableS6_name = 'Table-S6-NeuroTransmitter Genes'\n",
    "\n",
    "# # Add TableS6 to the dict of new tables to be added to the Excel file\n",
    "# new_tables[TableS6_name] = TableS6\n",
    "\n",
    "# # Save all supplementary tables including the new one\n",
    "# save_supplementary_tables(V1_TabS, new_tables, existing_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Table1. I need replace orignal column of \"Bias.ASC102\" to \"Bias.Fu_72\" and add a new column of \"Bias.Fu_185\"\n",
    "# Use column \"EFFECT\" from Fu_72 and Fu_185 to replace the original column \"Bias.ASC102\" in Table1.\n",
    "# Need to insert at proper column position.\n",
    "Fu_72 = pd.read_csv(\"../results/STR_ISH/Fu_ASD_72_bias_addP_sibling.csv\")\n",
    "Fu_185 = pd.read_csv(\"../results/STR_ISH/Fu_ASD_185_bias_addP_sibling.csv\")\n",
    "\n",
    "# Find Table1 in existing_tables (look for sheet names containing \"Table-1\" or \"Table1\" or \"Table 1\")\n",
    "Table1_sheet_name = 'Table-S1- Structure Bias'\n",
    "for sheet_name in existing_tables.keys():\n",
    "    if 'Table-1' in sheet_name or 'Table1' in sheet_name or 'Table 1' in sheet_name:\n",
    "        Table1_sheet_name = sheet_name\n",
    "        break\n",
    "\n",
    "if Table1_sheet_name is None:\n",
    "    print(\"Warning: Could not find Table1 in existing tables. Available sheets:\", list(existing_tables.keys()))\n",
    "else:\n",
    "    print(f\"Found Table1: {Table1_sheet_name}\")\n",
    "    Table1 = existing_tables[Table1_sheet_name].copy()\n",
    "    \n",
    "    # Check if Bias.ASC102 column exists\n",
    "    if 'Bias.ASC102' not in Table1.columns:\n",
    "        print(f\"Warning: Column 'Bias.ASC102' not found in Table1. Available columns: {list(Table1.columns)}\")\n",
    "    else:\n",
    "        # Find the position of Bias.ASC102 column\n",
    "        bias_asc102_idx = list(Table1.columns).index('Bias.ASC102')\n",
    "        print(f\"Found 'Bias.ASC102' at column index: {bias_asc102_idx}\")\n",
    "        \n",
    "        # Find the matching column for Structure (could be 'STR', 'Structure', 'Acronym', etc.)\n",
    "        merge_col_table1 = None\n",
    "        for col in ['STR', 'Structure', 'structure', 'Acronym', 'ACRONYM']:\n",
    "            if col in Table1.columns:\n",
    "                merge_col_table1 = col\n",
    "                break\n",
    "        \n",
    "        if merge_col_table1 is None:\n",
    "            print(f\"Warning: Could not find Structure column in Table1. Available columns: {list(Table1.columns)}\")\n",
    "        else:\n",
    "            print(f\"Using '{merge_col_table1}' column from Table1 for alignment\")\n",
    "            \n",
    "            # Create mapping dictionaries from Structure to EFFECT\n",
    "            Fu_72_map = dict(zip(Fu_72['Structure'], Fu_72['EFFECT']))\n",
    "            Fu_185_map = dict(zip(Fu_185['Structure'], Fu_185['EFFECT']))\n",
    "            \n",
    "            # Map EFFECT values based on Structure alignment\n",
    "            Table1['Bias.Fu_72'] = Table1[merge_col_table1].map(Fu_72_map)\n",
    "            Table1['Bias.Fu_185'] = Table1[merge_col_table1].map(Fu_185_map)\n",
    "            \n",
    "            # Remove the old Bias.ASC102 column\n",
    "            Table1 = Table1.drop(columns=['Bias.ASC102'])\n",
    "            \n",
    "            # Reorder columns to insert Bias.Fu_72 and Bias.Fu_185 at the position where Bias.ASC102 was\n",
    "            cols = list(Table1.columns)\n",
    "            # Remove Bias.Fu_72 and Bias.Fu_185 from their current positions\n",
    "            cols = [c for c in cols if c not in ['Bias.Fu_72', 'Bias.Fu_185']]\n",
    "            # Insert them at the original Bias.ASC102 position\n",
    "            cols.insert(bias_asc102_idx, 'Bias.Fu_72')\n",
    "            cols.insert(bias_asc102_idx + 1, 'Bias.Fu_185')\n",
    "            Table1 = Table1[cols]\n",
    "            \n",
    "            # Update Table1 in existing_tables and also add to new_tables to ensure it gets saved\n",
    "            existing_tables[Table1_sheet_name] = Table1\n",
    "            new_tables[Table1_sheet_name] = Table1\n",
    "            print(f\"Successfully updated Table1: replaced 'Bias.ASC102' with 'Bias.Fu_72' and added 'Bias.Fu_185'\")\n",
    "            print(f\"New columns around position {bias_asc102_idx}: {cols[bias_asc102_idx:bias_asc102_idx+3]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Table 7: Dopamine Bias\n",
    "\n",
    "TableS7 = pd.read_csv(\"../results/STR_ISH/NT_Dopamine_combined_bias_addP_sibling.csv\")\n",
    "TableS7_name = 'Table-S7-Dopamine Bias'\n",
    "\n",
    "# Add TableS7 to the dict of new tables to be added to the Excel file\n",
    "new_tables[TableS7_name] = TableS7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Table 8: Serotonin Bias\n",
    "\n",
    "TableS8 = pd.read_csv(\"../results/STR_ISH/NT_Serotonin_combined_bias_addP_sibling.csv\")\n",
    "TableS8_name = 'Table-S8-Serotonin Bias'\n",
    "\n",
    "# Add TableS8 to the dict of new tables to be added to the Excel file\n",
    "new_tables[TableS8_name] = TableS8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Table 9: Oxytocin Bias\n",
    "\n",
    "TableS9 = pd.read_csv(\"../results/STR_ISH/NT_Oxytocin_combined_bias_addP_sibling.csv\")\n",
    "TableS9_name = 'Table-S9-Oxytocin Bias'\n",
    "\n",
    "# Add TableS9 to the dict of new tables to be added to the Excel file\n",
    "new_tables[TableS9_name] = TableS9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Table 10: DDD (exclude ASD) Structure Bias\n",
    "TableS10 = pd.read_csv(\"../results/STR_ISH/DDD_293_ExcludeASD_bias_addP_sibling.csv\")\n",
    "TableS10_name = 'Table-S10-DDD (exclude ASD) Structure Bias'\n",
    "\n",
    "# Add TableS10 to the dict of new tables to be added to the Excel file\n",
    "new_tables[TableS10_name] = TableS10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Table 11: DDD (exclude ASD) Cell type Bias\n",
    "\n",
    "TableS11 = pd.read_csv(\"../results/CT_Z2/DDD_293_ExcludeASD_bias_addP_sibling.csv\")\n",
    "TableS11_name = 'Table-S11-DDD (exclude ASD) Cell type Bias'\n",
    "\n",
    "# Add TableS11 to the dict of new tables to be added to the Excel file\n",
    "new_tables[TableS11_name] = TableS11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Table 12: Constraint gene Structure Bias\n",
    "TableS12 = pd.read_csv(\"../results/STR_ISH/Constraint_top25_LOEUF_bias_addP_random.csv\")\n",
    "TableS12_name = 'Table-S12-Constraint gene Structure Bias'\n",
    "\n",
    "# Add TableS12 to the dict of new tables to be added to the Excel file\n",
    "new_tables[TableS12_name] = TableS12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Table 13: Constraint gene Cell type Bias\n",
    "TableS13 = pd.read_csv(\"../results/CT_Z2/Constraint_top25_LOEUF_bias_addP_random.csv\")\n",
    "TableS13_name = 'Table-S13-Constraint gene Cell type Bias'\n",
    "\n",
    "# Add TableS13 to the dict of new tables to be added to the Excel file\n",
    "new_tables[TableS13_name] = TableS13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Supplementary Table 14: Gencic vs Mouse fMRI\n",
    "# TableS14 = pd.read_csv(\"/home/jw3514/Work/ASD_Circuits_CellType/results/FMRI_GENCIC_Combined_Table.csv\")\n",
    "# TableS14_name = 'Table-S14-Gencic vs Mouse fMRI'\n",
    "\n",
    "# # Add TableS14 to the dict of new tables to be added to the Excel file\n",
    "# new_tables[TableS14_name] = TableS14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary Table 15: Human fMRI and GENCIC comparison\n",
    "TableS14 = pd.read_excel(\"../notebook_rebuttal/Buch_et_al/claude_mapping_v6_DCG.xlsx\")  # Placeholder - update with correct file\n",
    "TableS14_name = 'Table-S14-Human-Mouse region mapping'\n",
    "\n",
    "# Add TableS15 to the dict of new tables to be added to the Excel file\n",
    "new_tables[TableS14_name] = TableS14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all supplementary tables (existing + new) to the output Excel file\n",
    "save_supplementary_tables(output_excel, new_tables, existing_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Supplementary Table 1: ASD Bias & Qvalue & Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### ASD Bias & Qvalue & Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Bias = pd.read_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.csv\", index_col=\"STR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASD Bias Qvalue\n",
    "import statsmodels.stats as stats\n",
    "\n",
    "def getBiasesBySTR(STR, dfs):\n",
    "    biases = []\n",
    "    for df in dfs:\n",
    "        bias = df.loc[STR, \"EFFECT\"]\n",
    "        biases.append(bias)\n",
    "    biases = np.array(biases)\n",
    "    return biases\n",
    "\n",
    "ASD_Sim_dir = \"../dat/Unionize_bias/SubSampleSib/\"\n",
    "\n",
    "cont_dfs = []\n",
    "for file in os.listdir(ASD_Sim_dir):\n",
    "    if file.startswith(\"cont.genes\"):\n",
    "        continue\n",
    "    df = pd.read_csv(ASD_Sim_dir+file, index_col=\"STR\")\n",
    "    cont_dfs.append(df)\n",
    "\n",
    "for STR, row in ASD_Bias.iterrows():\n",
    "    mat_bias = getBiasesBySTR(STR, cont_dfs)\n",
    "    Z, P = GetPermutationP(mat_bias, row[\"EFFECT\"])\n",
    "    ASD_Bias.loc[STR, \"Pvalue\"] = P\n",
    "    ASD_Bias.loc[STR, \"Z_Match\"] = Z\n",
    "\n",
    "acc, qvalues = stats.multitest.fdrcorrection(ASD_Bias[\"Pvalue\"].values, alpha=0.1,\n",
    "                                                   method=\"i\")\n",
    "print(sum(acc))\n",
    "ASD_Bias[\"qvalues\"] = qvalues\n",
    "ASD_Bias.to_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.subsib.FDR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, qvalues = stats.multitest.fdrcorrection(ASD_Bias[\"Pvalue\"].values, alpha=0.05,\n",
    "                                                   method=\"i\")\n",
    "print(sum(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Bias.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to annotate:\n",
    "# 1. ASC 102 genes bias\n",
    "# 2. Spark 159 Genes bias\n",
    "# 3. Neuro Density Normed bias\n",
    "# 4. Neuro/Glia Normed bias\n",
    "# 5. Male Bias\n",
    "# 6. Female Bias\n",
    "# 7. 46 Circuit membership\n",
    "# 8. 32 Circuit membership\n",
    "\n",
    "ASD_ASC = pd.read_csv(\"../dat/Unionize_bias/ASD.ASC102.Z2.bias.csv\",\n",
    "                                      index_col=\"STR\")\n",
    "ASD_159 = pd.read_csv(\"../dat/Unionize_bias/ASD.159.pLI.z2.csv\",\n",
    "                                      index_col=\"STR\")\n",
    "ASD_Male = pd.read_csv(\"../dat/Unionize_bias/ASD.Male.ALL.bias.csv\",\n",
    "                                      index_col=\"STR\")\n",
    "ASD_Female = pd.read_csv(\"../dat/Unionize_bias/ASD.Female.ALL.bias.csv\",\n",
    "                                      index_col=\"STR\")\n",
    "ASD_Neuron_den_norm_bias = pd.read_csv(\"../dat/Unionize_bias/ASD.neuron.density.norm.bias.csv\",\n",
    "                                      index_col=\"STR\")\n",
    "ASD_Glia_norm_bias = pd.read_csv(\"../dat/Unionize_bias/ASD.neuro2glia.norm.bias.csv\",\n",
    "                                      index_col=\"STR\")\n",
    "ASD_CircuitsSet = pd.read_csv(\n",
    "    \"/home/jw3514/Work/ASD_Circuits/notebooks/ASD.SA.Circuits.Size46.csv\",\n",
    "    index_col=\"idx\")\n",
    "ASD_Circuits = ASD_CircuitsSet.loc[3, \"STRs\"].split(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_32 = \"Anterior_cingulate_area_dorsal_part,Anterior_olfactory_nucleus,Anterior_pretectal_nucleus,Anteromedial_visual_area,Bed_nuclei_of_the_stria_terminalis,Caudoputamen,Claustrum,Dentate_gyrus,Endopiriform_nucleus_dorsal_part,Field_CA2,Infralimbic_area,Lateral_amygdalar_nucleus,Lateral_posterior_nucleus_of_the_thalamus,Lateral_visual_area,Mediodorsal_nucleus_of_thalamus,Nucleus_accumbens,Nucleus_of_reuniens,Orbital_area_lateral_part,Orbital_area_ventrolateral_part,Parafascicular_nucleus,Parataenial_nucleus,Posterior_parietal_association_areas,Prelimbic_area,Primary_motor_area,Primary_somatosensory_area_lower_limb,Primary_somatosensory_area_trunk,Primary_visual_area,Retrosplenial_area_lateral_agranular_part,Rhomboid_nucleus,Secondary_motor_area,Subiculum_ventral_part,Submedial_nucleus_of_the_thalamus\"\n",
    "ASD_32 = ASD_32.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for STR, row in ASD_Bias.iterrows():\n",
    "    ASD_Bias.loc[STR, \"Bias.Male\"] = ASD_Male.loc[STR, \"EFFECT\"]\n",
    "    ASD_Bias.loc[STR, \"Bias.Famale\"] = ASD_Female.loc[STR, \"EFFECT\"]\n",
    "    ASD_Bias.loc[STR, \"Bias.ASC102\"] = ASD_ASC.loc[STR, \"EFFECT\"]\n",
    "    ASD_Bias.loc[STR, \"Bias.Spark159\"] = ASD_159.loc[STR, \"EFFECT\"]\n",
    "    ASD_Bias.loc[STR, \"Bias.Neuron_density_normalized\"] = ASD_Neuron_den_norm_bias.loc[STR, \"EFFECT\"]\n",
    "    ASD_Bias.loc[STR, \"Bias.Neuron_glia_ratio_normalized\"] = ASD_Glia_norm_bias.loc[STR, \"EFFECT\"]\n",
    "    if STR in ASD_Circuits:\n",
    "        ASD_Bias.loc[STR, \"Circuits.46\"] = 1\n",
    "    else:\n",
    "        ASD_Bias.loc[STR, \"Circuits.46\"] = 0\n",
    "    if STR in ASD_32:\n",
    "        ASD_Bias.loc[STR, \"Circuits.32\"] = 1\n",
    "    else:\n",
    "        ASD_Bias.loc[STR, \"Circuits.32\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Bias.to_excel(\"../Manuscript/SupTabs/SupTab1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Bias"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python (gencic)",
   "language": "python",
   "name": "gencic"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
