{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights Calculation\n",
    " Weight0: Every Gene weighted equally \n",
    " \n",
    " Weight1: Ralitive Risk\n",
    " \n",
    " Weight2: Number of Hits\n",
    " \n",
    " Weight3: LofZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "ProjDIR = \"/home/jw3514/Work/ASD_Circuits_CellType/\" # Change to your project directory\n",
    "sys.path.insert(1, f'{ProjDIR}/src/')\n",
    "from ASD_Circuits import *\n",
    "from plot import *\n",
    "\n",
    "try:\n",
    "    os.chdir(f\"{ProjDIR}/notebooks_mouse_str/\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not change directory - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "\n",
    "\n",
    "HGNC, ENSID2Entrez, GeneSymbol2Entrez, Entrez2Symbol = LoadGeneINFO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file\n",
    "with open(\"../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "expr_matrix_path = config[\"analysis_types\"][\"STR_ISH\"][\"expr_matrix\"]\n",
    "STR_BiasMat = pd.read_parquet(f\"../{expr_matrix_path}\")\n",
    "Anno = STR2Region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_BiasMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_Meta_2stage = pd.read_excel(\"../dat/Genetics/41588_2022_1148_MOESM4_ESM.xlsx\",\n",
    "                           skiprows=2, sheet_name=\"Table S7\")\n",
    "Spark_Meta_2stage = Spark_Meta_2stage[Spark_Meta_2stage[\n",
    "    \"pDenovoWEST_Meta\"]!=\".\"]   \n",
    "Spark_Meta_ExomeWide = Spark_Meta_2stage[Spark_Meta_2stage[\"pDenovoWEST_Meta\"]<=1.3e-6]\n",
    "Spark_Meta_ExomeWide.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_sum = Spark_Meta_ExomeWide[\"AutismMerged_LoF\"].sum()\n",
    "dmis_revel_sum = Spark_Meta_ExomeWide[\"AutismMerged_Dmis_REVEL0.5\"].sum()\n",
    "\n",
    "print(f\"Sum of AutismMerged_LoF: {lof_sum}\")\n",
    "print(f\"Sum of AutismMerged_Dmis_REVEL0.5: {dmis_revel_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "\n",
    "bgmr_path = config[\"data_files\"][\"Denovo_mut_rate\"]\n",
    "BGMR = pd.read_csv(bgmr_path, sep=None, engine='python', index_col=0)\n",
    "\n",
    "# Add 'entrez_id' to each gene according to GeneName and GeneSymbol2Entrez\n",
    "if \"GeneName\" in BGMR.columns:\n",
    "    BGMR[\"entrez_id\"] = BGMR[\"GeneName\"].map(GeneSymbol2Entrez)\n",
    "    # Convert entrez_id to int, dropping NAs\n",
    "    BGMR = BGMR[~BGMR[\"entrez_id\"].isna()].copy()\n",
    "    BGMR[\"entrez_id\"] = BGMR[\"entrez_id\"].astype(int)\n",
    "    BGMR = BGMR.set_index(\"entrez_id\")\n",
    "else:\n",
    "    print(\"Warning: 'GeneName' column not found in BGMR.\")\n",
    "\n",
    "# Optionally, display a preview for verification\n",
    "BGMR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGMR.to_csv(\"/home/jw3514/Work/Resources/BGMR.withEntrez.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGMR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agg_gene2None, Agg_gene_bgmr = SPARK_Gene_Weights(Spark_Meta_ExomeWide, BGMR, \n",
    "        out=\"../dat/Unionize_bias/Spark_Meta_EWS.GeneWeight.bgmr.csv\")\n",
    "ASD_STR_Bias_bgmr = MouseSTR_AvgZ_Weighted(STR_BiasMat, Agg_gene_bgmr)\n",
    "len(Agg_gene_bgmr)\n",
    "\n",
    "Agg_gene2None, Agg_gene2MutN = SPARK_Gene_Weights(Spark_Meta_ExomeWide, None, \n",
    "        out=\"../dat/Unionize_bias/Spark_Meta_EWS.GeneWeight.v2.csv\")\n",
    "ASD_STR_Bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, Agg_gene2MutN)\n",
    "len(Agg_gene2MutN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                                        #csv_fil = \"../dat/Unionize_bias/Spark.EW.Z2.v2.csv\")\n",
    "#D_Agg_avgZ_RD = RegionDistributionsList(ASD_STR_Bias, topN=50)\n",
    "#print(D_Agg_avgZ_RD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_STR_Bias.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_Z2_old = pd.read_csv(\"../dat/Unionize_bias/Spark_Meta_EWS.Z2.bias.FDR.csv\", index_col=\"STR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BiasCorrelation(ASD_Z2, ASD_Z2_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_weights = LoadGeneWeights(\"../dat/Unionize_bias/Spark_Meta_EWS.GeneWeight.csv\")\n",
    "# ASD_Z2_old2 = AvgSTRZ_Weighted(ExpZ2Mat, old_weights, Method = 1)\n",
    "# ASD_Z2_old2 = ASD_Z2_old2.set_index(\"STR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiasCorrelation(ASD_STR_Bias, ASD_Z2_old, name1=\"Original ASD STR Bias\", name2=\"ASD STR Bias with \\nMutation Rate correction\", dpi=200)\n",
    "#BiasCorrelation(ASD_STR_Bias, ASD_Z2_old2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_structure_bias_correlation(df_a, df_b, label_a='Dataset A', label_b='Dataset B', title=None):\n",
    "    \"\"\"\n",
    "    Create comparison plot between two structure bias datasets\n",
    "\n",
    "    Parameters:\n",
    "    df_a: DataFrame with EFFECT column for first dataset\n",
    "    df_b: DataFrame with EFFECT column for second dataset\n",
    "    label_a: Label for x-axis (first dataset)\n",
    "    label_b: Label for y-axis (second dataset)\n",
    "    title: Custom title for the plot (ignored, no title drawn)\n",
    "\n",
    "    Returns:\n",
    "    correlation: Pearson correlation coefficient\n",
    "    \"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(1, 1, dpi=120, figsize=(5, 4), facecolor='none')\n",
    "\n",
    "    fig.patch.set_alpha(0)\n",
    "    ax.patch.set_alpha(0)\n",
    "\n",
    "    # Merge the datasets on structure names for comparison\n",
    "    merged_data = pd.merge(df_a[['EFFECT']], df_b[['EFFECT']], \n",
    "                          left_index=True, right_index=True, suffixes=('_A', '_B'))\n",
    "\n",
    "    # Create scatter plot\n",
    "    ax.scatter(merged_data['EFFECT_A'], merged_data['EFFECT_B'], \n",
    "              alpha=1, s=20, c='#1f77b4', edgecolors='black', linewidth=0.5)\n",
    "\n",
    "    # Add diagonal line for reference\n",
    "    min_val = min(merged_data['EFFECT_A'].min(), merged_data['EFFECT_B'].min())\n",
    "    max_val = max(merged_data['EFFECT_A'].max(), merged_data['EFFECT_B'].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2, label='y=x')\n",
    "\n",
    "    # Calculate correlation and p-value\n",
    "    correlation, pval = pearsonr(merged_data['EFFECT_A'], merged_data['EFFECT_B'])\n",
    "\n",
    "    # Set labels (no title)\n",
    "    ax.set_xlabel(f'{label_a}', fontsize=14)\n",
    "    ax.set_ylabel(f'{label_b}', fontsize=14)\n",
    "\n",
    "    # Format p-value display according to instructions\n",
    "    if pval < 1e-10:\n",
    "        p_disp = f\"p <{1e-10:.0e}\"\n",
    "    else:\n",
    "        p_disp = f\"p ={pval:.2g}\"\n",
    "\n",
    "    # Put correlation and p-value inside plot as annotation\n",
    "    ax.annotate(f'r = {correlation:.3f}\\n{p_disp}',\n",
    "                xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                ha='left', va='top', fontsize=15,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"w\", ec=\"gray\", alpha=0.8))\n",
    "\n",
    "    # Add grid\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "    # Make axes equal for better comparison\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "    return correlation\n",
    "plot_structure_bias_correlation(ASD_Z2_old, ASD_STR_Bias_bgmr, label_a='Mutation Bias\\nZhou et al. 61 ASD genes', label_b='Mutation Bias (Expected Correction)\\nZhou et al. 61 ASD genes', title='Structure Bias Comparison: Spark vs Fu_ASD_72')\n",
    "#plot_structure_bias_correlation(Spark_ASD_STR_Bias, ASD_Female, label_a='Mutation Bias \\nZhou et al. 61 ASD genes', label_b='Neuro-to-Glia Ratio Normalized Bias\\nZhou et al. 61 ASD genes', title='Structure Bias Comparison: Spark vs Fu_ASD_185')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation Bootstrap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_Meta_ExomeWide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_Meta_ExomeWide_Genes = Spark_Meta_ExomeWide[[\"GeneID\", \"EntrezID\", \"HGNC\", \"ExACpLI\", \"LOEUF\", \"AutismMerged_LoF\", \"AutismMerged_Dmis_REVEL0.5\", \"pDenovoWEST_Meta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spark_Meta_ExomeWide_Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_gene_mutations(\n",
    "    df,\n",
    "    n_boot=10,\n",
    "    weighted=True,\n",
    "    lof_col=\"AutismMerged_LoF\",\n",
    "    dmis_col=\"AutismMerged_Dmis_REVEL0.5\",\n",
    "    rng=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Bootstrap mutation counts at the mutation level, preserving gene identity\n",
    "    and total mutation load. Supports weighted (mutation-rate) or uniform resampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe with gene-level LOF and Dmis mutation counts.\n",
    "    n_boot : int, optional\n",
    "        Number of bootstrap replicates (default = 10).\n",
    "    weighted : bool, optional\n",
    "        If True, mutations are resampled with probability proportional to observed counts.\n",
    "        If False, each gene has equal probability of receiving any mutation.\n",
    "    lof_col, dmis_col : str\n",
    "        Column names for LOF and Dmis counts.\n",
    "    rng : np.random.Generator, optional\n",
    "        Numpy random generator for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boot_DFs : list of pd.DataFrame\n",
    "        List of bootstrapped dataframes with resampled mutation counts and 'bootstrap_iter' column.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "    n = len(df)\n",
    "    boot_DFs = []\n",
    "\n",
    "    # Ensure integer non-negative mutation counts\n",
    "    lof = df[lof_col].astype(int).clip(lower=0)\n",
    "    dmis = df[dmis_col].astype(int).clip(lower=0)\n",
    "\n",
    "    total_lof = lof.sum()\n",
    "    total_dmis = dmis.sum()\n",
    "\n",
    "    # Probability vectors for mutation assignment\n",
    "    if weighted:\n",
    "        # Weighted by observed mutation burden per gene\n",
    "        p_lof = lof / total_lof if total_lof > 0 else np.ones(n) / n\n",
    "        p_dmis = dmis / total_dmis if total_dmis > 0 else np.ones(n) / n\n",
    "    else:\n",
    "        # Uniform: every gene equally likely\n",
    "        p_lof = np.ones(n) / n\n",
    "        p_dmis = np.ones(n) / n\n",
    "\n",
    "    for i in range(1, n_boot + 1):\n",
    "        # Draw total_lof mutation events, assign to genes\n",
    "        new_lof_counts = np.bincount(\n",
    "            rng.choice(n, size=total_lof, replace=True, p=p_lof),\n",
    "            minlength=n\n",
    "        )\n",
    "        new_dmis_counts = np.bincount(\n",
    "            rng.choice(n, size=total_dmis, replace=True, p=p_dmis),\n",
    "            minlength=n\n",
    "        )\n",
    "\n",
    "        # Create bootstrap replicate\n",
    "        df_boot = df.copy().reset_index(drop=True)\n",
    "        df_boot[lof_col] = new_lof_counts\n",
    "        df_boot[dmis_col] = new_dmis_counts\n",
    "        df_boot[\"bootstrap_iter\"] = i\n",
    "        df_boot[\"bootstrap_type\"] = \"weighted\" if weighted else \"uniform\"\n",
    "        boot_DFs.append(df_boot)\n",
    "\n",
    "    return boot_DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_DFs_weights = bootstrap_gene_mutations(Spark_Meta_ExomeWide_Genes, 1000, weighted=True)\n",
    "boot_DFs_uniform = bootstrap_gene_mutations(Spark_Meta_ExomeWide_Genes, 1000, weighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Spark_Meta_ExomeWide_Genes[\"AutismMerged_LoF\"].sum(), Spark_Meta_ExomeWide_Genes[\"AutismMerged_Dmis_REVEL0.5\"].sum())\n",
    "Spark_Meta_ExomeWide_Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "print(boot_DFs_weights[idx][\"AutismMerged_LoF\"].sum(), boot_DFs_uniform[idx][\"AutismMerged_Dmis_REVEL0.5\"].sum())\n",
    "boot_DFs_weights[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_bias_list_weights = []\n",
    "save_dir = \"../results/Bootstrap_bias/Spark_ExomeWide/Weighted_Resampling\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for i, DF in enumerate(boot_DFs_weights):\n",
    "    _, boot_gw = SPARK_Gene_Weights(DF, BGMR, Bmis=False)\n",
    "    boot_bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, boot_gw)\n",
    "    boot_bias_list_weights.append(boot_bias)\n",
    "    boot_bias.to_csv(os.path.join(save_dir, f\"Spark_ExomeWide.GeneWeight.boot{i}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_bias_list_uniform = []\n",
    "save_dir = \"../results/Bootstrap_bias/Spark_ExomeWide/Uniform_Resampling\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for i, DF in enumerate(boot_DFs_uniform):\n",
    "    _, boot_gw = SPARK_Gene_Weights(DF, BGMR)\n",
    "    boot_bias = MouseSTR_AvgZ_Weighted(STR_BiasMat, boot_gw)\n",
    "    boot_bias_list_uniform.append(boot_bias)\n",
    "    boot_bias.to_csv(os.path.join(save_dir, f\"Spark_ExomeWide.GeneWeight.boot{i}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_bias_list_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoreMatDir=\"/home/jw3514/Work/ASD_Circuits/dat/allen-mouse-conn/ScoreingMat_jw_v3/\"\n",
    "IpsiInfoMat=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.csv\", index_col=0)\n",
    "IpsiInfoMatShort_v1=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.Short.3900.csv\", index_col=0)\n",
    "IpsiInfoMatLong_v1=pd.read_csv(ScoreMatDir + \"InfoMat.Ipsi.Long.3900.csv\", index_col=0)\n",
    "\n",
    "DIR = \"/home/jw3514/Work/ASD_Circuits/scripts/RankScores/\"\n",
    "Cont_Distance = np.load(\"{}/RankScore.Ipsi.Cont.npy\".format(DIR))\n",
    "Cont_DistanceShort = np.load(\"{}/RankScore.Ipsi.Short.3900.Cont.npy\".format(DIR))\n",
    "Cont_DistanceLong = np.load(\"{}/RankScore.Ipsi.Long.3900.Cont.npy\".format(DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_circuit_scores_for_profiles(\n",
    "    profile_bias_dict,\n",
    "    topNs,\n",
    "    info_mats_dict,\n",
    "    scoring_func=ScoreCircuit_SI_Joint,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute circuit scores for multiple profiles and connection types.\n",
    "\n",
    "    Args:\n",
    "        profile_bias_dict: dict of {profile_name: STR_Bias DataFrame}\n",
    "        topNs: list of top N structure ranks to scan\n",
    "        info_mats_dict: dict of {conn_type: info_mat pandas DataFrame}\n",
    "        scoring_func: function (top_str_list, info_mat) => score\n",
    "\n",
    "    Returns:\n",
    "        results: dict of {profile_name: {conn_type: np.array of scores}}\n",
    "    \"\"\"\n",
    "    results = {profile_name: {conn_type: [] for conn_type in info_mats_dict}\n",
    "               for profile_name in profile_bias_dict}\n",
    "    for profile_name, bias_df in profile_bias_dict.items():\n",
    "        str_ranks = bias_df.sort_values(\"EFFECT\", ascending=False).index.values\n",
    "        for topN in topNs:\n",
    "            top_strs = str_ranks[:topN]\n",
    "            for conn_type, info_mat in info_mats_dict.items():\n",
    "                score = scoring_func(top_strs, info_mat)\n",
    "                results[profile_name][conn_type].append(score)\n",
    "    # Convert lists to np.arrays for easier plotting\n",
    "    for profile_name in results:\n",
    "        for conn_type in results[profile_name]:\n",
    "            results[profile_name][conn_type] = np.array(results[profile_name][conn_type])\n",
    "    return results\n",
    "\n",
    "def plot_circuit_connectivity_scores_multi(\n",
    "    topNs,\n",
    "    circuit_scores_results,\n",
    "    cont_distance_dict,\n",
    "    profile_plot_kwargs=None,\n",
    "    show_siblings=True,\n",
    "    profile_labels=None,\n",
    "    xlim=(0, 121)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot circuit connectivity scores for multiple profiles and connection types.\n",
    "    - circuit_scores_results: output of compute_circuit_scores_for_profiles\n",
    "    - cont_distance_dict: {conn_type: np.array [n_iter, len(topNs)]}\n",
    "    - profile_plot_kwargs: {profile_name: {kwargs for plt.plot}}\n",
    "    - profile_labels: {profile_name: label string}\n",
    "    \"\"\"\n",
    "    conn_types = list(cont_distance_dict.keys())\n",
    "    n_conn = len(conn_types)\n",
    "    fig, axes = plt.subplots(n_conn, 1, dpi=480, figsize=(7, 4*n_conn))\n",
    "\n",
    "    if n_conn == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    BarLen = 34.1\n",
    "\n",
    "    colors = [\"blue\", \"red\", \"purple\", \"orange\", \"green\", \"black\", \"brown\"]\n",
    "    if profile_plot_kwargs is None:\n",
    "        profile_plot_kwargs = {}\n",
    "    if profile_labels is None:\n",
    "        profile_labels = {}\n",
    "\n",
    "    for i, conn_type in enumerate(conn_types):\n",
    "        ax = axes[i]\n",
    "        cont = (np.median if not conn_type.lower().startswith(\"long\") else np.nanmean)(cont_distance_dict[conn_type], axis=0)\n",
    "        # Plot scores for all profiles\n",
    "        for idx, (profile_name, prof_scores) in enumerate(circuit_scores_results.items()):\n",
    "            scores = prof_scores[conn_type]\n",
    "            label = profile_labels.get(profile_name, profile_name)\n",
    "            plot_args = profile_plot_kwargs.get(profile_name, {})\n",
    "            if not plot_args:\n",
    "                # Generate plot styles dynamically\n",
    "                plot_args = dict(\n",
    "                    color=colors[idx % len(colors)],\n",
    "                    marker=[\"o\", \"s\", \"^\", \"d\", \"x\", \"v\"][idx % 6],\n",
    "                    markersize=5 if idx == 0 else 3,\n",
    "                    lw=1,\n",
    "                    ls='dashed' if idx == 0 else '-',\n",
    "                    label=label\n",
    "                )\n",
    "            ax.plot(topNs, scores, **plot_args)\n",
    "\n",
    "        # Plot Sibling controls\n",
    "        if show_siblings:\n",
    "            #if \"nan\" in str(type(cont_distance_dict[conn_type])):\n",
    "            lower = np.nanpercentile(cont_distance_dict[conn_type], 50-BarLen, axis=0)\n",
    "            upper = np.nanpercentile(cont_distance_dict[conn_type], 50+BarLen, axis=0)\n",
    "            #else:\n",
    "            #    lower = np.percentile(cont_distance_dict[conn_type], 50-BarLen, axis=0)\n",
    "            #    upper = np.percentile(cont_distance_dict[conn_type], 50+BarLen, axis=0)\n",
    "            ax.errorbar(\n",
    "                topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "                yerr=(cont - lower, np.abs(upper - cont)),\n",
    "                ls=\"dashed\", label=\"Siblings\"\n",
    "            )\n",
    "\n",
    "        ax.set_xlabel(\"Structure Rank\\n\", fontsize=17)\n",
    "        ax.set_ylabel(\"Circuit Connectivity Score\", fontsize=15)\n",
    "        ax.legend(fontsize=13)\n",
    "        ax.set_xlim(*xlim)\n",
    "        ax.grid(True)\n",
    "        ax.set_title(f'Connection Type: {conn_type}', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# -- USAGE EXAMPLE/INSTANTIATION --\n",
    "\n",
    "topNs = list(range(200, 5, -1))\n",
    "\n",
    "# Define profiles to use (easily reusable/extendable!)\n",
    "profiles = {\n",
    "    \"Spark 61\": ASD_STR_Bias,\n",
    "    \"Spark 61 Old\": ASD_Z2_old,\n",
    "    # \"Spark\": Spark_ASD_STR_Bias, # add more as needed\n",
    "}\n",
    "info_mats = {\n",
    "    \"Standard\": IpsiInfoMat,\n",
    "    \"Short\": IpsiInfoMatShort_v1,\n",
    "    \"Long\": IpsiInfoMatLong_v1,\n",
    "}\n",
    "cont_distance_dict = {\n",
    "    \"Standard\": Cont_Distance,\n",
    "    \"Short\": Cont_DistanceShort,\n",
    "    \"Long\": Cont_DistanceLong,\n",
    "}\n",
    "\n",
    "# Compute all\n",
    "circuit_scores = compute_circuit_scores_for_profiles(\n",
    "    profiles, topNs, info_mats\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig = plot_circuit_connectivity_scores_multi(\n",
    "    topNs,\n",
    "    circuit_scores,\n",
    "    cont_distance_dict,\n",
    "    profile_labels={\n",
    "        \"Fu_ASD_185\": \"185 genes (Fu_ASD_185)\",\n",
    "        \"Fu_ASD_72\": \"72 genes (Fu_ASD_72)\",\n",
    "    },\n",
    "    xlim=(0, 121)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Confidence Intervals for Circuit Connectivity Scores\n",
    "\n",
    "Now we compute the circuit connectivity scores for each bootstrap replicate to generate confidence intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute circuit scores for all bootstrap samples\n",
    "topNs = list(range(200, 5, -1))\n",
    "info_mats = {\n",
    "    \"Standard\": IpsiInfoMat,\n",
    "    \"Short\": IpsiInfoMatShort_v1,\n",
    "    \"Long\": IpsiInfoMatLong_v1,\n",
    "}\n",
    "\n",
    "# Initialize storage for bootstrap scores\n",
    "boot_circuit_scores_weights = {conn_type: [] for conn_type in info_mats.keys()}\n",
    "boot_circuit_scores_uniform = {conn_type: [] for conn_type in info_mats.keys()}\n",
    "\n",
    "print(f\"Computing circuit scores for {len(boot_bias_list_weights)} bootstrap samples...\")\n",
    "for boot_idx, (boot_bias, boot_bias_uniform) in enumerate(zip(boot_bias_list_weights, boot_bias_list_uniform)):\n",
    "    if (boot_idx + 1) % 20 == 0:\n",
    "        print(f\"  Processing bootstrap {boot_idx + 1}/{len(boot_bias_list_weights)}\")\n",
    "    \n",
    "    # Get structure ranks for this bootstrap (weighted and uniform)\n",
    "    str_ranks = boot_bias.sort_values(\"EFFECT\", ascending=False).index.values\n",
    "    str_ranks_uniform = boot_bias_uniform.sort_values(\"EFFECT\", ascending=False).index.values\n",
    "    \n",
    "    # Compute scores for each topN and connection type for weighted\n",
    "    for conn_type, info_mat in info_mats.items():\n",
    "        scores_this_boot = []\n",
    "        for topN in topNs:\n",
    "            top_strs = str_ranks[:topN]\n",
    "            score = ScoreCircuit_SI_Joint(top_strs, info_mat)\n",
    "            scores_this_boot.append(score)\n",
    "        boot_circuit_scores_weights[conn_type].append(scores_this_boot)\n",
    "        \n",
    "    # Compute scores for each topN and connection type for uniform\n",
    "    for conn_type, info_mat in info_mats.items():\n",
    "        scores_this_boot_uniform = []\n",
    "        for topN in topNs:\n",
    "            top_strs_uniform = str_ranks_uniform[:topN]\n",
    "            score_uniform = ScoreCircuit_SI_Joint(top_strs_uniform, info_mat)\n",
    "            scores_this_boot_uniform.append(score_uniform)\n",
    "        boot_circuit_scores_uniform[conn_type].append(scores_this_boot_uniform)\n",
    "\n",
    "# Convert to numpy arrays: shape (n_bootstrap, n_topNs)\n",
    "for conn_type in boot_circuit_scores_weights:\n",
    "    boot_circuit_scores_weights[conn_type] = np.array(boot_circuit_scores_weights[conn_type])\n",
    "    print(f\"{conn_type} (weighted): shape = {boot_circuit_scores_weights[conn_type].shape}\")\n",
    "\n",
    "for conn_type in boot_circuit_scores_uniform:\n",
    "    boot_circuit_scores_uniform[conn_type] = np.array(boot_circuit_scores_uniform[conn_type])\n",
    "    print(f\"{conn_type} (uniform): shape = {boot_circuit_scores_uniform[conn_type].shape}\")\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circuit_scores_with_bootstrap_ci(\n",
    "    topNs,\n",
    "    mean_scores,\n",
    "    boot_scores,\n",
    "    cont_distance_dict,\n",
    "    ci_type='percentile',  # 'percentile' for 95% CI or 'std' for 1 std\n",
    "    percentile_range=95,   # percentile range (e.g., 95 for 95% CI)\n",
    "    viz_style='shade',     # 'shade' for shaded region or 'errorbar'\n",
    "    show_siblings=True,\n",
    "    xlim=(0, 121),\n",
    "    colors=None,\n",
    "    labels=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot circuit connectivity scores with bootstrap confidence intervals.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    topNs : list\n",
    "        List of top N structure ranks\n",
    "    mean_scores : dict\n",
    "        Dictionary {conn_type: mean_scores_array}\n",
    "    boot_scores : dict\n",
    "        Dictionary {conn_type: bootstrap_scores_array (n_boot, n_topNs)}\n",
    "    cont_distance_dict : dict\n",
    "        Dictionary {conn_type: control_distance_array}\n",
    "    ci_type : str\n",
    "        'percentile' for percentile-based CI (default 95%)\n",
    "        'std' for mean ± 1 standard deviation\n",
    "    percentile_range : float\n",
    "        Percentile range for CI when ci_type='percentile' (default 95)\n",
    "    viz_style : str\n",
    "        'shade' for shaded region (default)\n",
    "        'errorbar' for error bars\n",
    "    show_siblings : bool\n",
    "        Whether to show sibling controls\n",
    "    xlim : tuple\n",
    "        X-axis limits\n",
    "    colors : dict\n",
    "        Custom colors for each connection type\n",
    "    labels : dict\n",
    "        Custom labels for each connection type\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib figure\n",
    "    \"\"\"\n",
    "    conn_types = list(mean_scores.keys())\n",
    "    n_conn = len(conn_types)\n",
    "    \n",
    "    # Tighter figure layout\n",
    "    fig, axes = plt.subplots(n_conn, 1, dpi=480, figsize=(7, 2.5*n_conn), \n",
    "                             sharex=True)\n",
    "    \n",
    "    if n_conn == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    BarLen = 34.1\n",
    "    \n",
    "    default_colors = {\n",
    "        \"Standard\": \"blue\",\n",
    "        \"Short\": \"red\", \n",
    "        \"Long\": \"purple\"\n",
    "    }\n",
    "    default_labels = {\n",
    "        \"Standard\": \"Full Connectome\",\n",
    "        \"Short\": \"Short Distance\\nConnectome\",\n",
    "        \"Long\": \"Long Distance\\nConnectome\"\n",
    "    }\n",
    "    \n",
    "    if colors is None:\n",
    "        colors = default_colors\n",
    "    if labels is None:\n",
    "        labels = default_labels\n",
    "    \n",
    "    # Collect all y-values for aligned y-limits\n",
    "    all_y_values = []\n",
    "    \n",
    "    for i, conn_type in enumerate(conn_types):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Get mean and bootstrap scores\n",
    "        mean_score = mean_scores[conn_type]\n",
    "        boot_score = boot_scores[conn_type]  # shape: (n_boot, n_topNs)\n",
    "        \n",
    "        # Calculate confidence intervals (ignoring NaN values in bootstrap)\n",
    "        if ci_type == 'percentile':\n",
    "            lower_percentile = (100 - percentile_range) / 2\n",
    "            upper_percentile = 100 - lower_percentile\n",
    "            lower_ci = np.nanpercentile(boot_score, lower_percentile, axis=0)\n",
    "            upper_ci = np.nanpercentile(boot_score, upper_percentile, axis=0)\n",
    "            ci_label = f'{percentile_range}% CI'\n",
    "        elif ci_type == 'std':\n",
    "            std = np.nanstd(boot_score, axis=0)\n",
    "            lower_ci = mean_score - std\n",
    "            upper_ci = mean_score + std\n",
    "            ci_label = '±1 std'\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ci_type: {ci_type}\")\n",
    "        \n",
    "        # Collect y values for consistent scaling\n",
    "        all_y_values.extend(mean_score[~np.isnan(mean_score)])\n",
    "        all_y_values.extend(lower_ci[~np.isnan(lower_ci)])\n",
    "        all_y_values.extend(upper_ci[~np.isnan(upper_ci)])\n",
    "        \n",
    "        # Plot mean line\n",
    "        color = colors.get(conn_type, \"blue\")\n",
    "        label = labels.get(conn_type, conn_type)\n",
    "        ax.plot(topNs, mean_score, color=color, marker='o', markersize=3, \n",
    "                lw=1.5, label=f'{label}', zorder=3)\n",
    "        \n",
    "        # Plot confidence intervals\n",
    "        if viz_style == 'shade':\n",
    "            ax.fill_between(topNs, lower_ci, upper_ci, color=color, \n",
    "                           alpha=0.2, label=ci_label, zorder=2)\n",
    "        elif viz_style == 'errorbar':\n",
    "            # Sample every Nth point to avoid overcrowding\n",
    "            step = max(1, len(topNs) // 20)\n",
    "            indices = range(0, len(topNs), step)\n",
    "            ax.errorbar(\n",
    "                [topNs[j] for j in indices],\n",
    "                [mean_score[j] for j in indices],\n",
    "                yerr=[\n",
    "                    [mean_score[j] - lower_ci[j] for j in indices],\n",
    "                    [upper_ci[j] - mean_score[j] for j in indices]\n",
    "                ],\n",
    "                fmt='none', ecolor=color, alpha=0.5, capsize=2,\n",
    "                label=ci_label, zorder=2\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown viz_style: {viz_style}\")\n",
    "        \n",
    "        # Plot sibling controls\n",
    "        if show_siblings:\n",
    "            cont = (np.median if not conn_type.lower().startswith(\"long\") \n",
    "                   else np.nanmean)(cont_distance_dict[conn_type], axis=0)\n",
    "            lower_sib = np.nanpercentile(cont_distance_dict[conn_type], 50-BarLen, axis=0)\n",
    "            upper_sib = np.nanpercentile(cont_distance_dict[conn_type], 50+BarLen, axis=0)\n",
    "            ax.errorbar(\n",
    "                topNs, cont, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "                yerr=(cont - lower_sib, np.abs(upper_sib - cont)),\n",
    "                ls=\"dashed\", label=\"Siblings\", zorder=1\n",
    "            )\n",
    "            all_y_values.extend(lower_sib[~np.isnan(lower_sib)])\n",
    "            all_y_values.extend(upper_sib[~np.isnan(upper_sib)])\n",
    "        \n",
    "        # Only show xlabel and ylabel on bottom subplot\n",
    "        if i == n_conn - 1:\n",
    "            ax.set_xlabel(\"Structure Rank\", fontsize=25)\n",
    "            ax.set_ylabel(\"Circuit Connectivity Score\", fontsize=20)\n",
    "        \n",
    "        ax.legend(fontsize=11, loc='upper right', frameon=True, framealpha=0.9)\n",
    "        ax.set_xlim(*xlim)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.tick_params(axis='both', labelsize=18)\n",
    "    \n",
    "    # Set consistent y-limits across all subplots for alignment\n",
    "    if all_y_values:\n",
    "        y_min = np.min(all_y_values)\n",
    "        y_max = np.max(all_y_values)\n",
    "        y_range = y_max - y_min\n",
    "        y_padding = y_range * 0.05\n",
    "        for ax in axes:\n",
    "            ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "    \n",
    "    plt.tight_layout(h_pad=0.5)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean scores from the original Spark 61 data\n",
    "mean_circuit_scores = {}\n",
    "\n",
    "str_ranks = ASD_STR_Bias.sort_values(\"EFFECT\", ascending=False).index.values\n",
    "\n",
    "for conn_type, info_mat in info_mats.items():\n",
    "    scores = []\n",
    "    for topN in topNs:\n",
    "        top_strs = str_ranks[:topN]\n",
    "        score = ScoreCircuit_SI_Joint(top_strs, info_mat)\n",
    "        scores.append(score)\n",
    "    mean_circuit_scores[conn_type] = np.array(scores)\n",
    "\n",
    "print(\"Mean circuit scores computed for all connection types.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 1: 95% Confidence Intervals (Shaded Region) - DEFAULT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with 95% CI and shaded regions (DEFAULT)\n",
    "fig1 = plot_circuit_scores_with_bootstrap_ci(\n",
    "    topNs=topNs,\n",
    "    mean_scores=mean_circuit_scores,\n",
    "    boot_scores=boot_circuit_scores_weights,\n",
    "    cont_distance_dict=cont_distance_dict,\n",
    "    ci_type='percentile',      # Use percentile-based CI\n",
    "    percentile_range=95,        # 95% CI\n",
    "    viz_style='shade',          # Shaded region\n",
    "    show_siblings=True,\n",
    "    xlim=(0, 121)\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circuit_scores_with_bootstrap_ci(\n",
    "    topNs,\n",
    "    mean_scores,\n",
    "    boot_scores,\n",
    "    cont_distance_dict,\n",
    "    ci_type='percentile',      # 'percentile' for 95% CI or 'std' for 1 std\n",
    "    percentile_range=95,       # percentile range (e.g., 95 for 95% CI)\n",
    "    viz_style='shade',         # deprecated, now controlled by show_asd_ci and show_sib_ci\n",
    "    show_siblings=True,        # deprecated, will show sib curve if show_sib_ci or both\n",
    "    xlim=(0, 121),\n",
    "    colors=None,\n",
    "    labels=None,\n",
    "    show_asd_ci=True,          # NEW: show ASD bootstrap shade/error\n",
    "    show_sib_ci=True           # NEW: show siblings errorbar\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot circuit connectivity scores with bootstrap confidence intervals and/or sibling error bars.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    topNs : list\n",
    "        List of top N structure ranks\n",
    "    mean_scores : dict\n",
    "        Dictionary {conn_type: mean_scores_array}\n",
    "    boot_scores : dict\n",
    "        Dictionary {conn_type: bootstrap_scores_array (n_boot, n_topNs)}\n",
    "    cont_distance_dict : dict\n",
    "        Dictionary {conn_type: control_distance_array}\n",
    "    ci_type : str\n",
    "        'percentile' for percentile-based CI (default 95%)\n",
    "        'std' for mean ± 1 standard deviation\n",
    "    percentile_range : float\n",
    "        Percentile range for CI when ci_type='percentile' (default 95)\n",
    "    viz_style : str\n",
    "        'shade' for shaded region (default) [deprecated]\n",
    "        'errorbar' for error bars         [deprecated]\n",
    "    show_siblings : bool\n",
    "        (deprecated, use show_sib_ci)\n",
    "    xlim : tuple\n",
    "        X-axis limits\n",
    "    colors : dict\n",
    "        Custom colors for each connection type\n",
    "    labels : dict\n",
    "        Custom labels for each connection type\n",
    "    show_asd_ci : bool\n",
    "        Whether to show ASD bootstrap CI area/bar (shaded/error bar)\n",
    "    show_sib_ci : bool\n",
    "        Whether to show sibling error bars\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib figure\n",
    "    \"\"\"\n",
    "    conn_types = list(mean_scores.keys())\n",
    "    n_conn = len(conn_types)\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, axes = plt.subplots(n_conn, 1, dpi=480, figsize=(8, 4*n_conn))\n",
    "\n",
    "    if n_conn == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    BarLen = 34.1\n",
    "\n",
    "    default_colors = {\n",
    "        \"Standard\": \"blue\",\n",
    "        \"Short\": \"red\", \n",
    "        \"Long\": \"purple\"\n",
    "    }\n",
    "    default_labels = {\n",
    "        \"Standard\": \"ASD Probands\\n(Full Connectome)\",\n",
    "        \"Short\": \"ASD Probands\\n(Short Distance Connectome)\",\n",
    "        \"Long\": \"ASD Probands\\n(Long Distance Connectome)\"\n",
    "    }\n",
    "\n",
    "    if colors is None:\n",
    "        colors = default_colors\n",
    "    if labels is None:\n",
    "        labels = default_labels\n",
    "\n",
    "    for i, conn_type in enumerate(conn_types):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # ASD: Mean and bootstrap scores\n",
    "        mean_score = mean_scores[conn_type]\n",
    "        boot_score = boot_scores[conn_type]  # shape: (n_boot, n_topNs)\n",
    "\n",
    "        # Calculate confidence intervals (ignoring NaN values in bootstrap)\n",
    "        if ci_type == 'percentile':\n",
    "            lower_percentile = (100 - percentile_range) / 2\n",
    "            upper_percentile = 100 - lower_percentile\n",
    "            lower_ci = np.nanpercentile(boot_score, lower_percentile, axis=0)\n",
    "            upper_ci = np.nanpercentile(boot_score, upper_percentile, axis=0)\n",
    "            ci_label = f'ASD Probands \\n{percentile_range}% CI'\n",
    "        elif ci_type == 'std':\n",
    "            std = np.nanstd(boot_score, axis=0)\n",
    "            lower_ci = mean_score - std\n",
    "            upper_ci = mean_score + std\n",
    "            ci_label = '±1 std'\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ci_type: {ci_type}\")\n",
    "\n",
    "        # Plot ASD mean line (ALWAYS SHOWN)\n",
    "        color = colors.get(conn_type, \"blue\")\n",
    "        label = labels.get(conn_type, conn_type)\n",
    "        ax.plot(topNs, mean_score, color=color, marker='o', markersize=5, \n",
    "                lw=1.5, label=f'{label}', zorder=3)\n",
    "\n",
    "        # Plot ASD confidence interval (shade or errorbar)\n",
    "        if show_asd_ci:\n",
    "            if viz_style == 'shade':\n",
    "                ax.fill_between(topNs, lower_ci, upper_ci, color=color, \n",
    "                                alpha=0.2, label=ci_label, zorder=2)\n",
    "            elif viz_style == 'errorbar':\n",
    "                step = max(1, len(topNs) // 20)\n",
    "                indices = range(0, len(topNs), step)\n",
    "                ax.errorbar(\n",
    "                    [topNs[j] for j in indices],\n",
    "                    [mean_score[j] for j in indices],\n",
    "                    yerr=[\n",
    "                        [mean_score[j] - lower_ci[j] for j in indices],\n",
    "                        [upper_ci[j] - mean_score[j] for j in indices]\n",
    "                    ],\n",
    "                    fmt='none', ecolor=color, alpha=0.5, capsize=2,\n",
    "                    label=ci_label, zorder=2\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown viz_style: {viz_style}\")\n",
    "\n",
    "        # Plot siblings: Always plot average sibling profile (grey solid line), \n",
    "        # add error bar only if show_sib_ci=True.\n",
    "        cont_func = np.median if not conn_type.lower().startswith(\"long\") else np.nanmean\n",
    "        cont_profile = cont_func(cont_distance_dict[conn_type], axis=0)\n",
    "        ax.plot(topNs, cont_profile, color=\"grey\", marker=\"o\", markersize=3, lw=1.5,\n",
    "                label=\"Siblings\", zorder=4)\n",
    "\n",
    "        if show_sib_ci:\n",
    "            lower = np.nanpercentile(cont_distance_dict[conn_type], 50-BarLen, axis=0)\n",
    "            upper = np.nanpercentile(cont_distance_dict[conn_type], 50+BarLen, axis=0)\n",
    "            ax.errorbar(\n",
    "                topNs, cont_profile, color=\"grey\", marker=\"o\", markersize=1.5, lw=1,\n",
    "                yerr=(cont_profile - lower, np.abs(upper - cont_profile)),\n",
    "                ls=\"dashed\", label=\"Siblings (Interquantile Range)\", zorder=1,\n",
    "                alpha=0.77\n",
    "            )\n",
    "\n",
    "        # Remove x label and title for all but the bottom-most subplot\n",
    "        if i == n_conn - 1:\n",
    "            ax.set_xlabel(\"Structure Rank\\n\", fontsize=25)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"Circuit Connectivity Score\", fontsize=20, weight='normal')\n",
    "        ax.legend(fontsize=13, loc='upper right', frameon=False)\n",
    "        ax.set_xlim(*xlim)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        # Only set title for single-plot case (optional, comment if unused)\n",
    "        # if n_conn == 1:\n",
    "        #    ax.set_title(f'Connection Type: {conn_type}', fontsize=15)\n",
    "        # No per-subplot title\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Example: ASD+shade+error, sibling+error\n",
    "fig1 = plot_circuit_scores_with_bootstrap_ci(\n",
    "    topNs=topNs,\n",
    "    mean_scores=mean_circuit_scores,\n",
    "    boot_scores=boot_circuit_scores_weights,\n",
    "    cont_distance_dict=cont_distance_dict,\n",
    "    ci_type='percentile',      # Use percentile-based CI\n",
    "    percentile_range=95,       # 95% CI\n",
    "    viz_style='shade',         # Shaded region for ASD\n",
    "    show_asd_ci=False,          # Show ASD bootstrap shade or errorbar\n",
    "    show_sib_ci=True,          # Show sibling errorbar as well\n",
    "    xlim=(0, 121)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: ASD+shade+error, sibling+error\n",
    "fig1 = plot_circuit_scores_with_bootstrap_ci(\n",
    "    topNs=topNs,\n",
    "    mean_scores=mean_circuit_scores,\n",
    "    boot_scores=boot_circuit_scores_weights,\n",
    "    cont_distance_dict=cont_distance_dict,\n",
    "    ci_type='percentile',      # Use percentile-based CI\n",
    "    percentile_range=95,       # 95% CI\n",
    "    viz_style='shade',         # Shaded region for ASD\n",
    "    show_asd_ci=True,          # Show ASD bootstrap shade or errorbar\n",
    "    show_sib_ci=False,          # Show sibling errorbar as well\n",
    "    xlim=(0, 121)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gencic)",
   "language": "python",
   "name": "gencic"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
